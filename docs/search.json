[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Flow predictions using control-oriented cluster-based network modeling",
    "section": "",
    "text": "Cover"
  },
  {
    "objectID": "Data/1_Writing/0_Deco/2_Thanks.html",
    "href": "Data/1_Writing/0_Deco/2_Thanks.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "All praise and thanks to the\n\n\n\n\nONE\n\n\n\n \n\n\n, Who does neither need my praise nor my thanks. To the\n\n\n \n\n\n\n\nONE\n\n\n\n, Who is independent of everything and everyone, but on Whom everything and everyone depends.\n\n\n\n\n\n\nThanks to the supervisor\nThank you, Dr. Semaan - you provided me with the possibility to work on such a compelling and challenging topic. Even though the difficult tasks were not always pleasant, I very much appreciate the opportunity to have worked on these captivating tasks. Thank you for the time and effort you invested in this work. Also, thank you for the weekly English exercises and for explaining to me how to pronounce methodology correctly."
  },
  {
    "objectID": "Data/1_Writing/0_Deco/1_Erkl.html",
    "href": "Data/1_Writing/0_Deco/1_Erkl.html",
    "title": "Declaration of independent authorship",
    "section": "",
    "text": "I hereby declare that the present work, the master thesis, is solely and independently done by myself in all aspects, such as developments, code implementations, and writing of the thesis. In addition, I confirm that I did not use any tools, materials or sources other than those explicitly specified.\nFull name: Javed Arshad Butt \nDate and place: 29.04.2022, Braunschweig\nSignature:"
  },
  {
    "objectID": "Data/1_Writing/0_Deco/2_1_Abstract.html",
    "href": "Data/1_Writing/0_Deco/2_1_Abstract.html",
    "title": "Abstract",
    "section": "",
    "text": "In this master thesis, a data-driven modeling technique is proposed. It enables making predictions for general dynamic systems for unknown model parameter values or operating conditions. The tool is denoted as CNMccontrol-oriented Cluster-based Network Modeling. The most recent developed version delivered promising results for the chaotic Lorenz system (Lorenz 1963). Since, the earlier work was restricted to the application of only one dynamical system, with this contribution the first major improvement was to allow CNMccontrol-oriented Cluster-based Network Modeling to be utilized for any general dynamical system. For this, CNMccontrol-oriented Cluster-based Network Modeling was written from scratch in a modular manner. The limitation of the number of the dimension and the shape of the trajectory of the dynamical systems are removed. Adding a new dynamic system was designed such that it should be as straightforward as possible. To affirm this point, 10 dynamic systems, most of which are chaotic systems, are included by default. To be able to run CNMccontrol-oriented Cluster-based Network Modeling on arbitrary dynamic systems in an automated way, a parameter study for the modal decomposition method NMFNon-negative Matrix Factorization was implemented. However, since a single NMFNon-negative Matrix Factorization solution took up to hours, a second option was added, i.e., SVDSingular Value Decomposition. With SVDSingular Value Decomposition the most time-consuming task could be brought to a level of seconds. The improvements introduced, allow CNMccontrol-oriented Cluster-based Network Modeling to be executed on a general dynamic system on a normal computer in a reasonable time. Furthermore, CNMccontrol-oriented Cluster-based Network Modeling comes with its integrated post-processor in form of HTML files to inspect the generated plots in detail. All the parameters used in CNMccontrol-oriented Cluster-based Network Modeling some additional beneficial features can be controlled via one settings file.\n\n\n\n\nLorenz, Edward N. 1963. “Deterministic Nonperiodic Flow.” Journal of Atmospheric Sciences 20 (2): 130–41."
  },
  {
    "objectID": "Data/1_Writing/0_Deco/3_Used_Abbrev.html",
    "href": "Data/1_Writing/0_Deco/3_Used_Abbrev.html",
    "title": "Abbreviations",
    "section": "",
    "text": "ODE\n\n  Ordinary Differential Equation\n\nCNM\n\n  Cluster-based Network Modeling\n\nCNMc\n\n  control-oriented Cluster-based Network Modeling\n\nCMM\n\n  Cluster Markov-based Modeling\n\nCFD\n\n  Computational Fluid Dynamics\n\nRANS\n\n  Reynolds Averaged Navier Stockes\n\nDLR\n\n  German Aerospace Center\n\nGPU\n\n  Graphics Processing Unit\n\nCPU\n\n  Computer Processing Unit\n\nSDIC\n\n  Sensitive Dependence on Initial Conditions\n\nNMF\n\n  Non-negative Matrix Factorization\n\nSVD\n\n  Singular Value Decomposition\n\nRF\n\n  Random Forest\n\nCPD\n\n  Cluster Probability Distribution\n\nCPE\n\n  Centroid Position Evolution\n\nDTW\n\n  Dynamical Time Warping\n\nKNN\n\n  KNearest Neighbor"
  },
  {
    "objectID": "Data/1_Writing/1_Task/1_Introduction.html",
    "href": "Data/1_Writing/1_Task/1_Introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "In this work, a tool called control-oriented Cluster-based Network Modeling (CNMc) is further developed. The overall goal, in very brief terms, is to generate a model, which is able to predict the trajectories of general dynamical systems. The model shall be capable of predicting the trajectories when a model parameter value is changed. Some basics about dynamical systems are covered in subsection 3.0.1 and in-depth explanations about CNMccontrol-oriented Cluster-based Network Modeling are given in chapter 5. \nHowever, for a short and broad introduction to CNMccontrol-oriented Cluster-based Network Modeling the workflow depicted in figure 1.1 shall be highlighted. The input it receives is data of a dynamical system or space state vectors for a range of model parameter values. The two main important outcomes are some accuracy measurements and the predicted trajectory for each desired model parameter value. Any inexperienced user may only have a look at the predicted trajectories to quickly decide visually whether the prediction matches the trained data. Since CNMccontrol-oriented Cluster-based Network Modeling is written in a modular manner, meaning it can be regarded as a black-box function, it can easily be integrated into other existing codes or workflows. \n\n\n\nFigure 1.1— Broad overview: Workflow of"
  },
  {
    "objectID": "Data/1_Writing/1_Task/2_0_Motivation.html",
    "href": "Data/1_Writing/1_Task/2_0_Motivation.html",
    "title": "2  Motivation",
    "section": "",
    "text": "CFDComputational Fluid Dynamics is an indispensable technique, when aimed to obtain information about aerodynamic properties, such as drag and lift distributions. Modern CFDComputational Fluid Dynamics solvers, such as DLRGerman Aerospace Center’s TAU (Langer, Schwöppe, and Kroll 2014) often solves the RANSReynolds Averaged Navier Stockes equations to obtain one flow-field. Advanced solvers like TAU apply advanced mathematical knowledge to speed up calculations and heavily exploit multiple CPUsComputer Processing Units in an optimized manner. Nevertheless, depending on the size of the object and accuracy demands or in other terms mesh grid size, the computation often is not economically efficient enough. If the object for which a flow field is desired is a full aircraft, then even with a big cluster and making use of symmetry properties of the shape of the airplane, if such exists, the computation of one single flow field can still easily cost one or even multiple months in computation time. \nIn modern science, there is a trend towards relying on GPUsGraphics Processing Units instead of CPUsComputer Processing Units. Graphic cards possess much more cores than a CPU. However, even with the utilization of GPUsGraphics Processing Units and GPU-optimized CFDComputational Fluid Dynamics solvers, the computation is still very expensive. Not only in time but also in electricity costs. Running calculations on a cluster for multiple months is such expensive that wind tunnel measurements can be considered to be the economically more efficient choice to make. Regarding accuracy, wind tunnel measurements and CFDComputational Fluid Dynamics simulations with state-of-the-art solvers can be considered to be equally useful. When using CFDComputational Fluid Dynamics solvers, there is one more thing to keep in mind. Each outcome is only valid for one single set of input parameters. Within the set of input parameters, the user often is only interested in the impact of one parameter, e.g., the angle of attack. Consequently, wanting to capture the effect of the change of the angle of attack on the flow field, multiple CFDComputational Fluid Dynamics calculations need to be performed, i.e., for each desired angle of attack. Based on the chosen angle of attack the solver might be able to converge faster to a solution. However, the calculation time needs to be added up for each desired angle of attack. In terms of time and energy costs, this could again be more expensive than wind-tunnel measurements. Wind tunnel measurements are difficult to set up, but once a configuration is available, measuring flow field properties with it, in general, is known to be faster and easier than running CFDComputational Fluid Dynamics simulations.\n\nWithin the scope of this work, a data-driven tool was developed that allows predictions for dynamic systems. In (Pierzyna 2021) the first version of it showed promising results. However, it was dedicated to the solution of one single dynamical system, i.e., the Lorenz system (Lorenz 1963). Due to the focus on one singular dynamical system, the proposed control-oriented Cluster-based Network Modeling (CNMc) was not verified for other dynamical systems. Hence, one of the major goals of this thesis is to enable CNMccontrol-oriented Cluster-based Network Modeling to be applied to any general dynamical system. For this, it is important to state that because of two main reasons CNMccontrol-oriented Cluster-based Network Modeling was not built upon the first version of CNMccontrol-oriented Cluster-based Network Modeling, but written from scratch. First, since the initial version of CNMccontrol-oriented Cluster-based Network Modeling was designed for only a single dynamic system, extending it to a general CNMccontrol-oriented Cluster-based Network Modeling was considered more time-consuming than starting fresh. Second, not all parts of the initial version of CNMccontrol-oriented Cluster-based Network Modeling could be executed without errors. The current CNMccontrol-oriented Cluster-based Network Modeling is therefore developed in a modular manner, i.e., on the one hand, the implementation of any other dynamical system is straightforward. To exemplify this, 10 different dynamic systems are available by default, so new dynamic systems can be added analogously.\nThe second important aspect for allowing CNMccontrol-oriented Cluster-based Network Modeling to be utilized in any general dynamical system is the removal of the two limitations. In the first version of CNMccontrol-oriented Cluster-based Network Modeling the behavior of the dynamical systems had to be circular as, e.g., the ears of the Lorenz system (Lorenz 1963) are. Next, its dimensionality must be strictly 3-dimensional. Neither is a general dynamical system is not bound to exhibit a circular motion nor to be 3-dimensional. By removing these two limitations CNMccontrol-oriented Cluster-based Network Modeling can be leveraged on any dynamical system. However, the first version of CNMccontrol-oriented Cluster-based Network Modeling employed Non-negative Matrix Factorization (NMF) as the modal decomposition method. The exploited NMFNon-negative Matrix Factorization algorithm is highly computationally intensive, which makes a universal CNMccontrol-oriented Cluster-based Network Modeling application economically inefficient. Therefore, the current CNMccontrol-oriented Cluster-based Network Modeling has been extended by the option to choose between the NMFNon-negative Matrix Factorization and the newly implemented Singular Value Decomposition (SVD). The aim is not only that CNMccontrol-oriented Cluster-based Network Modeling is returning results within an acceptable timescale, but also to ensure that the quality of the modal decomposition remains at least at an equal level. Proofs for the latter can be found in section 14.\nWith these modifications, the current CNMccontrol-oriented Cluster-based Network Modeling is now able to be used in any dynamical system within a feasible time frame. The next addressed issue is the B-spline interpolation. It is used in the propagation step of Cluster-based Network Modeling (CNM) (Fernex, Noack, and Semaan 2021) to smooth the predicted trajectory. However, as already noted in (Pierzyna 2021), when the number of the clustering centroids \\(K\\) is \\(K \\gtrapprox 15\\), the B-spline interpolation embeds oscillations with unacceptable high deviations from the original trajectories. To resolve this problem, the B-spline interpolation is replaced with linear interpolation. By preventing the occurrence of outliers caused by the B-spline interpolation, neither the autocorrelation defined in subsection 4.0.1 nor the predicted trajectories are made impractical . Apart from the main ability of CNMccontrol-oriented Cluster-based Network Modeling a high number of additional features are available, e.g., the entire pipeline of CNMccontrol-oriented Cluster-based Network Modeling with all its parameters can be adjusted via one file (settings.py), an incorporated log file, storing results at desired steps, the ability to execute multiple dynamical models consequentially and activating and disabling each step of CNMccontrol-oriented Cluster-based Network Modeling. The latter is particularly designed for saving computational time. Also, CNMccontrol-oriented Cluster-based Network Modeling comes with its own post-processor. It is optional to generate and save the plots. However, in the case of utilizing this feature, the plots are available as HTML files which, e.g., allow extracting further information about the outcome or rotating and zooming in 3d plots.\n\n\n\n\nFernex, Daniel, Bernd R. Noack, and Richard Semaan. 2021. “Cluster-Based Network Modelingfrom Snapshots to Complex Dynamical Systems.” Science Advances 7 (25). https://doi.org/10.1126/sciadv.abf5006.\n\n\nLanger, Stefan, Axel Schwöppe, and Norbert Kroll. 2014. “The DLR Flow Solver TAU - Status and Recent Algorithmic Developments.” In 52nd Aerospace Sciences Meeting. https://elib.dlr.de/90979/.\n\n\nLorenz, Edward N. 1963. “Deterministic Nonperiodic Flow.” Journal of Atmospheric Sciences 20 (2): 130–41.\n\n\nPierzyna, Maximilian. 2021. “Control-Oriented Cluster-Basednetwork Modeling.” Research report, TU Braunschweig."
  },
  {
    "objectID": "Data/1_Writing/1_Task/2_State_Of_Art.html",
    "href": "Data/1_Writing/1_Task/2_State_Of_Art.html",
    "title": "3  State of the art",
    "section": "",
    "text": "The desire to get fast CFDComputational Fluid Dynamics output is not new and also a data-driven approach is found in the literature. This section aims to describe some evolutionary steps of control-oriented Cluster-based Network Modeling (CNMc). Given that this work is built upon the most recent advancements, they will be explained in particular detail. Whereas the remaining development stages are briefly summarized to mainly clarify the differences and\nmention the reasons why improvements were desired. Since, this topic demands some prior knowledge to follow CNMccontrol-oriented Cluster-based Network Modeling’s workflow and goal, some basic principles about important topics shall be given in their subsection.\nThe first data-driven approach, which is known to the author, is by (Kaiser et al. 2014) and shall be called CMMCluster Markov-based Modeling. CNMccontrol-oriented Cluster-based Network Modeling is not directly built upon CMMCluster Markov-based Modeling but on the latest version of CNMCluster-based Network Modeling and is described in (Fernex, Noack, and Semaan 2021). CNMccontrol-oriented Cluster-based Network Modeling invokes CNMCluster-based Network Modeling many times in order to use its outcome for further progress. Therefore, it’s evident that only if CNMCluster-based Network Modeling is understood, CNMc’s progress can be followed. CMMCluster Markov-based Modeling on the other hand has only a historical link to CNMccontrol-oriented Cluster-based Network Modeling, but no line of code of CMMCluster Markov-based Modeling is invoked in CNMccontrol-oriented Cluster-based Network Modeling’s workflow. Consequently, CNMCluster-based Network Modeling will be explained in more detail than CMMCluster Markov-based Modeling.\n\n3.0.1 Principles\nCNM (Fernex, Noack, and Semaan 2021) is a method that uses some machine learning techniques, graphs, and probability theory to mirror the behavior of complex systems. These complex systems are described often by dynamical systems, which themselves are simply a set of differential equations. Differential equations are useful to capture motion. Thus, a dynamical system can be seen as a synonym for motion over time. Some differential equations can be solved in closed form, meaning analytically. However, for most of them either it is too difficult to obtain an analytical solution or the analytical solution is very unhandy or unknown. Unhandy in terms of the solution being expressed in too many terms. Therefore, in most cases, differential equations are solved numerically. Since the purpose of CNMCluster-based Network Modeling is not to be only used for analytically solvable equations, a numerical ordinary differential integrator is used. \nThe default solver is SciPy’s RK45 solver. It is a widely deployed solver and can also be applied to chaotic systems for integration over a certain amount of time. Another option for solving chaotic ODEOrdinary Differential Equations is LSODA. The developers of pySindy (Silva et al. 2020; Kaptanoglu et al. 2022) state on their homepage (“pySindy’s Remark on RK45 Vs. LSODA” 2022) that LSODA even outperforms the default RK45 when it comes to chaotic dynamical systems. The reasons why for CNMccontrol-oriented Cluster-based Network Modeling still RK45 was chosen will be given in section 7. It is important to remember that turbulent flows are chaotic. This is the main reason why in this work CNMccontrol-oriented Cluster-based Network Modeling, has been designed to handle not only general dynamical systems but also general chaotic attractors. Other well-known instances where chaos is found are, e.g., the weather, the motion of planets and also the financial market is believed to be chaotic. For more places, where chaos is found the reader is referred to (Argyris et al. 2017).\nNote that CNMccontrol-oriented Cluster-based Network Modeling is designed for all kinds of dynamical systems, it is not restricted to linear, nonlinear or chaotic systems. Therefore, chaotic systems shall be recorded to be only one application example of CNMccontrol-oriented Cluster-based Network Modeling. However, because chaotic attractors were primarily exploited in the context of the performed investigations in this work, a slightly lengthier introduction to chaotic systems is provided in the appendix B. Two terms that will be used extensively over this entire thesis are called model parameter value \\(\\beta\\) and a range of model parameter values \\(\\vec{\\beta}\\). A regular differential equation can be expressed as in equation 3.1, where \\(F\\) is denoted as the function which describes the dynamical system. The vector \\(\\vec{x}(t)\\) is the state vector. The form in which differential equations are viewed in this work is given in equation 3.2 .\n\\[\n\\begin{equation}\n    F = \\dot{\\vec{x}}(t) = \\frac{\\vec{x}(t)}{dt} = f(\\vec{x}(t))\n    \\label{eq_1_0_DGL}\n\\end{equation}\n\\tag{3.1}\\]\n\\[\n\\begin{equation}\n    F_{CNMc} = \\left(\\dot{\\vec{x}}(t), \\, \\vec{\\beta} \\right) =\n    \\left( \\frac{\\vec{x}(t)}{dt}, \\, \\vec{\\beta} \\right) =\n     f(\\vec{x}(t), \\, \\vec{\\beta} )\n    \\label{eq_1_1_MPV}\n\\end{equation}\n\\tag{3.2}\\]\nNote the vector \\(\\vec{\\beta}\\) indicates a range of model parameter values, i.e., the differential equation is solved for each model parameter value \\(\\beta\\) separately. The model parameter value \\(\\beta\\) is a constant and does not depend on the time, but rather it is a user-defined value. In other terms, it remains unchanged over the entire timeline for which the dynamical system is solved. The difference between \\(F\\) and \\(F_{CNMc}\\) is that \\(F\\) is the differential equation for only one \\(\\beta\\), while \\(F_{CNMc}\\) can be considered as the same differential equation, however, solved, for a range of individual \\(\\beta\\) values. The subscript CNMccontrol-oriented Cluster-based Network Modeling stresses that fact that CNMccontrol-oriented Cluster-based Network Modeling is performed for a range of model parameter values \\(\\vec{\\beta}\\). Some dynamical systems, which will be used for CNMccontrol-oriented Cluster-based Network Modeling’s validation can be found in section 7. They are written as a set of differential equations in the \\(\\beta\\) dependent form. Even a tiny change in \\(\\beta\\) can result in the emergence of an entirely different trajectory.   \n\n\n\n\n\n\n\n\nIn summary, the following key aspects can be concluded. The reason why CNMccontrol-oriented Cluster-based Network Modeling in future releases is believed to be able to manage real CFDComputational Fluid Dynamics fluid flow data and make predictions for unknown model parameter values \\(\\beta\\) is that turbulent flows are chaotic. Thus, allowing CNMccontrol-oriented Cluster-based Network Modeling to work with chaotic attractors in the course of this thesis is considered to be the first step toward predicting entire flow fields. \n\n\n\n\nArgyris, John, Gunter Faust, Maria Haase, and Rudolf Friedrich. 2017. Die Erforschung Des Chaos. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-54546-1.\n\n\nFernex, Daniel, Bernd R. Noack, and Richard Semaan. 2021. “Cluster-Based Network Modelingfrom Snapshots to Complex Dynamical Systems.” Science Advances 7 (25). https://doi.org/10.1126/sciadv.abf5006.\n\n\nKaiser, Eurika, Bernd R Noack, Laurent Cordier, Andreas Spohn, Marc Segond, Markus Abel, Guillaume Daviller, Jan Östh, Siniša Krajnović, and Robert K Niven. 2014. “Cluster-Based Reduced-Order Modelling of a Mixing Layer.” Journal of Fluid Mechanics 754: 365–414.\n\n\nKaptanoglu, Alan, Brian De Silva, Urban Fasel, Kadierdan Kaheman, Andy Goldschmidt, Jared Callaham, Charles Delahunt, et al. 2022. “PySINDy: A Comprehensive Python Package for Robust Sparse System Identification.” Journal of Open Source Software 7 (69): 3994. https://doi.org/10.21105/joss.03994.\n\n\n“pySindy’s Remark on RK45 Vs. LSODA.” 2022. https://pysindy.readthedocs.io/en/latest/examples/1_feature_overview.html.\n\n\nSilva, Brian de, Kathleen Champion, Markus Quade, Jean-Christophe Loiseau, J. Kutz, and Steven Brunton. 2020. “PySINDy: A Python Package for the Sparse Identification of Nonlinear Dynamical Systems from Data.” Journal of Open Source Software 5 (49): 2104. https://doi.org/10.21105/joss.02104."
  },
  {
    "objectID": "Data/1_Writing/1_Task/3_CNM.html",
    "href": "Data/1_Writing/1_Task/3_CNM.html",
    "title": "4  Cluster-based Network Modeling (CNM)",
    "section": "",
    "text": "In this subsection, the workflow of CNMCluster-based Network Modeling (Fernex, Noack, and Semaan 2021) will be elaborated, as well as the previous attempt to expand the algorithm to accommodate a range of model parameter values \\(\\vec{\\beta}\\). CNMCluster-based Network Modeling (Fernex, Noack, and Semaan 2021) is the basis on which CNMccontrol-oriented Cluster-based Network Modeling is built or rather CNMccontrol-oriented Cluster-based Network Modeling invokes CNMCluster-based Network Modeling multiple times for one of its preprocessing steps. CNM can be split up into 4 main tasks, which are data collection, clustering, calculating transition properties and propagation. The first step is to collect the data, which can be provided from any dynamic system or numerical simulations. In this study, only dynamical systems are investigated. Once the data for the dynamical system is passed to CNMCluster-based Network Modeling, the data is clustered, e.g., with k-means++ algorithm (Arthur and Vassilvitskii 2006). A detailed elaboration about this step is given in section 8. CNMCluster-based Network Modeling exploits graph theory for approximating the trajectory as a movement on nodes. These nodes are equivalent to the centroids, which are acquired through clustering. Next, the motion, i.e., movement from one centroid to another, shall be clarified.\nIn order to fully describe the motion on the centroids, the time at which one centroid is visited is exited, and also the order of movement must be known. Note, when saying the motion is on the centroids, that means the centroids or characteristic nodes do not move at all. The entire approximated motion of the original trajectory on the nodes is described with the transition property matrices \\(\\boldsymbol Q\\) and \\(\\boldsymbol T\\). The matrices \\(\\boldsymbol Q\\) and \\(\\boldsymbol T\\) are the transition probability and transition time matrices, respectively. \\(\\boldsymbol Q\\) is used to apply probability theory for predicting the next following most likely centroid. In other words, if the current location is at any node \\(c_i\\), \\(\\boldsymbol Q\\) will provide all possible successor centroids with their corresponding transition probabilities. Thus, the motion on the centroids through \\(\\boldsymbol Q\\) is probability-based. In more detail, the propagation of the motion on the centroids can be described as equation 4.1 . The variables are denoted as the propagated \\(\\vec{x}(t)\\) trajectory, time \\(t\\), centroid positions \\(\\vec{c}_k,\\, \\vec{c}_j\\), the time \\(t_j\\) where centroid \\(\\vec{c}_j\\) is left and the transition time \\(T_{k,j}\\) from \\(\\vec{c}_j\\) to \\(\\vec{c}_k\\) (Fernex, Noack, and Semaan 2021). Furthermore, for the sake of a smooth trajectory, the motion between the centroids is interpolated through a spline interpolation. \\[\n\\begin{equation}\n    \\vec{x}(t) = \\alpha_{kj} (t) \\, \\vec{c}_k + [\\, 1 - \\alpha_{kj} (t)\\,] \\, \\vec{c}_j, \\quad \\alpha_{kj} (t) = \\frac{t-t_j}{T_{k,j}}\n    \\label{eq_34}\n\\end{equation}\n\\tag{4.1}\\]\nThe \\(\\boldsymbol Q\\) matrix only contains non-trivial transitions, i.e., if after a transition the centroid remains on the same centroid, the transition is not considered to be a real transition in CNMCluster-based Network Modeling. This idea is an advancement to the original work of Kaiser et al. (Kaiser et al. 2014). In Kaiser et al. (Kaiser et al. 2014) the transition is modeled as a Markov model. Markov models enable non-trivial transitions. Consequently, the diagonals of the resulting non-direct transition matrix \\(\\boldsymbol{Q_n}\\)\nexhibits the highest values. The diagonal elements stand for non-trivial transitions which lead to idling on the same centroid many times. Such behavior is encountered and described by Kaiser et al. (Kaiser et al. 2014).\nThere are 3 more important aspects that come along when adhering to Markov models. First, the propagation of motion is done by matrix-vector multiplication. In the case of the existence of a stationary state, the solution will converge to the stationary state, with an increasing number of iterations, where no change with time happens. A dynamical system can only survive as long as change with time exists. In cases where no change with respect to time is encountered, equilibrium or fixed points are found. Now, if a stationary state or fixed point exists in the considered dynamical system, the propagation will tend to converge to this fixed point. However, the nature of Markov models must not necessarily be valid for general dynamical systems. Another way to see that is by applying some linear algebra. The long-term behavior of the Markov transition matrix can be obtained with equation 4.2 . Here, \\(l\\) is the number of iterations to get from one stage to another. Kaiser et al.  (Kaiser et al. 2014) depict in a figure, how the values of\n\\(\\boldsymbol{Q_n}\\) evolves after \\(1 \\mathrm{e}{+3}\\) steps. \\(\\boldsymbol{Q_n}\\) has become more uniform. \\[\n\\begin{equation}\n    \\label{eq_3_Infinite}\n    \\lim\\limits_{l \\to \\infty} \\boldsymbol{Q_n}^l\n\\end{equation}\n\\tag{4.2}\\]\nIf the number of steps is increased even further and all the rows would have the same probability value, \\(\\boldsymbol{Q_n}\\) would converge to a stationary point. What also can be concluded from rows being equal is that it does not matter from where the dynamical system was started or what its initial conditions were. The probability to end at one specific state or centroid is constant as the number of steps approaches infinity. Following that, it would violate the sensitive dependency on initial conditions, which often is considered to be mandatory for modeling chaotic systems. Moreover, chaotic systems amplify any perturbation exponentially, whether at time \\(t = 0\\) or at time \\(t&gt;&gt;0\\). \nThus, a stationary transition matrix \\(\\boldsymbol{Q_n}\\) is prohibited by chaos at any time step. This can be found to be one of the main reasons, why the Cluster Markov based Modeling (CMMCluster Markov-based Modeling) often fails to predict the trajectory. Li et al. (Li et al. 2021) summarize this observation compactly as after some time the initial condition would be forgotten and the asymptotic distribution would be reached. Further, they stated, that due to this fact, CMMCluster Markov-based Modeling would not be suited for modeling dynamical systems. The second problem which is involved, when deploying regular Markov modeling is that the future only depends on the current state. However, (Fernex, Noack, and Semaan 2021) has shown with the latest CNMCluster-based Network Modeling version that incorporating also past centroid positions for predicting the next centroid position increases the prediction quality. The latter effect is especially true when systems are complex.\nHowever, for multiple consecutive time steps the trajectories position still could be assigned to the same centroid position (trivial transitions). Thus, past centroids are those centroids that are found when going back in time through only non-trivial transitions. The number of incorporated past centroids is given as equation 4.3, where \\(L\\) is denoted as the model order number. It represents the number of all considered centroids, where the current and all the past centroids are included, with which the prediction of the successor centroid is made. \\[\n\\begin{equation}\n    B_{past} = L -1\n    \\label{eq_5_B_Past}\n\\end{equation}\n\\tag{4.3}\\]\nFurthermore, in (Fernex, Noack, and Semaan 2021) it is not simply believed that an increasing model order \\(L\\) would increase the outcome quality in every case. Therefore, a study on the number of \\(L\\) and the clusters \\(K\\) was conducted. The results proved that the choice of \\(L\\) and \\(K\\) depend on the considered dynamical system. \nThe third problem encountered when Markov models are used is that the time step must be provided. This time step is used to define when a transition is expected. In case the time step is too small, some amount of iterations is required to transit to the next centroid. Thus, non-trivial transitions would occur. In case the time step is too high, the intermediate centroids would be missed. Such behavior would be a coarse approximation of the real dynamics. Visually this can be thought of as jumping from one centroid to another while having skipped one or multiple centroids. The reconstructed trajectory could lead to an entirely wrong representation of the state-space. CNM generates the transition time matrix \\(\\boldsymbol T\\) from data and therefore no input from the user is required.\nA brief review of how the \\(\\boldsymbol Q\\) is built shall be provided. Since the concept of model order, \\(L\\) has been explained, it can be clarified that it is not always right to call \\(\\boldsymbol Q\\) and \\(\\boldsymbol T\\) matrices. The latter is only correct, if \\(L = 1\\), otherwise it must be denoted as a tensor. \\(\\boldsymbol Q\\) and \\(\\boldsymbol T\\) can always be referred to as tensors since a tensor incorporates matrices, i.e., a matrix is a tensor of rank 2. In order to generate \\(\\boldsymbol Q\\), \\(L\\) must be defined, such that the shape of \\(\\boldsymbol Q\\) is known. The next step is to gather all sequences of clusters \\(c_i\\). To understand that, we imagine the following scenario, \\(L = 3\\), which means 2 centroids from the past and the current one are incorporated to predict the next centroid. Furthermore, imagining that two cluster sequence scenarios were found, \\(c_0 \\rightarrow c_1 \\rightarrow c_2\\) and \\(c_5 \\rightarrow c_1 \\rightarrow c_2\\). These cluster sequences tell us that the current centroid is \\(c_2\\) and the remaining centroids belong to the past. In order to complete the sequence for \\(L = 3\\), the successor cluster also needs to be added, \\(c_0 \\rightarrow c_1 \\rightarrow c_2 \\rightarrow c_5\\) and \\(c_5 \\rightarrow c_1 \\rightarrow c_2 \\rightarrow c_4\\). The following step is to calculate the likelihood of a transition to a specific successor cluster. This is done with equation 4.4, where \\(n_{k, \\boldsymbol{j}}\\) is the amount of complete sequences, where also the successor is found. The index \\(j\\) is written as a vector in order to generalize the equation for \\(L \\ge 1\\). It then contains all incorporated centroids from the past and the current centroid. The index \\(k\\) represents the successor centroid (\\(\\boldsymbol{j} \\rightarrow k\\)). Finally, \\(n_{\\boldsymbol{j}}\\) counts all the matching incomplete sequences. \\[\n\\begin{equation}\n    \\label{eq_4_Poss}\n     P_{k, \\boldsymbol j} = \\frac{n_{k,\\boldsymbol{j}}}{n_{\\boldsymbol{j}}}\n\\end{equation}\n\\tag{4.4}\\]\nAfter having collected all the possible complete cluster sequences with their corresponding probabilities \\(\\boldsymbol Q\\), the transition time tensors \\(\\boldsymbol T\\) can be inferred from the data. With that, the residence time on each cluster is known and can be used for computing the transition times for every single transition. At this stage, it shall be highlighted again, CNM approximates its data fully with only two matrices or when \\(L \\ge 2\\) tensors, \\(\\boldsymbol Q\\) and \\(\\boldsymbol T\\). The final step is the prorogation following equation 4.1 . For smoothing the propagation between two centroids the B-spline interpolation is applied.\n\n\n\n\n\n\n\n4.0.1 First version of CNMc\nApart from this thesis, there already has been an attempt to build control-oriented Cluster-based Network Modeling (CNMc). The procedure, progress and results of the most recent effort are described in (Pierzyna 2021). Also, in the latter, the main idea was to predict the trajectories for dynamical systems with a control term or a model parameter value \\(\\beta\\). In this subsection, a review of (Pierzyna 2021) shall be given with pointing out which parts need to be improved. In addition, some distinctions between the previous version of CNMccontrol-oriented Cluster-based Network Modeling and the most recent version are named. Further applied modifications are provided in chapter 5.\nTo avoid confusion between the CNMccontrol-oriented Cluster-based Network Modeling version described in this thesis and the prior CNMccontrol-oriented Cluster-based Network Modeling version, the old version will be referred to as first CNMc. First CNMc starts by defining a range of model parameter values \\(\\vec{\\beta}\\). It was specifically designed to only be able to make predictions for the Lorenz attractor (Lorenz 1963), which is described with the set of equations 7.1 given in section 7. An illustrative trajectory is of the Lorenz system (Lorenz 1963) with \\(\\beta = 28\\) is depicted in figure 4.1 .\n\n\n\n\n\n\nFigure 4.1— Illustrative trajectory of the Lorenz attractor (Lorenz 1963), \\(\\beta = 28\\)\n\n\nHaving chosen a range of model parameter values \\(\\vec{\\beta}\\), the Lorenz system was solved numerically and its solution was supplied to CNMCluster-based Network Modeling in order to run k-means++ on all received trajectories.    The centroid label allocation by the k-means+ algorithm is conducted randomly. Thus, linking or matching centroid labels from one model parameter value \\(\\beta_i\\) to another model parameter value \\(\\beta_j\\), where \\(i \\neq j\\), is performed in 3 steps. The first two steps are ordering the \\(\\vec{\\beta}\\) in ascending order and transforming the Cartesian coordinate system into a spherical coordinate system. With the now available azimuth angle, each centroid is labeled in increasing order of the azimuth angle. The third step is to match the centroids across \\(\\vec{\\beta}\\), i.e., \\(\\beta_i\\) with \\(\\beta_j\\). For this purpose, the centroid label from the prior model parameter value is used as a reference to match its corresponding nearest centroid in the next model parameter value. As a result, one label can be assigned to one centroid across the available \\(\\vec{\\beta}\\).\nFirstly, (Pierzyna 2021) showed that ambiguous regions can occur. Here the matching of the centroids across the \\(\\vec{\\beta}\\) can not be trusted anymore. Secondly, the deployed coordinate transformation is assumed to only work properly in 3 dimensions. There is the possibility to set one or two variables to zero in order to use it in two or one dimension, respectively. However, it is not known, whether such an artificially decrease of dimensions yields a successful outcome for lower-dimensional (2- and 1-dimensional) dynamical systems. In the event of a 4-dimensional or even higher dimensional case, the proposed coordinate transformation cannot be used anymore. In conclusion, the transformation is only secure to be utilized in 3 dimensions. Thirdly, which is also acknowledged by (Pierzyna 2021) is that the coordinate transformation forces the dynamical system to have a circular-like trajectory, e.g., as the in figure 4.1 depicted Lorenz system does. Since not every dynamical system is forced to have a circular-like trajectory, it is one of the major parts which needs to be improved, when first CNMc is meant to be leveraged for all kinds of dynamical systems. Neither the number of dimensions nor the shape of the trajectory should matter for a generalized CNMccontrol-oriented Cluster-based Network Modeling.\nOnce the centroids are matched across all the available \\(\\vec{\\beta}\\) pySINDy (Brunton, Proctor, and Kutz 2016; Silva et al. 2020; Kaptanoglu et al. 2022) is used to build a regression model. This regression model serves the purpose of capturing all centroid positions of the calculated model parameter values \\(\\vec{\\beta }\\) and making predictions for unseen \\(\\vec{\\beta}_{unseen}\\). Next, a preprocessing step is performed on the transition property tensors \\(\\boldsymbol Q\\) and \\(\\boldsymbol T\\). Both are scaled, such that the risk of a bias is assumed to be reduced. Then, on both Non-negative Matrix Factorization (NMF) (Lee and Seung 1999) is applied. Following equation 4.5 NMFNon-negative Matrix Factorization (Lee and Seung 1999) returns two matrices, i.e., \\(\\boldsymbol W\\) and \\(\\boldsymbol H\\). The matrices exhibit a physically relevant meaning. \\(\\boldsymbol W\\) corresponds to a mode collection and \\(\\boldsymbol H\\) contains the weighting factor for each corresponding mode. \\[\n\\begin{equation}\n    \\label{eq_5_NMF}\n    \\boldsymbol {A_{i \\mu}} \\approx \\boldsymbol A^{\\prime}_{i \\mu}  = (\\boldsymbol W  \\boldsymbol H)_{i \\mu}  = \\sum_{a = 1}^{r}\n    \\boldsymbol W_{ia} \\boldsymbol H_{a \\mu}\n\\end{equation}\n\\tag{4.5}\\]\nThe number of modes \\(r\\) depends on the underlying dynamical system. Firstly, the NMFNon-negative Matrix Factorization is utilized by deploying optimization. The goal is to satisfy the condition that, the deviation between the original matrix and the approximated matrix shall be below a chosen threshold. For this purpose, the number of required optimization iterations easily can be in the order of \\(\\mathcal{O} (1 \\mathrm{e}+7)\\). The major drawback here is that such a high number of iterations is computationally very expensive. Secondly, for first CNMc the number of modes \\(r\\) must be known beforehand. Since in most cases this demand cannot be fulfilled two issues arise. On the one hand, running NMFNon-negative Matrix Factorization on a single known \\(r\\) can already be considered to be computationally expensive. On the other hand, conducting a study to find the appropriate \\(r\\) involves even more computational effort. Pierzyna (Pierzyna 2021) acknowledges this issue and defined it to be one of the major limitations. \nThe next step is to generate a regression model with Random Forest (RF). Some introductory words about RFRandom Forest are given in subsection 10.0.2. As illustrated in (Pierzyna 2021), RFRandom Forest was able to reproduce the training data reasonably well. However, it faced difficulties to approximate spike-like curves. Once the centroid positions and the two transitions property tensors \\(\\boldsymbol Q\\) and \\(\\boldsymbol T\\) are known, they are passed to CNMCluster-based Network Modeling to calculate the predicted trajectories. For assessing the prediction quality two methods are used, i.e., the autocorrelation and the Cluster Probability Distribution (CPD). CPDCluster Probability Distribution outlines the probability of being on one of the \\(K\\) clusters. The autocorrelation given in equation 4.6 allows comparing two trajectories with a phase-mismatch (Protas, Noack, and Östh 2015) and it measures how well a point in trajectory correlates with a point that is some time steps ahead. The variables in equation 4.6 are denoted as time lag \\(\\tau\\), state space vector \\(\\boldsymbol x\\), time \\(t\\) and the inner product \\((\\boldsymbol x, \\boldsymbol y) = \\boldsymbol x \\cdot \\boldsymbol{y}^T\\). \\[\n\\begin{equation}\n    R(\\tau) = \\frac{1}{T - \\tau} \\int\\limits_{0}^{T-\\tau}\\, (\\boldsymbol{x} (t), \\boldsymbol{x}(t+ \\tau))    dt, \\quad \\tau \\in [\\, 0, \\, T\\,]\n    \\label{eq_35}\n\\end{equation}\n\\tag{4.6}\\]\nFirst CNMc proved to work well for the Lorenz system only for the number of centroids up to \\(K=10\\) and small \\(\\beta\\). Among the points which need to be improved is the method to match the centroids across the chosen \\(\\vec{\\beta}\\). Because of this, two of the major problems occur, i.e., the limitation to 3 dimensions and the behavior of the trajectory must be circular, similar to the Lorenz system (Lorenz 1963). These demands are the main obstacles to the application of first CNMc to all kinds of dynamical systems. The modal decomposition with NMFNon-negative Matrix Factorization is the most computationally intensive part and should be replaced by a faster alternative.\n\n\n\n\nArthur, David, and Sergei Vassilvitskii. 2006. “K-Means++: The Advantages of Careful Seeding.” Stanford.\n\n\nBrunton, Steven L, Joshua L Proctor, and J Nathan Kutz. 2016. “Sparse Identification of Nonlinear Dynamics with Control (SINDYc).” IFAC-PapersOnLine 49 (18): 710–15.\n\n\nFernex, Daniel, Bernd R. Noack, and Richard Semaan. 2021. “Cluster-Based Network Modelingfrom Snapshots to Complex Dynamical Systems.” Science Advances 7 (25). https://doi.org/10.1126/sciadv.abf5006.\n\n\nKaiser, Eurika, Bernd R Noack, Laurent Cordier, Andreas Spohn, Marc Segond, Markus Abel, Guillaume Daviller, Jan Östh, Siniša Krajnović, and Robert K Niven. 2014. “Cluster-Based Reduced-Order Modelling of a Mixing Layer.” Journal of Fluid Mechanics 754: 365–414.\n\n\nKaptanoglu, Alan, Brian De Silva, Urban Fasel, Kadierdan Kaheman, Andy Goldschmidt, Jared Callaham, Charles Delahunt, et al. 2022. “PySINDy: A Comprehensive Python Package for Robust Sparse System Identification.” Journal of Open Source Software 7 (69): 3994. https://doi.org/10.21105/joss.03994.\n\n\nLee, Daniel D, and H Sebastian Seung. 1999. “Learning the Parts of Objects by Non-Negative Matrix Factorization.” Nature 401 (6755): 788–91.\n\n\nLi, Hao, Daniel Fernex, Richard Semaan, Jianguo Tan, Marek Morzyński, and Bernd R Noack. 2021. “Cluster-Based Network Model.” Journal of Fluid Mechanics 906.\n\n\nLorenz, Edward N. 1963. “Deterministic Nonperiodic Flow.” Journal of Atmospheric Sciences 20 (2): 130–41.\n\n\nPierzyna, Maximilian. 2021. “Control-Oriented Cluster-Basednetwork Modeling.” Research report, TU Braunschweig.\n\n\nProtas, Bartosz, Bernd R Noack, and Jan Östh. 2015. “Optimal Nonlinear Eddy Viscosity in Galerkin Models of Turbulent Flows.” Journal of Fluid Mechanics 766: 337–67.\n\n\nSilva, Brian de, Kathleen Champion, Markus Quade, Jean-Christophe Loiseau, J. Kutz, and Steven Brunton. 2020. “PySINDy: A Python Package for the Sparse Identification of Nonlinear Dynamical Systems from Data.” Journal of Open Source Software 5 (49): 2104. https://doi.org/10.21105/joss.02104."
  },
  {
    "objectID": "Data/1_Writing/2_Task/0_Methodlogy.html",
    "href": "Data/1_Writing/2_Task/0_Methodlogy.html",
    "title": "5  Methodology",
    "section": "",
    "text": "In this chapter, the entire pipeline for designing the proposed CNMccontrol-oriented Cluster-based Network Modeling is elaborated. For this purpose, the ideas behind the individual processes are explained. Results from the step tracking onwards will be presented in chapter 11.\nHaving said that, CNMccontrol-oriented Cluster-based Network Modeling consists of multiple main process steps or stages. First, a broad overview of the CNMccontrol-oriented Cluster-based Network Modeling’s workflow shall be given. Followed by a detailed explanation for each major operational step. The implemented process stages are presented in the same order as they are executed in CNMccontrol-oriented Cluster-based Network Modeling. However, CNMccontrol-oriented Cluster-based Network Modeling is not forced to go through each stage. If the output of some steps is already available, the execution of the respective steps can be skipped. \nThe main idea behind such an implementation is to prevent computing the same task multiple times. Computational time can be reduced if the output of some CNMccontrol-oriented Cluster-based Network Modeling steps are available. Consequently, it allows users to be flexible in their explorations. It could be the case that only one step of is desired to be examined with different settings or even with newly implemented functions without running the full CNMccontrol-oriented Cluster-based Network Modeling pipeline. Let the one CNMccontrol-oriented Cluster-based Network Modeling step be denoted as C, then it is possible to skip steps A and B if their output is already calculated and thus available. Also, the upcoming steps can be skipped or activated depending on the need for their respective outcomes. Simply put, the mentioned flexibility enables to load data for A and B and execute only C. Executing follow-up steps or loading their data is also made selectable.    Since the tasks of this thesis required much coding, it is important to mention the used programming language and the dependencies. As for the programming language, Python 3 (Van Rossum and Drake 2009) was chosen. For the libraries, only a few important libraries will be mentioned, because the number of used libraries is high. Note, each used module is freely available on the net and no licenses are required to be purchased. \nThe important libraries in terms of performing actual calculations are\nNumPy (Harris et al. 2020), SciPy (Virtanen et al. 2020), Scikit-learn (Pedregosa et al. 2011), pySindy (Silva et al. 2020; Kaptanoglu et al. 2022), for multi-dimensional sparse matrix management sparse and for plotting only plotly (Inc. 2015) was deployed. One of the reason why plotly is preferred over Matplotlib (Hunter 2007) are post-processing capabilities, which now a re available. Note, the previous  version used Matplotlib* (Hunter 2007), which in this work has been fully replaced by plotly (Inc. 2015). More reasons why this modification is useful and new implemented post-processing capabilities will be given in the upcoming sections.\nFor local coding, the author’s Linux-Mint-based laptop with the following hardware was deployed: CPU: Intel Core i7-4702MQ CPUComputer Processing Unit@ 2.20GHz × 4, RAM: 16GB. The Institute of fluid dynamics of the Technische Universität Braunschweig also supported this work by providing two more powerful computation resources. The hardware specification will not be mentioned, due to the fact, that all computations and results elaborated in this thesis can be obtained by the hardware described above (authors laptop). However, the two provided resources shall be mentioned and explained if CNMccontrol-oriented Cluster-based Network Modeling benefits from faster computers. The first bigger machine is called Buran, it is a powerful Linux-based working station and access to it is directly provided by the chair of fluid dynamics. \nThe second resource is the high-performance computer or cluster available across the Technische Universität Braunschweig Phoenix. The first step, where the dynamical systems are solved through an ODEOrdinary Differential Equation solver is written in a parallel manner. This step can if specified in the settings.py file, be performed in parallel and thus benefits from multiple available cores. However, most implemented ODEOrdinary Differential Equations are solved within a few seconds. There are also some dynamical systems implemented whose ODE solution can take a few minutes. Applying CNMccontrol-oriented Cluster-based Network Modeling on latter dynamical systems results in solving their ODEOrdinary Differential Equations for multiple different model parameter values. Thus, deploying the parallelization can be advised in the latter mentioned time-consuming ODEOrdinary Differential Equations.\nBy far the most time-intensive part of the improved CNMccontrol-oriented Cluster-based Network Modeling is the clustering step. The main computation for this step is done with Scikit-learn (Pedregosa et al. 2011). It is heavily parallelized and the computation time can be reduced drastically when multiple threads are available. Other than that, NumPy and SciPy are well-optimized libraries and are assumed to benefit from powerful computers. In summary, it shall be stated that a powerful machine is for sure advised when multiple dynamical systems with a range of different settings shall be investigated since parallelization is available. Yet executing CNMccontrol-oriented Cluster-based Network Modeling on a single dynamical system, a regular laptop can be regarded as a sufficient tool.\n\n\n\n\nHarris, Charles R., K. Jarrod Millman, Stéfan J. van der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020. “Array Programming with NumPy.” Nature 585 (7825): 357–62. https://doi.org/10.1038/s41586-020-2649-2.\n\n\nHunter, J. D. 2007. “Matplotlib: A 2D Graphics Environment.” Computing in Science & Engineering 9 (3): 90–95. https://doi.org/10.1109/MCSE.2007.55.\n\n\nInc., Plotly Technologies. 2015. “Collaborative Data Science.” Montreal, QC: Plotly Technologies Inc. 2015. https://plot.ly.\n\n\nKaptanoglu, Alan, Brian De Silva, Urban Fasel, Kadierdan Kaheman, Andy Goldschmidt, Jared Callaham, Charles Delahunt, et al. 2022. “PySINDy: A Comprehensive Python Package for Robust Sparse System Identification.” Journal of Open Source Software 7 (69): 3994. https://doi.org/10.21105/joss.03994.\n\n\nPedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.” Journal of Machine Learning Research 12: 2825–30.\n\n\nSilva, Brian de, Kathleen Champion, Markus Quade, Jean-Christophe Loiseau, J. Kutz, and Steven Brunton. 2020. “PySINDy: A Python Package for the Sparse Identification of Nonlinear Dynamical Systems from Data.” Journal of Open Source Software 5 (49): 2104. https://doi.org/10.21105/joss.02104.\n\n\nVan Rossum, Guido, and Fred L. Drake. 2009. Python 3 Reference Manual. Scotts Valley, CA: CreateSpace.\n\n\nVirtanen, Pauli, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, et al. 2020. “SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python.” Nature Methods 17: 261–72. https://doi.org/10.1038/s41592-019-0686-2."
  },
  {
    "objectID": "Data/1_Writing/2_Task/1_0_CNMC_Data.html",
    "href": "Data/1_Writing/2_Task/1_0_CNMC_Data.html",
    "title": "6  CNMc’s data and workflow",
    "section": "",
    "text": "In this section, the 5 main points that characterize CNMccontrol-oriented Cluster-based Network Modeling will be discussed. Before diving directly into CNMccontrol-oriented Cluster-based Network Modeling’s workflow some remarks are important to be made. First, CNMccontrol-oriented Cluster-based Network Modeling is written from scratch, it is not simply an updated version of the described first CNMc in subsection 4.0.1. Therefore, the workflow described in this section for CNMccontrol-oriented Cluster-based Network Modeling will not match that of first CNMc, e.g., first CNMc had no concept of settings.py and it was not utilizing Plotly (Inc. 2015) to facilitate post-processing capabilities. The reasons for a fresh start were given in subsection 4.0.1. However, the difficulty of running first CNMc and the time required to adjust first CNMc such that a generic dynamic system could be utilized were considered more time-consuming than starting from zero. \nSecond, the reader is reminded to have the following in mind. Although it is called pipeline or workflow, CNMccontrol-oriented Cluster-based Network Modeling is not obliged to run the whole workflow. With settings.py file, which will be explained below, it is possible to run only specific selected tasks. The very broad concept of CNMccontrol-oriented Cluster-based Network Modeling was already provided at the beginning of chapter 1. However, instead of providing data of dynamical systems for different model parameter values, the user defines a so-called settings.py file and executes CNMccontrol-oriented Cluster-based Network Modeling. The outcome of CNMccontrol-oriented Cluster-based Network Modeling consists, very broadly, of the predicted trajectories and some accuracy measurements as depicted in figure 1.1 . In the following, a more in-depth view shall be given.\nThe extension of settings.py is a regular Python file. However, it is a dictionary, thus there is no need to acquire and have specific knowledge about Python. The syntax of Python’s dictionary is quite similar to that of the JSON dictionary, in that the setting name is supplied within a quote mark and the argument is stated after a colon. In order to understand the main points of CNMccontrol-oriented Cluster-based Network Modeling, its main data and workflow are depicted 6.1 as an XDSM diagram (Lambe and Martins 2012). \n\n\n\n\n\n\n\nFigure 6.1— general workflow overview\n\n\nThe first action for executing CNMccontrol-oriented Cluster-based Network Modeling is to define settings.py. It contains descriptive information about the entire pipeline, e.g., which dynamical system to use, which model parameters to select for training, which for testing, which method to use for modal decomposition and mode regression. To be precise, it contains all the configuration attributes of all the 5 main CNMccontrol-oriented Cluster-based Network Modeling steps and some other handy extra functions. It is written in a very clear way such that settings to the corresponding stages of CNMccontrol-oriented Cluster-based Network Modeling and the extra features can be distinguished at first glance. First, there are separate dictionaries for each of the 5 steps to ensure that the desired settings are made where they are needed. Second, instead of regular line breaks, multiline comment blocks with the stage names in the center are used. Third, almost every settings.py attribute is explained with comments. Fourth, there are some cases, where a specific attribute needs to be reused in other steps. The user is not required to adapt it manually for all its occurrences, but rather to change it only on the first occasion, where the considered function is defined. Python will automatically ensure that all remaining steps receive the change correctly. Other capabilities implemented in settings.py are mentioned when they are actively exploited. In figure 6.1 it can be observed that after passing settings.py a so-called Informer and a log file are obtained. The Informer is a file, which is designed to save all user-defined settings in settings.py for each execution of CNMccontrol-oriented Cluster-based Network Modeling. Also, here the usability and readability of the output are important and have been formatted accordingly. It proves to be particularly useful when a dynamic system with different settings is to be calculated, e.g., to observe the influence of one or multiple parameters. \nOne of the important attributes which can be arbitrarily defined by the user in settings.py and thus re-found in the Informer is the name of the model. In CNMccontrol-oriented Cluster-based Network Modeling multiple dynamical systems are implemented, which can be chosen by simply changing one attribute in settings.py. Different models could be calculated with the same settings, thus this clear and fast possibility to distinguish between multiple calculations is required. The name of the model is not only be saved in the Informer but it will be used to generate a folder, where all of CNMccontrol-oriented Cluster-based Network Modeling output for this single CNMccontrol-oriented Cluster-based Network Modeling workflow will be stored. The latter should contribute to on the one hand that the CNMccontrol-oriented Cluster-based Network Modeling models can be easily distinguished from each other and on the other hand that all results of one model are obtained in a structured way. \nWhen executing CNMccontrol-oriented Cluster-based Network Modeling many terminal outputs are displayed. This allows the user to be kept up to date on the current progress on the one hand and to see important results directly on the other. In case of unsatisfying results, CNMccontrol-oriented Cluster-based Network Modeling could be aborted immediately, instead of having to compute the entire workflow. In other words, if a computation expensive CNMccontrol-oriented Cluster-based Network Modeling task shall be performed, knowing about possible issues in the first steps can be regarded as a time-saving mechanism. The terminal outputs are formatted to include the date, time, type of message, the message itself and the place in the code where the message can be found. The terminal outputs are colored depending on the type of the message, e.g., green is used for successful computations. Colored terminal outputs are applied for the sake of readability. More relevant outputs can easily be distinguished from others. The log file can be considered as a memory since, in it, the terminal outputs are saved.\nThe stored terminal outputs are in the format as the terminal output described above, except that no coloring is utilized. An instance, where the log file can be very helpful is the following. Some implemented quality measurements give very significant information about prediction reliability. Comparing different settings in terms of prediction capability would become very challenging if the terminal outputs would be lost whenever the CNMccontrol-oriented Cluster-based Network Modeling terminal is closed. The described Informer and the log file can be beneficial as explained, nevertheless, they are optional. That is, both come as two of the extra features mentioned above and can be turned off in settings.py.\nOnce settings.py is defined, CNMccontrol-oriented Cluster-based Network Modeling will filter the provided input, adapt the settings if required and send the corresponding parts to their respective steps. The sending of the correct settings is depicted in figure 6.1, where the abbreviation st stands for settings. The second abbreviation SOP is found for all 5 stages and denotes storing output and plots. All the outcome is stored in a compressed form such that memory can be saved. All the plots are saved as HTML files. There are many reasons to do so, however, to state the most crucial ones. First, the HTML file can be opened on any operating system. In other words, it does not matter if Windows, Linux or Mac is used. Second, the big difference to an image is that HTML files can be upgraded with, e.g., CSS, JavaScript and PHP functions. Each received HTML plot is equipped with some post-processing features, e.g., zooming, panning and taking screenshots of the modified view. When zooming in or out the axes labels are adapted accordingly. Depending on the position of the cursor, a panel with the exact coordinates of one point and other information such as the \\(\\beta\\) are made visible. \nIn the same way that data is stored in a compressed format, all HTML files are generated in such a way that additional resources are not written directly into the HTML file, but a link is used so that the required content is obtained via the Internet.\nOther features associated with HTML plots and which data are saved will be explained in their respective section in this chapter. The purpose of CNMccontrol-oriented Cluster-based Network Modeling is to generate a surrogate model with which predictions can be made for unknown model parameter values \\({\\beta}\\). For a revision on important terminology as model parameter value \\(\\beta\\) the reader is referred to subsection 3.0.1. Usually, in order to obtain a sound predictive model, machine learning methods require a considerable amount of data. Therefore, the ODEOrdinary Differential Equation is solved for a set of \\(\\vec{\\beta }\\). An in-depth explanation for the first is provided in section 7. The next step is to cluster all the received trajectories deploying kmeans++ (Arthur and Vassilvitskii 2006). Once this has been done, tracking can take be performed. Here the objective is to keep track of the positions of all the centroids when \\(\\beta\\) is changed over the whole range of \\(\\vec{\\beta }\\). A more detailed description is given in section 9.\nThe modeling step is divided into two subtasks, which are not displayed as such in figure 6.1 . The first subtask aims to get a model that yields all positions of all the \\(K\\) centroids for an unseen \\(\\beta_{unseen}\\), where an unseen \\(\\beta_{unseen}\\) is any \\(\\beta\\) that was not used to train the model. In the second subtask, multiple tasks are performed. First, the regular CNMCluster-based Network Modeling (Fernex, Noack, and Semaan 2021) shall be applied to all the tracked clusters from the tracking step. For this purpose, the format of the tracked results is adapted in a way such that CNMCluster-based Network Modeling can be executed without having to modify CNMCluster-based Network Modeling itself. By running CNMCluster-based Network Modeling on the tracked data of all \\(\\vec{\\beta }\\), the transition property tensors \\(\\boldsymbol Q\\) and \\(\\boldsymbol T\\) for all \\(\\vec{\\beta }\\) are received. \nSecond, all the \\(\\boldsymbol Q\\) and the \\(\\boldsymbol T\\) tensors are stacked to form \\(\\boldsymbol {Q_{stacked}}\\) and \\(\\boldsymbol {T_{stacked}}\\) matrices. These stacked matrices are subsequently supplied to one of the two possible implemented modal decomposition methods. Third, a regression model for the obtained modes is constructed. Clarifications on the modeling stage can be found in section 10.\nThe final step is to make the actual predictions for all provided \\(\\beta_{unseen}\\) and allow the operator to draw conclusions about the trustworthiness of the predictions. For the trustworthiness, among others, the three quality measurement concepts explained in subsection 4.0.1 are leveraged. Namely, comparing the CNMccontrol-oriented Cluster-based Network Modeling and CNMCluster-based Network Modeling predicted trajectories by overlaying them directly. The two remaining techniques, which were already applied in regular CNMCluster-based Network Modeling (Fernex, Noack, and Semaan 2021), are the Cluster Probability Distribution (CPD) and the autocorrelation.\nThe data and workflow in figure 6.1 do not reveal one additional feature of the implementation of CNMccontrol-oriented Cluster-based Network Modeling. That is, inside the folder Inputs multiple subfolders containing a settings.py file, e.g., different dynamical systems, can be inserted to allow a sequential run. In the case of an empty subfolder, CNMccontrol-oriented Cluster-based Network Modeling will inform the user about that and continue its execution without an error. As explained above, each model will have its own folder where the entire output will be stored. To switch between the multiple and a single settings.py version, the settings.py file outside the Inputs folder needs to be modified. The argument for that is multiple_Settings.\nFinally, one more extra feature shall be mentioned. After having computed expensive models, it is not desired to overwrite the log file or any other output. To prevent such unwanted events, it is possible to leverage the overwriting attribute in settings.py. If overwriting is disabled, CNMccontrol-oriented Cluster-based Network Modeling would verify whether a folder with the specified model name already exists. In the positive case, CNMccontrol-oriented Cluster-based Network Modeling would initially only propose an alternative model name. Only if the suggested model name would not overwrite any existing folders, the suggestion will be accepted as the new model name. Both, whether the model name was chosen in settings.py as well the new final replaced model name is going to be printed out in the terminal line.\nIn summary, the data and workflow of CNMccontrol-oriented Cluster-based Network Modeling are shown in Figure 6.1 and are sufficient for a broad understanding of the main steps. However, each of the 5 steps can be invoked individually, without having to run the full pipeline. Through the implementation of settings.py CNMccontrol-oriented Cluster-based Network Modeling is highly flexible. All settings for the steps and the extra features can be managed with settings.py. A log file containing all terminal outputs as well a summary of chosen settings is stored in a separate file called Informer are part of CNMccontrol-oriented Cluster-based Network Modeling’s tools.\n\n\n\n\nArthur, David, and Sergei Vassilvitskii. 2006. “K-Means++: The Advantages of Careful Seeding.” Stanford.\n\n\nFernex, Daniel, Bernd R. Noack, and Richard Semaan. 2021. “Cluster-Based Network Modelingfrom Snapshots to Complex Dynamical Systems.” Science Advances 7 (25). https://doi.org/10.1126/sciadv.abf5006.\n\n\nInc., Plotly Technologies. 2015. “Collaborative Data Science.” Montreal, QC: Plotly Technologies Inc. 2015. https://plot.ly.\n\n\nLambe, Andrew B., and Joaquim R. R. A. Martins. 2012. “Extensions to the Design Structure Matrix for the Description of Multidisciplinary Design, Analysis, and Optimization Processes.” Structural and Multidisciplinary Optimization 46: 273–84. https://doi.org/10.1007/s00158-012-0763-y."
  },
  {
    "objectID": "Data/1_Writing/2_Task/1_Data_Gen.html",
    "href": "Data/1_Writing/2_Task/1_Data_Gen.html",
    "title": "7  Data generation",
    "section": "",
    "text": "In this section, the first main step of the 5 steps shall be explained. The idea of CNMccontrol-oriented Cluster-based Network Modeling is to create a surrogate model such that predictions for unseen \\(\\beta_{unseen}\\) can be made. An unseen model parameter value \\(\\beta_{unseen}\\) is defined to be not incorporated in the training data. Generally in machine learning, the more linear independent data is available the higher the trustworthiness of the surrogate model is assumed to be. Linear independent data is to be described as data which provide new information. Imagining any million times a million data matrix \\(\\boldsymbol {A_{n\\, x\\, n}}\\), where \\(n = 1 \\mathrm{e}{+6}\\). On this big data matrix \\(\\boldsymbol A\\) a modal decomposition method, e.g., the Singular Value Decomposition (SVD) (Brunton and Kutz 2019; Gerbrands 1981), shall be applied.\nTo reconstruct the original matrix \\(\\boldsymbol A\\) fully with the decomposed matrices only the non-zero modes are required. The number of the non-zero modes \\(r\\) is often much smaller than the dimension of the original matrix, i.e., \\(r &lt;&lt; n\\). If \\(r &lt;&lt; n\\), the measurement matrix \\(\\boldsymbol A\\) contains a high number of linear dependent data. This has the advantage of allowing the original size to be reduced. The disadvantage, however, is that \\(\\boldsymbol A\\) contains duplicated entries (rows, or columns). For this reason, \\(\\boldsymbol A\\) includes data parts which do not provide any new information. In the case of \\(r = n\\) only meaningful observations are comprised and \\(\\boldsymbol A\\) has full rank. Part of feature engineering is to supply the regression model with beneficial training data and filter out redundant copies. The drawback of \\(r = n\\) is observed when the number of representative modes is chosen to be smaller than the full dimension \\(r &lt; n\\). Consequently, valuable measurements could be lost. \nMoreover, if the dimension \\(n\\) is very large, accuracy demands may make working with matrices unavoidable. As a result, more powerful computers are required and the computational time is expected to be increased. For this work, an attempt is made to represent non-linear differential equations by a surrogate model. In addition, trajectories of many \\(\\vec{\\beta }\\) can be handled quite efficiently. Therefore, it attempted to provide sufficient trajectories as training data. Having said that the data and workflow of this step, i.e., data generation, shall be described. The general overview is depicted in figure 7.1 . Data generation corresponding settings are passed to its step, which invokes the ODEOrdinary Differential Equation solver for the range of selected \\(\\vec{\\beta}\\). The trajectories are plotted and, both, all the obtained trajectories \\(F_(\\vec{\\beta})\\) and their plots are saved. Note that \\(\\vec{\\beta}\\) indicates that one differential equation is solved for selected \\(\\beta\\) values within a range of model parameter values \\(\\vec{\\beta}\\).\n\n\n\nFigure 7.1— Data and workflow of the first step: Data generation\n\n\nA detailed description will be given in the following. First, in order to run this task, it should be activated in settings.py. Next, the user may change local output paths, define which kind of plots shall be generated, which dynamical model should be employed and provide the range \\(\\vec{\\beta}\\). As for the first point, the operator can select the path where the output of this specific task shall be stored. Note, that this is an optional attribute. Also, although it was only tested on Linux, the library pathlib was applied. Therefore, if the output is stored on a Windows or Mac-based operating system, which uses a different path system, no errors are expected. \nRegarding the types of plots, first, for each type of plot, the user is enabled to define if these plots are desired or not. Second, all the plots are saved as HTML files. Some reasons for that were provided at the beginning of this chapter and others which are important for trajectory are the following. With in-depth explorations in mind, the user might want to highlight specific regions in order to get detailed and correct information. For trajectories, this can be encountered when e.g., coordinates of some points within a specified region shall be obtained. Here zooming, panning, rotation and a panel that writes out additional information about the current location of the cursor can be helpful tools. The first type of plot is the trajectory itself with the initial condition as a dot in the state-space.\nIf desired, arrows pointing in the direction of motion of the trajectory can be included in the plots. The trajectory, the initial state sphere and the arrows can be made invisible by one click on the legend if desired. The second type of representation is an animated plot, i.e., each trajectory \\(F(\\beta)\\) is available as the animated motion. The final type of display is one plot that contains all \\(F(\\vec{\\beta})\\) as a sub-figure. The latter type of visualization is a very valuable method to see the impact of \\(\\beta\\) across the available \\(\\vec{\\beta }\\) on the trajectories \\(F(\\vec{\\beta})\\). Also, it can be leveraged as fast sanity check technique, i.e., if any \\(F(\\beta )\\) is from expectation, this can be determined quickly by looking at the stacked trajectory plots. \nIf for presentation HTML files are not desired, clicking on a button will provide a png image of the current view state of the trajectory. Note, that the button will not be on the picture. Finally, modern software, especially coding environments, understood that staring at white monitors is eye-straining. Consequently, dark working environments are set as default. For this reason, all the mentioned types of plots have a toggle implemented. It allows switching between a dark default and a white representation mode.\nFor choosing a dynamical system, two possibilities are given. On the one hand, one of the 10 incorporated models can be selected by simply selecting a number, which corresponds to an integrated dynamical system. On the other hand, a new dynamical system can be implemented. This can be achieved without much effort by following the syntax of one of the 10 available models. The main adjustment is done by replacing the ODEOrdinary Differential Equation. The differential equations of all 10 dynamic systems that can be selected by default are given in equations 7.1 to 7.7 and the 3 sets of equations A.1 to A.3 are found the Appendix. The latter 3 sets of equations are provided in the Appendix because they are not used for validating CNMccontrol-oriented Cluster-based Network Modeling prediction performance. Next to the model’s name, the reference to the dynamical system can be seen. The variables \\(a\\) and \\(b\\) are constants. Except for the Van der Pol, which is given in the Appendix A as equation A.3, all dynamical systems are 3-dimensional .\n\n\n\nLorenz (Lorenz 1963): \\[\n    \\begin{equation}\n        \\label{eq_6_Lorenz}\n        \\begin{aligned}\n            \\dot x &= a\\, (y - x)  \\\\\n            \\dot y &= x\\, (\\beta - z -y) \\\\\n            \\dot z &= x y -\\beta z\n        \\end{aligned}\n    \\end{equation} \\tag{7.1}\\]\nRössler (Rössler 1976): \\[\n    \\begin{equation}\n        \\label{eq_7_Ross}\n        \\begin{aligned}\n            \\dot x &= -y -z \\\\\n            \\dot y &= x + ay \\\\\n            \\dot z &= b +z \\, (x-\\beta)\\\\\n        \\end{aligned}\n    \\end{equation} \\tag{7.2}\\]\n\n\nTwo Scroll (Vaidyanathan et al. 2019): \\[\n    \\begin{equation}\n        \\label{eq_9_2_Scroll}\n        \\begin{aligned}\n            \\dot x &= \\beta \\, (y-x) \\\\\n            \\dot y &= x z \\\\\n            \\dot z &= a - by^4\n        \\end{aligned}\n        \\end{equation} \\tag{7.3}\\]\n\nFour Wing (Li et al. 2015): \\[\n    \\begin{equation}\n        \\label{eq_10_4_Wing}\n        \\begin{aligned}\n            \\dot x &= \\beta x +y +yz\\\\\n            \\dot y &= yz - xz \\\\\n            \\dot z &= a + bxy -z\n        \\end{aligned}\n    \\end{equation} \\tag{7.4}\\]\n\n\nSprott_V_1 (SPROTT 2020): \\[\n    \\begin{equation}\n        \\label{eq_11_Sprott_V_1}\n        \\begin{aligned}\n            \\dot x &= y \\\\\n            \\dot y &= -x - sign(z)\\,y\\\\\n            \\dot z &= y^2 - exp(-x^2) \\, \\beta\n        \\end{aligned}\n    \\end{equation} \\tag{7.5}\\]\n\n\nTornado (SPROTT 2020): \\[\n    \\begin{equation}\n        \\label{eq_12_Tornado}\n        \\begin{aligned}\n            \\dot x &= y \\, \\beta \\\\\n            \\dot y &= -x - sign(z)\\,y\\\\\n            \\dot z &= y^2 - exp(-x^2)\n        \\end{aligned}\n    \\end{equation} \\tag{7.6}\\]\n\n\nInsect (SPROTT 2020): \\[\n    \\begin{equation}\n        \\label{eq_13_Insect}\n        \\begin{aligned}\n            \\dot x &= y \\\\\\\n            \\dot y &= -x - sign(z)\\,y \\, \\beta\\\\\n            \\dot z &= y^2 - exp(-x^2)\n        \\end{aligned}\n    \\end{equation} \\tag{7.7}\\]\n\n\n\nSprott_V_1, Tornado and Insect in equations 7.5 to 7.7 are not present in the cited reference (SPROTT 2020) in this expressed form. The reason is that the introduced equations are a modification of the chaotic attractor proposed in (SPROTT 2020). The curious reader is invited to read (SPROTT 2020) and to be convinced about the unique properties. The given names are made up and serve to distinguish them. Upon closer inspection, it becomes clear that they differ only in the place where \\(\\beta\\) is added. All 3 models are highly sensitive to \\(\\beta\\), i.e., a small change in \\(\\beta\\) results in bifurcations. For follow-up improvements of CNMccontrol-oriented Cluster-based Network Modeling, these 3 systems can be applied as performance benchmarks for bifurcation prediction capability.\nShowing the trajectories of all 10 models with different \\(\\vec{\\beta}\\) would claim too much many pages. Therefore, for demonstration purposes the 3 above-mentioned models, i.e., Sprott_V_1, Tornado and Insect are displayed in figures 7.2 to 7.8 . Figure 7.2 depicts the dynamical system Sprott_V_1 7.5 with \\(\\beta =9\\). Figures 7.3 to 7.5 presents the Tornado 7.6 with \\(\\beta =16.78\\) with 3 different camera perspectives. Observing these figures, the reader might recognize why the name Tornado was chosen. The final 3 figures 7.6 to 7.8 display the Insect 7.7 with \\(\\beta =7\\) for 3 different perspectives. Other default models will be displayed in subsection 16.0.2, as they were used for performing benchmarks . \n\n\n\n\n\n\nFigure 7.2— Default model: Sprott_V_1 7.5 with \\(\\beta =9\\)\n\n\n\n\n\n\n\nFigure 7.3— Default model: Tornado 7.6 with \\(\\beta =16.78\\), view: 1\n\n\n\n\n\nFigure 7.4— Default model: Tornado 7.6 with \\(\\beta =16.78\\), view: 2\n\n\n\n\n\n\n\n\n\nFigure 7.5— Default model: Tornado 7.6 with \\(\\beta =16.78\\), view: 3\n\n\n\n\n\nFigure 7.6— Default model: Insect 7.7 with \\(\\beta =7\\), view: 1\n\n\n\n\n\n\n\n\n\nFigure 7.7— Default model: Insect 7.7 with \\(\\beta =7\\), view: 2\n\n\n\n\n\nFigure 7.8— Default model: Insect 7.7 with \\(\\beta =7\\), view: 3\n\n\n\n\n\n\n\nHaving selected a dynamical system, the model parameter values for which the system shall be solved must be specified in settings.py. With the known range \\(\\vec{\\beta}\\) the problem can be described, as already mentioned in subsection 3.0.1, with equation 3.2 .\n\\[\n\\begin{equation}\n    F_{CNMc} = \\left(\\dot{\\vec{x}}(t), \\, \\vec{\\beta} \\right) =\n    \\left( \\frac{\\vec{x}(t)}{dt}, \\, \\vec{\\beta} \\right) =\n     f(\\vec{x}(t), \\, \\vec{\\beta} )\n     \\tag{3.2}\n\\end{equation}\\]\nThe solution to 3.2 is obtained numerically by applying SciPy’s RK45 ODEOrdinary Differential Equation solver. If desired CNMccontrol-oriented Cluster-based Network Modeling allows completing this task in parallel. Additional notes on executing this task in parallel are given in section 2. The main reason for relying on RK45 is that it is commonly known to be a reliable option. Also, in (Butt 2021) RK45 was directly compared with LSODA. The outcome was that LSODA was slightly better, however, the deviation between RK45’s and LSODA’s performance was found to be negligible. In other words, both solvers fulfilled the accuracy demands. Since chaotic systems are known for their Sensitive  Dependence on Initial Conditions (SDIC) any deviation, even in the \\(\\mathcal{O} (1 \\mathrm{e}{-15})\\), will be amplified approximately exponentially and finally will become unacceptably high. Therefore, it was tested, whether the RK45 solver would allow statistical variations during the solution process. For this purpose, the Lorenz system (Lorenz 1963) was solved multiple times with different time ranges. The outcome is that RK45 has no built-in statistical variation. Simply put, the trajectory of the Lorenz system for one constant \\(\\beta\\) will not differ when solved multiple times on one computer.\nComparing first CNMc and CNMccontrol-oriented Cluster-based Network Modeling the key takeaways are that CNMccontrol-oriented Cluster-based Network Modeling has 10 in-built dynamical systems. However, desiring to implement a new model is also achieved in a way that is considered relatively straightforward. Important settings, such as the model itself, the \\(\\vec{\\beta }\\), plotting and storing outcome can be managed with the settings.py. The plots are generated and stored such that post-processing capabilities are supplied.\n\n\n\n\nBrunton, Steven, and J Kutz. 2019. “Data-Driven Science and Engineering.” Cambridge University Press. https://doi.org/10.1017/9781108380690.\n\n\nButt, Javed. 2021. “Development of a Module for Mission Analysis for a Gradient-Based Aerodynamic Shape Optimization Process.” TU Braunschweig. https://elib.dlr.de/144285/.\n\n\nGerbrands, Jan J. 1981. “On the Relationships Between SVD, KLT and PCA.” Pattern Recognition 14 (1-6): 375–81.\n\n\nLi, Chunbiao, Ihsan Pehlivan, Julien Clinton Sprott, and Akif Akgul. 2015. “A Novel Four-Wing Strange Attractor Born in Bistablity.” IEICE Electronics Express 12 (February). https://doi.org/10.1587/elex.12.20141116.\n\n\nLorenz, Edward N. 1963. “Deterministic Nonperiodic Flow.” Journal of Atmospheric Sciences 20 (2): 130–41.\n\n\nRössler, O. E. 1976. “An Equation for Continuous Chaos.” Physics Letters A 57 (5): 397–98. https://doi.org/https://doi.org/10.1016/0375-9601(76)90101-8.\n\n\nSPROTT, Julien. 2020. “Do We Need More Chaos Examples?” Chaos Theory and Applications 2 (2): 49–51.\n\n\nVaidyanathan, Sundarapandian, Aceng Sambas, Sen Zhang, Yicheng Zeng, Mohamad Afendee Mohamed, and Mustafa Mamat. 2019. “A New Two-Scroll Chaotic System with Two Nonlinearities: Dynamical Analysis and Circuit Simulation.” Telkomnika 17 (5): 2465–74."
  },
  {
    "objectID": "Data/1_Writing/2_Task/2_Clustering.html",
    "href": "Data/1_Writing/2_Task/2_Clustering.html",
    "title": "8  Clustering",
    "section": "",
    "text": "In this section, the second step, the clustering of all trajectories \\((\\vec{\\beta})\\), is explained. The main idea is to represent \\(F(\\vec{\\beta})\\) through movement on centroids. The data and workflow of clustering are very similar to the previous step of the data generation. It can be comprehended with figure 8.1 . All settings for this step can be individually configured in settings.py. The \\(F(\\vec{\\beta})\\) and cluster-algorithm specific parameters are filtered and provided to the clustering algorithm. The solutions are plotted and both, the plots and the clustered output are saved.\n\n\n\n\n\n\nFigure 8.1— Data and workflow of the second step: Clustering\n\n\nData clustering is an unsupervised machine learning technique. There are a variety of approaches that may be used for this, e.g., k-means, affinity propagation, mean shift, spectral clustering and Gaussian mixtures. All the methods differ in their use cases, scalability,\nmetric or deployed norm and required input parameters. The latter is an indicator of customization abilities. Since k-means can be used for very large data sets and enables easy and fast implementation, k-means is preferred. Furthermore, David Arthur et al.  (Arthur and Vassilvitskii 2006) introduced k-means++, which is known to outperform k-means. Therefore, CNMccontrol-oriented Cluster-based Network Modeling uses k-means++ as its default method for data clustering. Note, applying k-means++ is not new in CNMccontrol-oriented Cluster-based Network Modeling, but it was already applied in the regular CNMCluster-based Network Modeling (Fernex, Noack, and Semaan 2021).\nIn order to cover the basics of k-means and k-means++, two terms should be understood. Picturing a box with 30 points in it, where 10 are located on the left, 10 in the middle and 10 on the right side of the box. Adhering to such a constellation, it is appealing to create 3 groups, one for each overall position (left, center and right). Each group would contain 10 points. These groups are called clusters and the geometrical center of each cluster is called a centroid. A similar thought experiment is visually depicted in (“K-Means Finding Set of Initial Points,” n.d.). Considering a dynamical system, the trajectory is retrieved by integrating the ODEOrdinary Differential Equation numerically at discrete time steps. For each time step the obtained point is described with one x-, y- and z-coordinate. Applying the above-mentioned idea on, e.g., the Lorenz system (Lorenz 1963), defined as the set of equations in 7.1, then the resulting centroids can be seen in figure 8.2 . The full domains of the groups or clusters are color-coded in figure 8.3 .\n\n\n\n\n\nFigure 8.2— Centroids of the Lorenz system 7.1 with \\(\\beta =28\\)\n\n\n\n\n\nFigure 8.3— Cluster domains of the Lorenz system 7.1 with \\(\\beta =28\\)\n\n\n\n\nTheoretically, the points which are taken to calculate a center could be assigned weighting factors. However, this is not done in CNMccontrol-oriented Cluster-based Network Modeling and therefore only be outlined as a side note. After being familiar with the concept of clusters and centroids, the actual workflow of k-means shall be explained. For initializing k-means, a number of clusters and an initial guess for the centroid positions must be provided. Next, the distance between all the data points and the centroids is calculated. The data points closest to a centroid are assigned to these respective clusters. In other words, each data point is assigned to that cluster for which the corresponding centroid exhibits the smallest distance to the considered data point. The geometrical mean value for all clusters is subsequently determined for all cluster-associated residents’ data points. With the new centroid positions, the clustering is performed again. \nCalculating the mean of the clustered data points (centroids) and performing clustering based on the distance between each data point and the centroids is done iteratively. The iterative process stops when the difference between the prior and current centroids position is equal to zero or satisfies a given threshold. Other explanations with pseudo-code and\nvisualization for better understanding can be found(Frochte 2020) and (“K-Means Finding Set of Initial Points,” n.d.), respectively\n\n\n\nMathematically k-means objective can be expressed as an optimization problem with the centroid position \\(\\boldsymbol{\\mu_j}\\) as the design variable. That is given in equation 8.1 (extracted from (Frochte 2020)), where \\(\\boldsymbol{\\mu_J}\\) and \\(\\mathrm{D}^{\\prime}_j\\) denote the centroid or mean of the jth cluster and the data points belonging to the jth cluster, respectively. The distance between all the jth cluster data points and its corresponding jth centroid is stated as \\(\\mathrm{dist}(\\boldsymbol{x}_j, \\boldsymbol{\\mu}_j)\\).\n\\[\n\\begin{equation}\n    \\label{eq_1_k_means}\n    \\underset{\\boldsymbol{\\mu}_j}{\\mathrm{argmin}}\\sum_{j=1}^k \\; \\sum_{\\boldsymbol{x}_j \\in \\mathrm{D}^{\\prime}_j }\n    \\mathrm{dist}(\\boldsymbol{x}_j, \\boldsymbol{\\mu_j})\n\\end{equation}\n\\tag{8.1}\\]\nUsually, the k-means algorithm is deployed with a Euclidean metric and equation 8.1 becomes 8.2, which is known as the Lloyd algorithm (Frochte 2020; Lloyd 1982). The Lloyd algorithm can be understood as the minimization of the variance. Thus, it is not necessarily true that k-means is equivalent to reducing the variance. It is only true when the Euclidean norm is used. \\[\n\\begin{equation}\n    \\label{eq_2_k_Means_Ly}\n    \\underset{\\boldsymbol{\\mu}_j}{\\mathrm{argmin}}\\sum_{j=1}^k \\; \\sum_{\\boldsymbol{x}_j \\in \\mathrm{D}^{\\prime}_j }\n    \\| \\boldsymbol x_j - \\boldsymbol{\\mu_j} \\|^2\n\\end{equation}\n\\tag{8.2}\\]\nThe clustering algorithm highly depends on the provided initial centroids positions. Since in most cases, these are guessed, there is no guarantee of a reliable outcome. Sergei Vassilvitskii, one of the founders of k-means++, says in one of his presentations (“K-Means++ Visual Explanation,” n.d.), finding a good set of initial points would be black art. Arthur et al. (Arthur and Vassilvitskii 2006) state, that the speed and simplicity of k-means would be appealing, not its accuracy. There are many natural examples for which the algorithm generates arbitrarily bad clusterings (Arthur and Vassilvitskii 2006).\nAn alternative or improved version of k-means is the already mentioned k-means++, which only differs in the initialization step. Instead of providing initial positions for all centroids, just one centroid’s position is supplied. The remaining are calculated based on maximal distances. In concrete, the distance between all data points and the existing centroids is computed. The data point which exhibits the greatest distance is added to the list of collected centroids. This is done until all \\(k\\) clusters are generated. A visual depiction of this process is given by Sergei Vassilvitskii in (“K-Means Finding Set of Initial Points,” n.d.). Since the outcome of k-means++ is more reliable than k-means, k-means++ is deployed in CNMccontrol-oriented Cluster-based Network Modeling.\nAfter having discussed some basics of k-means++, it shall be elaborated on how and why the solution of the dynamical system should be clustered. The solution of any dynamical system returns a trajectory. If the trajectory repeats itself or happens to come close to prior trajectories without actually touching them,\ncharacteristic sections can be found. Each characteristic section in the phase space is captured by a centroid. The movement from one centroid to another is supposed to portray the original trajectory. With a clustering algorithm, these representative characteristic locations in the phase space are obtained. Since the clusters shall capture an entire trajectory, it is evident that the number of clusters is an essential parameter to choose. Latter fact becomes even more clear when recalling that a trajectory can be multi-modal or complex.\nIn the case of a highly non-linear trajectory, it is obvious that many clusters are demanded in order to minimize the loss of the original trajectories. The projection of the real trajectory to a cluster-based movement can be compared to a reduced-order model of the trajectory. In this context, it is plausible to refer to the centroids as representative characteristic locations. Furthermore, CNMCluster-based Network Modeling and thus, CNMccontrol-oriented Cluster-based Network Modeling, exploits graph theory. Therefore, the centroids can be denoted as nodes or characteristic nodes.\nThe remaining part of this section will be devoted exclusively to the application of CNMccontrol-oriented Cluster-based Network Modeling. First, the leveraged kmeans++ algorithm is from the machine learning Python library Scikit-learn (Pedregosa et al. 2011). Crucial settings, e.g., the number of clusters \\(K\\), the maximal number of iterations, the tolerance as a convergence criterion and the number of different centroid seeds with which k-means is executed. The operator can decide if the clustering step shall be performed or skipped. The path for outputs can be modified and generating plots is also optional. For the clustering stage, there are 4 types of plots available. Two types of plots are depicted in figures 8.2 and 8.3 . With the generated HTML plots the same features as described in section 7 are available, e .g., receiving more information through pop-up panels and switching between a dark and white mode. \nThe other two types of charts are not displayed here because they are intended to be studied as HTML graphs where the output can be viewed from multiple angles. The first type shows the clustered output of one system for two different \\(\\beta\\) next to each other. The centroids are labeled randomly as will be shown in subsection 8.0.1. Consequently, the centroids representing the immediate neighbors across the two separate \\(\\beta\\) have separate labels. In the second remaining type of HTML graph, the closest centroids across the two different \\(\\beta\\) are connected through lines. Also, in the same way, as it was done for the first step in the data generation an additional HTML file containing all \\(\\vec{\\beta }\\) charts is generated. \nIt can be concluded that the clustering step is performed by employing Scikit-learn’s kmeans++ implementation, which is well suited for a great number of points. As usual, all important settings can be controlled with settings.py.\n\n8.0.1 Parameter Study\nIn this subsection, the effects on the clustering step caused by the parameter n_init shall be named. After that, the random labeling of the centroids is to be highlighted. With the parameter n_init it is possible to define how often the k-means algorithm will be executed with different centroid seeds (Pedregosa et al. 2011). For a reliable clustering quality n_init should be chosen high. However, the drawback is that with increasing n_init the calculation time increases unacceptably high. Having chosen n_init too high, the clustering part becomes the new bottleneck of the entire CNMccontrol-oriented Cluster-based Network Modeling pipeline. \nTo conduct the parameter study, clustering was performed using the following n_init values: \\(\\textit{n\\_init} = \\{100,\\, 200, \\, 400,\\, 800,\\, 1000, \\, 1200, \\, 1500 \\}\\). Some results are presented in figures 8.4 to 8.9 . It can be observed that when all the different n_init values are compared, visually no big difference in the placing of the centroids can be perceived. A graphical examination is sufficient because even with n_init values that differ by only by the number one (\\(n_{init,1} - n_{init,2} = 1\\)), the centroid positions are still expected to vary slightly. Simply put, only deviations on a macroscopic scale, which can be noted visually are searched for. As a conclusion it can be said that \\(\\textit{n\\_init} = 100\\) and \\(\\textit{n\\_init} = 1500\\) can be considered as an equally valuable clustering outcome. Hence, n_init the computational expense can be reduced by deciding on a reasonable small value for n_init.\nThe second aim of this subsection was to highlight the fact that the centroids are labeled randomly. For this purpose, the depicted figures 8.4 to 8.9 shall be examined. Concretely, any of the referred figures can be compared with the remaining figures to be convinced that the labeling is not obeying any evident rule.\n\n\n\n\n\n\n\n\nFigure 8.4— Lorenz 7.1, \\(\\beta =28\\), \\(\\text{n\\_init}= 100\\)\n\n\n\n\n\nFigure 8.5— Lorenz 7.1, \\(\\beta =28\\), \\(\\text{n\\_init}= 200\\)\n\n\n\n\n\n\n\n\n\nFigure 8.6— Lorenz 7.1, \\(\\beta =28\\), \\(\\text{n\\_init}= 400\\)\n\n\n\n\n\nFigure 8.7— Lorenz 7.1, \\(\\beta =28\\), \\(\\text{n\\_init}= 1000\\)\n\n\n\n\n\n\n\n\n\nFigure 8.8— Lorenz 7.1, \\(\\beta =28\\), \\(\\text{n\\_init}= 1200\\)\n\n\n\n\n\nFigure 8.9— Lorenz 7.1, \\(\\beta =28\\), \\(\\text{n\\_init}= 1500\\)\n\n\n\n\n\n\n\n\n\n\n\nArthur, David, and Sergei Vassilvitskii. 2006. “K-Means++: The Advantages of Careful Seeding.” Stanford.\n\n\nFernex, Daniel, Bernd R. Noack, and Richard Semaan. 2021. “Cluster-Based Network Modelingfrom Snapshots to Complex Dynamical Systems.” Science Advances 7 (25). https://doi.org/10.1126/sciadv.abf5006.\n\n\nFrochte, Jörg. 2020. Maschinelles Lernen. Carl Hanser Verlag GmbH & Co. KG. https://doi.org/10.3139/9783446463554.\n\n\n“K-Means Finding Set of Initial Points.” n.d. https://theory.stanford.edu/~sergei/slides/BATS-Means.pdf.\n\n\n“K-Means++ Visual Explanation.” n.d. https://theory.stanford.edu/~sergei/slides/BATS-Means.pdf.\n\n\nLloyd, Stuart. 1982. “Least Squares Quantization in PCM.” IEEE Transactions on Information Theory 28 (2): 129–37.\n\n\nLorenz, Edward N. 1963. “Deterministic Nonperiodic Flow.” Journal of Atmospheric Sciences 20 (2): 130–41.\n\n\nPedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.” Journal of Machine Learning Research 12: 2825–30."
  },
  {
    "objectID": "Data/1_Writing/2_Task/3_Tracking.html",
    "href": "Data/1_Writing/2_Task/3_Tracking.html",
    "title": "9  Tracking",
    "section": "",
    "text": "In this section, it is the pursuit to explain the third step, tracking, by initially answering the following questions. What is tracking, why is it regarded to be complex and why is it important? In the subsection 9.0.1 the final workflow will be elaborated . Furthermore, a brief discussion on the advancements in tracking of CNMccontrol-oriented Cluster-based Network Modeling to first CNMc shall be given. Since the data and workflow of tracking are extensive, for the sake of a better comprehension the steps are visually separated with two horizontal lines in the upcoming subsection. The lines introduce new tracking subtasks, which are intended to provide clear guidance to orient readers within the workflow. Note, the tracking results will be presented in subsection 12. \nTo define the term tracking some explanations from subsection 4.0.1 shall be revisited . Through the clustering step, each centroid is defined with a label. The label allocation is performed randomly as showed in subsection 8.0.1. Thus, matching centroid labels from one model parameter value \\(\\beta_i\\) to another model parameter value \\(\\beta_j\\), where \\(i \\neq j\\), becomes an issue. In order first, to understand the term tracking, figure 9.1 shall be considered. The centroids of the Lorenz system 7.1 for two \\(\\beta\\) values \\(\\beta_i = 31.333\\) in green and \\(\\beta_j = 32.167\\) in yellow are plotted next to each other. The objective is to match each centroid of \\(\\beta_i\\) with one corresponding centroid of \\(\\beta _j\\). It is important to understand that the matching must be done across the two \\(\\beta\\) values \\(\\beta_i\\) and \\(\\beta_j\\) and not within the same \\(\\beta\\).\n\n\n\n\n\n\nFigure 9.1— Unrealistic tracking example for the Lorenz system with \\(\\beta_i=31.333, \\, \\beta_j=32.167, \\, K = 10\\)\n\n\nBy inspecting the depicted figure closer it can be observed that each green centroid \\(\\beta_i\\) has been connected with a corresponding yellow centroid \\(\\beta_j\\) with an orange line. The centroids which are connected through the orange lines shall be referred to as inter \\(\\beta\\) connected centroids. Determining the inter \\(\\beta\\) connected centroids is the outcome of tracking. Thus, it is matching centroids across different model parameter values \\(\\beta\\) based on their corresponding distance to each other. The closer two inter \\(\\beta\\) centroids are, the more likely they are to be matched. The norm for measuring distance can be chosen from one of the 23 possible norms defined in SciPy (Virtanen et al. 2020). However, the default metric is the euclidean norm which is defined as equation 9.1 .\n\\[\n\\begin{equation}\n     \\label{eq_16}\n     d(\\vec x, \\vec y) = \\sqrt[]{\\sum_{i=1}^n \\left(\\vec{x}_i - \\vec{y}_i\\right)^2}\n\\end{equation} \\tag{9.1}\\]\nThe orange legend on the right side of figure 9.1 outlines the tracked results. In this rare and not the general case, the inter \\(\\beta\\) labeling is straightforward in two ways. First, the closest centroids from \\(\\beta_i\\) to \\(\\beta_j\\) have the same label. Generally, this is not the case, since the centroid labeling is assigned randomly. Second, the inter \\(\\beta\\) centroid positions can be matched easily visually. Ambiguous regions, where visually tracking is not possible, are not present. To help understand what ambiguous regions could look like, figure 9.2 shall be viewed. It illustrates the outcome of the Lorenz system 7.1 with \\(\\beta_i=39.004,\\, \\beta_j = 39.987\\) and with a number of centroids of \\(K= 50\\). Overall, the tracking seems to be fairly obvious, but paying attention to the centroids in the center, matching the centroids becomes more difficult. This is a byproduct of the higher number of centroids \\(K\\). With more available centroids, more centroids can fill a small area. As a consequence, multiple possible reasonable matchings are allowed. Note, that due to spacing limitations, not all tracking results are listed in the right orange legend of figure 9.2 . The emergence of such ambiguous regions is the main driver why tracking is considered to be complex.\n\n\n\nFigure 9.2— Ambiguous regions in the tracking example for the Lorenz system with \\(\\beta_i=39.004,\\, \\beta_j = 39.987,\\, K= 50\\)\n\n\nIn general, it can be stated that the occurrence of ambiguous regions can be regulated well with the number of centroids \\(K\\). \\(K\\) itself depends on the underlying dynamical system. Thus, \\(K\\) should be only as high as required to capture the complexity of the dynamical system. Going above that generates unnecessary many centroids in the state space. Each of them increases the risk of enabling ambiguous regions to appear. Consequently, incorrect tracking results can arise.\nIn figure 9.3 a second example of tracked outcome for the Lorenz system 7.1 with \\(\\beta_i=30.5,\\, \\beta_j=31.333, \\, K = 10\\) is given. Here it can be inspected that the immediate inter \\(\\beta\\) centroid neighbors do not adhere to the same label. Hence, it is representative of a more general encountered case. The latter is only true when the \\(K\\) is chosen in a reasonable magnitude. The reason why centroids are tracked by employing distance measurements is grounded in the following. If the clustering parameter n_init is chosen appropriately (see 8.0.1), the position of the centroids are expected to change only slightly when \\(\\beta\\) is changed . In simpler terms, a change in \\(\\beta\\) should not move a centroid much, if the clustering step was performed satisfactorily in the first place.\n\n\n\nFigure 9.3— Realistic tracking example for the Lorenz system with \\(\\beta_i=30.5\\) and \\(\\beta_j=31.333\\)\n\n\nThe next point is to answer the question, of why tracking is of such importance to CNMccontrol-oriented Cluster-based Network Modeling. The main idea of CNMccontrol-oriented Cluster-based Network Modeling is to approximate dynamical systems and allow prediction trajectories for unseen \\(\\beta_{unseen}\\). The motion, i.e., the trajectory, is replicated by the movement from one centroid to another centroid. Now, if the centroids are labeled wrong, the imitation of the motion is wrong as well. For instance, the considered dynamical system is only one movement from left to right. For instance, imagining a dynamical system, where the trajectory is comprised of solely one movement. Namely, moving from left to right. Following that, labeling the left centroid \\(c_l\\) to be the right centroid \\(c_r\\), would fully change the direction of the movement, i.e. \\((c_l \\rightarrow c_r) \\neq (c_r \\rightarrow c_l)\\). In one sentence, the proper tracking is vital because otherwise CNMccontrol-oriented Cluster-based Network Modeling cannot provide reliably predicted trajectories. \n\n9.0.1 Tracking workflow\nIn this subsection, the main objective is to go through the designed tracking workflow. As side remarks, other attempted approaches to tracking and the reason for their failure will be mentioned briefly.\nTo recapitulate on the term tracking, it is a method to match centroids across a set of different model parameter values \\(\\vec{\\beta}\\) based on their respective distances. One obvious method for handling this task could be KNNKNearest Neighbor. However, having implemented it, undesired results were encountered. Namely, one centroid label could be assigned to multiple centroids within the same \\(\\beta\\). The demand for tracking, on the hand, is that, e.g., with \\(K=10\\), each of the 10 available labels is found exactly once for one \\(\\beta\\). Therefore, it can be stated that KNNKNearest Neighbor is not suitable for tracking, as it might not be possible to impose KNNKNearest Neighbor to comply with the tracking demand.\nThe second approach was by applying DTWDynamical Time Warping. The conclusion is that DTW’s tracking results highly depended on the order in which the inter \\(\\beta\\) distances are calculated. Further, it can be stated that DTW needs some initial wrong matching before the properly tracked outcomes are provided. The initial incorrect matching can be seen as the reason, why DTW is mostly used when very long signals, as in speech recognition, are provided. In these cases, some mismatching is tolerated. For CNMccontrol-oriented Cluster-based Network Modeling, where only a few \\(K\\) centroids are available, a mismatch is strongly unwelcome.\nThe third method was based on the sequence of the labels. The idea was that the order of the movement from one centroid to another centroid is known. In other terms, if the current position is at centroid \\(c_i\\) and the next position for centroid \\(c_{i+1}\\) is known. Assuming that the sequences across the \\(\\vec{\\beta}\\) should be very similar to each other, a majority vote should return the correct tracking results. It can be recorded that this was not the case and the approach was dismissed.\nAfter having explained 3 methods, which did not lead to a satisfactory outcome, the data and workflow of the final successful approach shall be presented. First very concisely, followed by an in-depth account. For that, figure 9.4 shall be analyzed. The initial input is obtained through settings.py, where execution, storage and plotting attributes are defined. For the further sub-steps, it shall be noted that the index big O stands for output of the respective sub-step. The clustered results from step two, described in section 8 are used as input for the so-called ordering step. The ordered state can be stored and plotted if desired and exploited to calculate a cost matrix \\(\\boldsymbol A (\\vec{\\beta})\\). \n\n\n\nFigure 9.4— General data and workflow overview of the third step, tracking\n\n\nThe tracking demand is applied on \\(\\boldsymbol A (\\vec{\\beta})\\), e.g., each row element must be matched to exactly one column element with the constraint that their additive sum is minimized. It will return a suggested best path, i.e., the proposed optimized tracking path. It is possible that the proposed optimized tracking path may not be feasible concerning a linking condition, it undergoes a validity check. If required the suggested path will be chopped off and replaced such that the linking condition is met. The final path is then imposed to a transition such that the centroid labeling across all available \\(\\vec{\\beta}\\) matches. The transformed final paths are designated as the tracked outcome and can be saved and plotted.\nSince the fast description leaves some open questions, the in-depth explanation shall be tackled. Defining settings.py is analogously done to the two previous steps, i.e. data generation 7 and clustering 8. Therefore, accounts regarding the sub-tasks settings.py and the clustered data are not repeated.\n1. Ordering \\(\\,(\\vec{\\boldsymbol{\\beta}})\\)\n\nThe ordering of the clustered data can be understood by viewing figures 9.5 and 9.6 . Both depict the clustered Lorenz system 7.1 for \\(\\beta = 30.5\\). The difference between the two figures is that figure 9.5 shows the clustering as it is obtained from the clustering step. It shall be referred to as the initial state. Figure 9.6 on the other shows the ordered state, i.e. the state after applying the ordering sub-step. The labeling of the ordered step represents to some degree the actual movement of the trajectory. It can be observed that moving from label \\(1\\) up to \\(6\\) in a consecutive manner the resulting trajectory is generating the left ear of the Lorenz system. Analogously, moving from label \\(7\\) up to \\(10\\) produces the right ear of the Lorenz system. Furthermore, the transition from centroid \\(6\\) to \\(7\\) captures the transition from one ear to the other.\n\n\n\n\n\nFigure 9.5— Initial State - centroids of the Lorenz system 7.1 \\(\\beta =30.5\\)\n\n\n\n\n\nFigure 9.6— Ordered State - centroids of the Lorenz system 7.1 \\(\\beta =30.5\\)\n\n\n\n\nThe way the ordered state is retrieved is as follows. The entire sequence of the motion along the centroids is available. In simpler terms, the first centroid from where the trajectory will start, all the upcoming centroids and the order in which they will be visited are known. Therefore, the initial centroid can be labeled as \\(1\\), the second as \\(2\\) and so on. However, it is important to note that with modifying one label of the trajectory sequence, the same label needs to be found in the entire sequence and modified as well. Otherwise, the ordered-state is true for one turn and a wrong initial-ordered-state mixture is kept for the remaining turns. Such an approach would also falsify the trajectory. The labeling in the ordered state provides information about the trajectory. Further, the original motion of the trajectory is untouched. Labeling the characteristic centroids with different numbers or with Greek letters does not impose any change on the original dynamics. For that to be fully true, the newly introduced labeling must be consistent across the entire sequence. Although it is obvious, nevertheless CNMccontrol-oriented Cluster-based Network Modeling performs a sanity check, i.e., it is verified, whether the resulting trajectory in the ordered state is the same as the original trajectory. Note, that all the same 4 types of plots stated in section 8 are also available for visualizing the ordered state . \n2. Calculating \\(\\boldsymbol A \\, (\\vec{\\boldsymbol{\\beta}})\\) & best path \\(\\,(\\vec{\\boldsymbol{\\beta}})\\)\n\nIn the next sub-task the cost or similarity matrix \\(\\boldsymbol A(\\vec{\\beta})\\) is calculated. First, the assignment problem shall be elaborated. Let \\(\\beta_1\\) and \\(\\beta_2\\) be two different model parameter values \\(\\beta_1 \\neq \\beta_2\\) and both shall consist of \\(K\\) centroids. Each centroid is not only associated with a label but described fully with a position. The goal is to match each centroid from \\(\\beta_1\\) to exactly one corresponding centroid from \\(\\beta_2\\) such that the overall spatial distance is minimized. This idea was given as part of the definition of the term tracking itself. The difference between tracking and the assignment problem is that first, tracking solves the assignment problem multiple times and thus the assignment problem is only a part of tracking. Second, the tracked results are also feasible and transformed, which will be covered later in this subsection.\nFor construction an illustrative cost matrix \\(\\boldsymbol A(\\vec{\\beta})\\), 3 pairwise different \\(\\beta\\) values, \\(\\beta_1, \\, \\beta_2, \\beta_3\\) with \\((\\beta_1,\\neq \\beta_2) \\neq \\beta_3\\) shall be considered. Again, each \\(\\beta_i\\), where \\(i = \\{1,2,3\\}\\), consists of \\(K\\) centroid positions. The assignment problem is solved by exploiting SciPy (Virtanen et al. 2020). Its solution, e.g., for \\(\\beta_1\\) and \\(\\beta_2\\) only matches the centroids from the two different \\(\\beta\\) such that the overall spatial distance is minimized. The addition of the spatial distances of \\(\\beta_1\\) and \\(\\beta_2\\) shall be designated as the cost value \\(\\beta_{i=1,j=2}\\). With this level of understanding, the similarity matrix given in equation 9.2 can be read. \\[\n\\begin{equation}\n     \\boldsymbol A_{3\\times 3}\\,(\\vec{\\beta}) =\n     \\begin{bmatrix}\n      \\beta_{1,1} & \\beta_{1,2} & \\beta_{1,3}\\\\\n       \\beta_{2,1}  &\\beta_{2,2} & \\beta_{2,3}\\\\\n       \\beta_{3,1} & \\beta_{3,2} &\\beta_{3,3}\n     \\end{bmatrix}\n     \\label{eq_17_Dist_A}\n   \\end{equation}\n\\tag{9.2}\\]\nConsidering equation 9.3, if the assignment problem is solved for equal \\(\\beta \\Rightarrow \\beta_i = \\beta_j\\), the centroid positions overlap exactly. As a consequence, the distance between all the centroids across the two same \\(\\beta\\) is zero. Further, adding up the zero spatial distances yields a cost of zero \\(\\beta_{i,i} = 0\\). \\[\n\\begin{equation}\n  \\begin{aligned}\n    i &= j \\\\\n    \\Rightarrow \\beta_i &= \\beta_j  \\\\\n    \\Rightarrow \\beta_{i,j} &=  \\beta_{i,i} = 0\n  \\end{aligned}\n    \\label{eq_18_Expl}\n\\end{equation}\n\\tag{9.3}\\]\nThe cost matrix \\(\\boldsymbol A\\,(\\vec{\\beta})\\) compares each \\(\\beta_i\\) with all the remaining \\(\\beta_j\\), where \\(i = \\{1, \\,2, \\cdots, n_{\\beta}\\}, \\; j = \\{1, \\,2, \\cdots, n_{\\beta}\\}\\) and \\(n_{\\beta}\\) denotes the number of the pairwise different \\(\\vec{\\beta}\\). The outcome of each possible comparison \\(\\beta_i\\) with \\(\\beta_j\\) is a cost value representing a similarity between \\(\\beta_i\\) and \\(\\beta_j\\). Obviously, in the case trivial as described above \\(\\beta_i = \\beta_j\\), the similarity is maximized and the cost is minimized. To find the best path, i.e., proposed tracking results, the trivial entries on the diagonal entries must be prohibited. Obeying that the cost matrix \\(\\boldsymbol A\\,(\\vec{\\beta})\\) can be reformulated as equation 9.4 . Moreover, \\(\\boldsymbol A\\,(\\vec{\\beta})\\) is symmetrical, therefore computing one triangular part of the cost matrix is sufficient. The triangular part can be filled by mirroring along with the diagonal entries \\(\\beta_{i,i}\\) as outlined for the lower triangular matrix in equation 9.4 . \\[\n\\begin{equation}\n     \\boldsymbol A_{3\\times 3}\\,(\\vec{\\beta}) =\n     \\begin{bmatrix}\n       \\infty & \\beta_{1,2} & \\beta_{1,3}\\\\\n       \\beta_{2,1} = \\beta_{1,2} & \\infty & \\beta_{2,3}\\\\\n       \\beta_{3,1} =  \\beta_{1,3} & \\beta_{3,2} =\\beta_{2,3}  & \\infty\\\\\n     \\end{bmatrix}\n     \\label{eq_19}\n\\end{equation}\n\\tag{9.4}\\]\nThe objective behind exploiting symmetry is to reduce computation time. Having defined the cost matrix \\(\\boldsymbol A\\,(\\vec{\\beta})\\) as given in equation 9.4, it can be used to again solve the assignment problem. Its output is denoted as path\\(_O\\,(\\vec{\\beta })\\) in figure 9.4 .\n3. Validity check\n\nThe sdfvalidity check can also be regarded as a feasibility investigation. To grasp what the feasibility constraint is table 9.1 (a) shall be analyzed .\n\n\n\n\n\n\n\n\n(a) Direct feasible\n\n\n\\(\\boldsymbol{\\beta_i}\\)\n\\(\\boldsymbol{\\beta_j}\\)\n\n\n\n\n1\n2\n\n\n2\n3\n\n\n3\n4\n\n\n4\n5\n\n\n5\n6\n\n\n6\n7\n\n\n\n\n\n\n(b) feasible\n\n\n\\(\\boldsymbol{\\beta_i}\\)\n\\(\\boldsymbol{\\beta_j}\\)\n\n\n\n\n1\n2\n\n\n2\n3\n\n\n3\n6\n\n\n4\n7\n\n\n5\n4\n\n\n6\n5\n\n\n\n\n\n\n(c) infeasible\n\n\n\\(\\boldsymbol{\\beta_i}\\)\n\\(\\boldsymbol{\\beta_j}\\)\n\n\n\n\n1\n2\n\n\n2\n1\n\n\n3\n5\n\n\n4\n6\n\n\n5\n7\n\n\n6\n3\n\n\n\n\n\n\nTable 9.1— Examples for feasible and infeasible best tracking paths\n\n\n\n\n\n\nIt can be observed that in total the 7 model parameter values \\((\\vec{\\beta}, \\, n_{\\beta}=7)\\) were chosen. The overall goal is to provide one centroid label and get its corresponding centroid positions across all the 7 model parameter values \\(\\vec{\\beta }\\). Therefore, a feasible linking path, which allows the linking of all centroids of all \\(\\beta_i\\) to all the other \\(\\beta_{\\vec{j}}\\) centroids, is required. The latter description shall be elaborated step-wise in the following. For instance, if the first \\(\\beta_i = 1\\), a linking to the remaining \\(\\beta_{\\vec{j}} = \\{2, \\, 3, \\, 4, \\, 5, \\, 6, \\, 7 \\}\\) is mandatory. The first item of table 9.1 (a) outlines that the centroids from \\(\\beta_i = 1\\) are tracked with the centroids \\(\\beta_j=2\\) . In other words, a clear relationship between the centroids across \\(\\beta_i = 1\\) and \\(\\beta_j=2\\) is established. Leveraging this relationship, the proper tracked centroid position across the two \\(\\beta = 1\\) and \\(\\beta= 2\\), are returned.\nBecause the centroid labels of \\(\\beta_i = 1\\) are used as the reference to match the centroid labels of \\(\\beta_j=2\\), the known linked path can be stated as \\(L_{known}= \\{1,\\, 2\\}\\). The next model parameter value \\(\\beta_j = 3\\) and it is tracked with \\(\\beta_i =2\\). Since \\(\\beta_i =2\\) is already incorporated in the known linked path, the known linking path can be extended to \\(L_{known}= \\{1,\\, 2, \\, 3\\}\\). The next model parameter value \\(\\beta_j = 4\\) and its corresponding tracked counterpart is \\(\\beta_i =3\\). Again, \\(\\beta_i =3\\) is found in the known linked path, therefore the known linking path can be extended to \\(L_{known}= \\{1,\\, 2, \\, 3, \\, 4\\}\\). The next model parameter value \\(\\beta_j = 5\\) and its corresponding tracked \\(\\beta_i =4\\) and so this procedure can be performed until the last \\(\\beta_j = 7\\). Having completed the scheme, the known linking path is of full rank, i.e. with \\(n_{\\beta}= 7\\) all the 7 pairwise different model parameter values \\(\\vec{\\beta}\\) are captured in the known linking path \\(L_{known}\\). The information gained through a full ranked \\(L_{known, full}\\) is that all centroids of all \\(\\beta_i\\) are linked to all the other \\(\\beta_{\\vec{j}}\\) centroids. \nAfter having introduced the full rank \\(L_{known, full}\\), the more straightforward definition for feasible linking path can be stated as follows. A feasible linking path is given when \\(L_{known}\\) has full rank \\(L_{known, full}\\). Direct feasible cases as shown in table 9.1 (a) are one way of feasible linking paths . Another, more general feasible case is provided in table 9.1 (b) . Here, up to \\(\\beta_i = 2\\) and \\(\\beta_j = 3\\) the scheme of the direct feasible linking path is followed. However, with \\(\\beta_i = 4\\) and \\(\\beta_j = 7\\) the obstacle that \\(\\beta_j = 7\\) is not present in the current \\(L_{known}= \\{1,\\, 2,\\, 3,\\, 6\\}\\), occurs. This issue can be circumvented by viewing \\(\\beta_i = 6\\) and \\(\\beta_j = 5\\). Since \\(\\beta_i = 6\\) is in the current state of \\(L_{known}= \\{1,\\, 2,\\, 3,\\, 6\\}\\), \\(L_{known}\\) can be extended with \\(\\beta_j = 5\\), i.e., \\(L_{known}= \\{1,\\, 2,\\, 3,\\, 5, \\, 6\\}\\). Note, having acquired the relationship between \\(\\beta_i\\) to \\(\\beta_j\\) is the same as knowing the relationship between \\(\\beta_j\\) to \\(\\beta_i\\). Applying the newly added linking perspective, it can be seen that table 9.1 (b) also demonstrates a fulled ranked \\(L_{known, full}\\) or a feasible linking path .\nIn table 9.1 (c) an example for an incomplete linking path or an infeasible linking path is provided, where \\(L_{known}\\) has no full rank . The aim of the sub-task, validity, is to determine, whether the proposed optimized tracking path is feasible by extracting information about the rank of the final \\(L_{known}\\). Internally in CNMccontrol-oriented Cluster-based Network Modeling, this is achieved through logical queries utilizing mainly if statements. One major advantage which was not mentioned when the examples above were worked out is the following. \\(\\beta_{i,ref} = 1\\) is not necessarily the best choice for being the reference. The reference \\(\\beta_{i,ref}\\) is chosen such that it has the overall highest similarity or least cost to all the other \\((n_{\\beta} -1)\\) available \\(\\vec{\\beta}\\). Hence, a feasible linking path with a lower sum of cost sum is generated.\nThis feature of a flexible reference is only providing better feasible linking paths, when the proposed optimized tracking path is infeasible, which in general is the case. Therefore, in most cases, it is advantageous to leverage the flexible reference. One of the outputs of CNMccontrol-oriented Cluster-based Network Modeling is the percentage cost savings that could be achieved with the flexible approach. In others, by what percentage could the costs be decreased when the flexible approach is compared with the rigid approach. In the rigid approach, \\(\\beta_{i,ref} = 1\\) is chosen as the reference. Further, in the rigid approach, the \\(\\vec{\\beta}\\) are linked in increasing order, i.e. \\(\\beta_1\\) with \\(\\beta_1\\), \\(\\beta_2\\) with \\(\\beta_2\\), \\(\\beta_3\\) with \\(\\beta_4\\) and so on. Exploiting the flexible approach yields cost savings of around \\(20\\%\\) to \\(50\\%\\) An example of coping with a flexible reference is provided in the description of the following sub-step. \n4. Truncate, final path\n\nIf the proposed optimized tracking path is feasible (feasible linking path), i.e. \\(L_{known}\\) has full rank \\(L_{known, full}\\), the truncation can be skipped. Consequently, the final path is the same as the proposed optimized tracking path. However, as mentioned, in general, this is not the expected case. Therefore, an example with an incomplete \\(L_{known}\\) shall be portrayed to explain the workflow with active truncation.\nFirst, the final incomplete \\(L_{known}\\) will be used as the starting point. It will be filled until full rank is reached. Allowing a flexible reference \\(\\beta_{i,ref}\\) the incomplete known linked path could be, e.g., \\(L_{known} = \\{3, \\, 4, \\, 5\\}\\). To get full rank, the remaining \\(L_{missing} = \\{1, \\, 2, \\, 6, \\, 7\\}\\) are inferred through the following concept. The cost \\(\\beta_{i,j}\\) between all \\(L_{known}\\) and \\(L_{missing}\\) are known through the cost matrix \\(\\boldsymbol A\\,(\\vec{\\beta })\\). The one \\(\\beta_j\\) entry from \\(L_{missing}\\) which has the highest similarity or lowest cost \\(\\beta_{i,j}\\) to the one entry \\(\\beta_j\\) of the \\(L_{known}\\), is removed from \\(L_{missing}\\) and added to \\(L_{known}\\). Now, the same procedure can be applied to the modified \\(L_{known}\\) and \\(L_{missing}\\) until \\(L_{missing}\\) is empty and \\(L_{known}\\) has reached full rank. The inferred \\(L_{known, full}\\) is then used as the final path and sent to the next sub-task.\n5. Transform\n\nOnce the final path is determined, it is known which \\(\\beta_i\\) is linked to which \\(\\beta_j\\). For all the \\(\\beta_{i},\\, \\beta_j\\) matches in the final path, the linear sum assignment problem is solved again. Two illustrative solutions are provided in section 12. For further explanation, table 9.1 (b) shall be revisited . The first \\(\\beta_{i},\\, \\beta_j\\) link is defined as \\(\\beta_i = 1\\) and \\(\\beta_j = 2\\). Moreover, for this scenario, it is assumed that \\(\\beta_i = \\beta_{ref} = 1\\). Therefore, the \\(\\beta_{i} = 1,\\, \\beta_j= 2\\) is denoted as a direct match. In simpler terms, a direct pairwise \\(\\beta_{i},\\, \\beta_j\\) relation, is obtained when \\(\\beta_i\\) or \\(\\beta_j\\) is directly traced back to the reference. For a pairwise direct \\(\\beta_{i},\\, \\beta_j\\) link the transformation, i.e., relabeling without changing the dynamics of the system, as explained for the ordering sub-step, is applied directly and only once.\nNow, considering the next \\(\\beta_{i},\\, \\beta_j\\) match, i.e., \\(\\beta_i = 2\\) and \\(\\beta_j = 3\\). Linking the centroids from \\(\\beta_j = 3\\) to \\(\\beta_i = 2\\) directly would have no connection to the reference \\(\\beta_{ref} = 1\\). Therefore, the solution to its linear sum assignment problem must experience the same transformations as \\(\\beta_i = 2\\) did. In this case it is only the transformation caused by the \\((\\beta_i = 1,\\,\\beta_j = 2)\\) match. The idea behind the transformation stays the same, however, if no direct relation is seen, respective multiple transformations must be performed. Once the final path has undergone all required transformations, the output is the desired tracked state. The output can be stored and plotted if desired. Some types of plots, which can be generated, will be shown in the section 12.\nFinally, in short, the difference between first CNMc and this CNMccontrol-oriented Cluster-based Network Modeling version shall be mentioned. The proposed tracking algorithm is neither restricted to any dimension nor to a specific dynamical system. Thus, two major limitations of first CNMc could be removed in the current CNMccontrol-oriented Cluster-based Network Modeling version. Also, the flexible approach yields a better feasible linking path.\n\n\n\n\nVirtanen, Pauli, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, et al. 2020. “SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python.” Nature Methods 17: 261–72. https://doi.org/10.1038/s41592-019-0686-2."
  },
  {
    "objectID": "Data/1_Writing/2_Task/6_Modeling.html",
    "href": "Data/1_Writing/2_Task/6_Modeling.html",
    "title": "10  Modeling",
    "section": "",
    "text": "In this section, the fourth main step of CNMccontrol-oriented Cluster-based Network Modeling, i.e., modeling, is elaborated. The data and workflow is described in figure 10.1 . It comprises two main sub-tasks, which are modeling the Centroid Position Evolution (CPE) and modeling the transition properties tensors \\(\\boldsymbol Q / \\boldsymbol T\\). The settings are as usually defined in settings.py and the extracted attributes are distributed to the sub-tasks. Modeling the CPECentroid Position Evolution and the \\(\\boldsymbol Q/ \\boldsymbol T\\) tensors can be executed separately from each other. If the output of one of the two modeling sub-steps is at hand, CNMccontrol-oriented Cluster-based Network Modeling is not forced to recalculate both modeling sub-steps. Since the tracked states are used as training data to run the modeling they are prerequisites for both modeling parts. The modeling of the centroid position shall be explained in the upcoming subsection 10.0.1, followed by the explanation of the transition properties in subsection 10.0.2. A comparison between this CNMccontrol-oriented Cluster-based Network Modeling and the first CNMc version is provided at the end of the respective subsections. The results of both modeling steps can be found in section 13 and 14\n\n\n\nFigure 10.1— Data and workflow of the fourth step: Modeling\n\n\n\n10.0.1 Modeling the centroid position evolution\nIn this subsection, the modeling of the CPECentroid Position Evolution is described. The objective is to find a surrogate model, which returns all \\(K\\) centroid positions for an unseen \\(\\beta_{unseen}\\). The training data for this are the tracked centroids from the previous step, which is described in section 9. To explain the modeling of the CPE, figure 10.2 shall be inspected. The model parameter values which shall be used to train the model \\(\\vec{\\beta_{tr}}\\) are used for generating a so-called candidate library matrix \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\). The candidate library matrix \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) is obtained making use of a function of pySindy (Silva et al. 2020; Kaptanoglu et al. 2022; S. L. Brunton, Proctor, and Kutz 2016). In (S. L. Brunton, Proctor, and Kutz 2016) the term \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) is explained well. However, in brief terms, it allows the construction of a matrix, which comprises the output of defined functions. These functions could be, e.g., a linear, polynomial, trigonometrical or any other non-linear function. Made-up functions that include logical conditions can also be applied. \n\n\n\nFigure 10.2— Data and workflow of modeling the \n\n\nSince, the goal is not to explain, how to operate pySindy (S. L. Brunton, Proctor, and Kutz 2016), the curious reader is referred to the pySindy very extensive online documentation and (Silva et al. 2020; Kaptanoglu et al. 2022). Nevertheless, to understand \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) equation 10.1 shall be considered. In this example, 3 different functions, denoted as \\(f_i\\) in the first row, are employed. The remaining rows are the output for the chosen \\(f_i\\). Furthermore, \\(n\\) is the number of samples or the size of \\(\\vec{\\beta_{tr} }\\), i.e., \\(n_{\\beta,tr}\\) and \\(m\\) denotes the number of the features, i.e., the number of the functions \\(f_i\\). \\[\n\\begin{equation}\n    \\boldsymbol{\\Theta_{exampl(n \\times m )}}(\\,\\vec{\\beta_{tr}}) =\n    \\renewcommand\\arraycolsep{10pt}\n    \\begin{bmatrix}\n      f_1 = \\beta & f_2 = \\beta^2 & f_2 = cos(\\beta)^2 - exp\\,\\left(\\dfrac{\\beta}{-0.856} \\right) \\\\[1.5em]\n      1  & 1^2 & cos(1)^2 - exp\\,\\left(\\dfrac{1}{-0.856} \\right) \\\\[1.5em]\n      2 &  2^2  & cos(2)^2 - exp\\,\\left(\\dfrac{2}{-0.856} \\right) \\\\[1.5em]\n    \\end{bmatrix}\n    \\label{eq_20}\n\\end{equation} \\tag{10.1}\\]\nThe actual candidate library matrix \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) incorporates a quadratic polynomial, the inverse \\(\\frac{1}{\\beta}\\), the exponential \\(exp(\\beta)\\) and 3 frequencies of cos and sin, i.e., \\(cos(\\vec{\\beta}_{freq}), \\ sin(\\vec{\\beta}_{freq})\\), where \\(\\vec{\\beta}_{freq} = [1, \\, 2,\\, 3]\\). There are much more complex \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) available in CNMccontrol-oriented Cluster-based Network Modeling, which can be selected if desired. Nonetheless, the default \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) is chosen as described above. Once \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) is the generated, the system of equations 10.2 is solved. Note, this is very similar to solving the well-known \\(\\boldsymbol A \\, \\vec{x} = \\vec{y}\\) system of equations. The difference is that the vectors \\(\\vec{x}, \\, \\vec{y}\\) can be vectors in the case of 10.2 as well, but in general, they are the matrices \\(\\boldsymbol{X} ,\\, \\boldsymbol Y\\), respectively. The solution to the matrix \\(\\boldsymbol{X}\\) is the desired output. It contains the coefficients which assign importance to the used functions \\(f_i\\). The matrix \\(\\boldsymbol Y\\) contains the targets or the known output for the chosen functions \\(f_i\\). Comparing \\(\\boldsymbol A\\) and \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) mathematically, no difference exists.\n\\[\n\\begin{equation}\n    \\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}}) \\: \\boldsymbol X = \\boldsymbol Y\n    \\label{eq_21}\n\\end{equation} \\tag{10.2}\\]\nWith staying in the pySindy environment, the system of equations 10.2 is solved by means of the optimizer SR3, which is implemented in pySindy. Details and some advantages of the SR3 optimizer can be found in (Zheng et al. 2018). Nevertheless, two main points shall be stated. It is highly unlikely that the \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}}),\\: \\boldsymbol X,\\, \\boldsymbol Y\\) is going to lead to a well-posed problem, i.e., the number of equations are equal to the number of unknowns and having a unique solution. In most cases the configuration will be ill-posed, i.e., the number of equations is not equal to the number of unknowns. In the latter case, two scenarios are possible, the configuration could result in an over-or under-determined system of equations.\nFor an over-determined system, there are more equations than unknowns. Thus, generally, no outcome that satisfies equation 10.2 exists. In order to find a representation that comes close to a solution, an error metric is defined as the objective function for optimization. There are a lot of error metrics or norms, however, some commonly used (S. Brunton and Kutz 2019) are given in equations 10.3 to 10.5, where \\(f(x_k)\\) are true values of a function and \\(y_k\\) are their corresponding predictions. The under-determined system has more unknown variables than equations, thus infinitely many solutions exist. To find one prominent solution, again, optimization is performed. Note, for practical application penalization or regularization parameter are exploited as additional constraints within the definition of the optimization problem. For more about over- and under-determined systems as well as for deploying optimization for finding a satisfying result the reader is referred to (S. Brunton and Kutz 2019). \\[\n\\begin{equation}\n    E_{\\infty} = \\max_{1&lt;k&lt;n} |f(x_k) -y_k | \\quad \\text{Maximum Error} \\;(l_{\\infty})\n    \\label{eq_22}\n\\end{equation} \\tag{10.3}\\]\n\\[\n\\begin{equation}\n    E_{1} = \\frac{1}{n} \\sum_{k=1}^{n} |f(x_k) -y_k | \\quad \\text{Mean Absolute Error} \\;(l_{1})\n    \\label{eq_23}\n\\end{equation} \\tag{10.4}\\]\n\\[\n\\begin{equation}\n    E_{2} =  \\sqrt{\\frac{1}{n} \\sum_{k=1}^{n} |f(x_k) -y_k |^2 }  \\quad \\text{Least-squares Error} \\;(l_{2})\n    \\label{eq_24}\n\\end{equation} \\tag{10.5}\\]\nThe aim for modeling CPE is to receive a regression model, which is sparse, i.e., it is described through a small number of functions \\(f_i\\). For this to work, the coefficient matrix \\(\\boldsymbol X\\) must be sparse, i.e., most of its entries are zero. Consequently, most of the used functions \\(f_i\\) would be inactive and only a few \\(f_i\\) are actively applied to capture the CPE behavior. The \\(l_1\\) norm as defined in 10.4 and the \\(l_0\\) are metrics which promotes sparsity. In simpler terms, they are leveraged to find only a few important and active functions \\(f_i\\). The \\(l_2\\) norm as defined in 10.5 is known for its opposite effect, i.e. to assign importance to a high number of \\(f_i\\). The SR3 optimizer is a sparsity promoting optimizer, which deploys \\(l_0\\) and \\(l_1\\) regularization.\nThe second point which shall be mentioned about the SR3 optimizer is that it can cope with over-and under-determined systems and solves them without any additional input. One important note regarding the use of pySindy is that pySindy in this thesis is not used as it is commonly. For modeling the CPE only the modules for generating the candidate library matrix \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) and the SR3 optimizer are utilized.\nGoing back to the data and workflow in figure 10.2, the candidate library matrix \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) is generated. Furthermore, it also has been explained how it is passed to pySindy and how SR3 is used to find a solution. It can be observed that \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) is also passed to a Linear and Elastic net block. The Linear block is used to solve the system of equations 10.2 through linear interpolation. The Elastic net solves the same system of equations with the elastic net approach. In this the optimization is penalized with an \\(l_1\\) and \\(l_2\\) norm. In other words, it combines the Lasso (Tibshirani 1996; S. Brunton and Kutz 2019) and Ridge (S. Brunton and Kutz 2019), regression respectively. The linear and elastic net solvers are invoked from the Scikit-learn (Pedregosa et al. 2011) library.\nThe next step is not depicted in figure 10.2 . Namely, the linear regression model is built with the full data. For pySindy and the elastic net, the models are trained with \\(90 \\%\\) of the training data and the remaining \\(10 \\%\\) are used to test or validate the model. For pySindy \\(20\\) different models with the linear distributed thresholds starting from \\(0.1\\) and ending at \\(2.0\\) are generated. The model which has the least mean absolute error 10.4 will be selected as the pySindy model. The mean absolute error of the linear, elastic net and the selected pySindy will be compared against each other. The one regression model which has the lowest mean absolute error is selected as the final model.\nThe described process is executed multiple times. In 3-dimensions the location of a centroid is given as the coordinates of the 3 axes. Since the CPE across the 3 different axes can deviate significantly, capturing the entire behavior in one model would require a complex model. A complex model, however, is not sparse anymore. Thus, a regression model for each of the \\(K\\) labels and for each of the 3 axes is required. In total \\(3 \\, K\\) regression models are generated. \nFinally, first CNMc and CNMccontrol-oriented Cluster-based Network Modeling shall be compared. First, in first CNMc only pySindy with a different built-in optimizer. Second, the modeling CPE was specifically designed for the Lorenz system 7.1 . Third, first CNMc entirely relies on pySindy, no linear and elastic models are calculated and used for comparison. Fourth, the way first CNMc would perform prediction, was by transforming the active \\(f_i\\) with their coefficients to equations such that SymPy could be applied. The disadvantage is that if \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) is changed, modifications for SymPy are necessary. Also, \\(\\boldsymbol{\\Theta}\\,(\\vec{\\beta_{tr}})\\) can be used for arbitrary defined functions \\(f_i\\), SymPy functions, however, are restricted to some predefined functions. In CNMccontrol-oriented Cluster-based Network Modeling it is also possible to get the active \\(f_i\\) as equations. However, the prediction is obtained with a regular matrix-matrix multiplication as given in equation 10.6 . The variables are denoted as the predicted outcome \\(\\boldsymbol{\\tilde{Y}}\\), the testing data for which the prediction is desired \\(\\boldsymbol{\\Theta_s}\\) and the coefficient matrix \\(\\boldsymbol X\\) from equation 10.2 . \\[\n\\begin{equation}\n    \\boldsymbol{\\tilde{Y}} = \\boldsymbol{\\Theta_s} \\, \\boldsymbol X\n    \\label{eq_25}\n\\end{equation} \\tag{10.6}\\]\nWith leveraging equation 10.6 the limitations imposed through SymPy are removed.\n\n\n10.0.2 Modeling Q/T\nIn this subsection, the goal is to explain how the transition properties are modeled. The transition properties are the two tensors \\(\\boldsymbol Q\\) and \\(\\boldsymbol T\\), which consist of transition probability from one centroid to another and the corresponding transition time, respectively. For further details about the transition properties, the reader is referred to section 4. Modeling \\(\\boldsymbol Q / \\boldsymbol T\\) means to find surrogate models that capture the trained behavior and can predict the tensors for unseen model parameter values \\(\\boldsymbol{\\tilde{Q}}(\\vec{\\beta}_{unseeen}) ,\\, \\boldsymbol{\\tilde{T}}(\\vec{\\beta}_{unseeen})\\). To go through the data and workflow figure 10.3 shall be considered.\n\n\n\nFigure 10.3— Data and workflow of \\(\\boldsymbol Q / \\boldsymbol T\\) modeling\n\n\nFirst, the tracked state data is loaded and adapted in the sense that CNM’s data format is received. After that CNMCluster-based Network Modeling can be executed on the tracked state data. The outcome of CNMCluster-based Network Modeling are the transition property tensors for all the provided model parameter values \\(\\boldsymbol Q(\\vec{\\beta}) ,\\, \\boldsymbol T(\\vec{\\beta})\\). However, CNMCluster-based Network Modeling does not return tensors as NumPy (Harris et al. 2020) arrays, but as Python dictionaries. Thus, the next step is to transform the dictionaries to NumPy arrays. \\(\\boldsymbol Q / \\boldsymbol T\\) are highly sparse, i.e., \\(85 \\% - 99\\%\\) of the entries can be zero. The \\(99\\%\\) case is seen with a great model order, which for the Lorenz system 7.1 was found to be \\(L \\approx 7\\). Furthermore, with an increasing \\(L\\), saving the dictionaries as NumPy arrays becomes inefficient and at some \\(L\\) impossible. With \\(L&gt;7\\) the storage cost goes above multiple hundreds of gigabytes of RAM. Therefore, the dictionaries are converted into sparse matrices. \nThereafter, the sparse matrices are reshaped or stacked into a single matrix, such that a modal decomposition method can be applied. Followed by training a regression model for each of the mode coefficients. The idea is that the regression models receive a \\(\\beta_{unseen}\\) and returns all the corresponding predicted modes. The regression models are saved and if desired plots can be enabled via settings.py. \nIn this version of CNMccontrol-oriented Cluster-based Network Modeling two modal decomposition methods are available. Namely, the Singular Value Decomposition (SVD) and the Non-negative Matrix Factorization (NMF). The difference between both is given in (Lee and Seung 1999). The SVDSingular Value Decomposition is stated in equation 10.7, where the variables are designated as the input matrix \\(\\boldsymbol A\\) which shall be decomposed, the left singular matrix \\(\\boldsymbol U\\), the diagonal singular matrix \\(\\boldsymbol{\\Sigma}\\) and the right singular matrix \\(\\boldsymbol V^T\\). The singular matrix \\(\\boldsymbol{\\Sigma}\\) is mostly ordered in descending order such that the highest singular value is the first diagonal element. The intuition behind the singular values is that they assign importance to the modes in the left and right singular matrices \\(\\boldsymbol U\\) and \\(\\boldsymbol {V^T}\\), respectively. \\[\n\\begin{equation}\n    \\boldsymbol A = \\boldsymbol U \\, \\boldsymbol{\\Sigma} \\, \\boldsymbol {V^T}\n    \\label{eq_26}\n\\end{equation} \\tag{10.7}\\]\nThe big advantage of the SVDSingular Value Decomposition is observed when the so-called economical SVDSingular Value Decomposition is calculated. The economical SVDSingular Value Decomposition removes all zero singular values, thus the dimensionality of all 3 matrices can be reduced. However, from the economical SVDSingular Value Decomposition as a basis, all the output with all \\(r\\) modes is available. There is no need to perform any additional SVDSingular Value Decomposition to get the output for \\(r\\) modes, but rather the economical SVDSingular Value Decomposition is truncated with the number \\(r\\) for this purpose. NMFNon-negative Matrix Factorization, given in equation 4.5, on the other hand, has the disadvantage that there is no such thing as economical NMF. For every change in the number of modes \\(r\\), a full NMFNon-negative Matrix Factorization must be recalculated.\n\\[\n\\begin{equation}\n    \\boldsymbol {A_{i \\mu}} \\approx \\boldsymbol A^{\\prime}_{i \\mu}  = (\\boldsymbol W  \\boldsymbol H)_{i \\mu}  = \\sum_{a = 1}^{r}\n    \\boldsymbol W_{ia} \\boldsymbol H_{a \\mu}\n    \\tag{4.5}\n\\end{equation}\n\\]\nThe issue with NMFNon-negative Matrix Factorization is that the solution is obtained through an iterative optimization process. The number of iterations can be in the order of millions and higher to meet the convergence criteria. Because the optimal \\(r_{opt}\\) depends on the dynamical system, there is no general rule for acquiring it directly. Consequently, NMFNon-negative Matrix Factorization must be run with multiple different \\(r\\) values to find \\(r_{opt}\\). Apart from the mentioned parameter study, one single NMFNon-negative Matrix Factorization execution was found to be more computationally expensive than SVDSingular Value Decomposition. In (Pierzyna 2021) NMFNon-negative Matrix Factorization was found to be the performance bottleneck of first CNMc, which became more evident when \\(L\\) was increased. In subsection 14.0.1 a comparison between NMFNon-negative Matrix Factorization and SVDSingular Value Decomposition regarding computational time is given.\nNevertheless, if the user wants to apply NMFNon-negative Matrix Factorization, only one attribute in settings.py needs to be modified. Because of that and the overall modular structure of CNMccontrol-oriented Cluster-based Network Modeling, implementation of any other decomposition method should be straightforward. In CNMccontrol-oriented Cluster-based Network Modeling the study for finding \\(r_{opt}\\) is automated and thus testing CNMccontrol-oriented Cluster-based Network Modeling on various dynamical systems with NMFNon-negative Matrix Factorization should be manageable. The benefit of applying NMFNon-negative Matrix Factorization is that the entries of the output matrices \\(\\boldsymbol W_{ia},\\, \\boldsymbol H_{a \\mu}\\) are all non-zero. This enables interpreting the \\(\\boldsymbol W_{ia}\\) matrix since both \\(\\boldsymbol Q / \\boldsymbol T\\) tensors cannot contain negative entries, i.e., no negative probability and no negative transition time.\nDepending on whether NMFNon-negative Matrix Factorization or SVDSingular Value Decomposition is chosen, \\(r_{opt}\\) is found through a parameter study or based on \\(99 \\%\\) of the information content, respectively. The \\(99 \\%\\) condition is met when \\(r_{opt}\\) modes add up to \\(99 \\%\\) of the total sum of the modes. In SVDSingular Value Decomposition \\(r_{opt}\\) is automatically detected and does not require any new SVDSingular Value Decomposition execution. A comparison between SVDSingular Value Decomposition and NMFNon-negative Matrix Factorization regarding prediction quality is given in section 14.0.2. After the decomposition has been performed, modes that capture characteristic information are available. If the modes can be predicted for any \\(\\beta_{unseen}\\), the predicted transition properties \\(\\boldsymbol{\\tilde{Q}}(\\vec{\\beta}_{unseeen}) ,\\, \\boldsymbol{\\tilde{T}}(\\vec{\\beta}_{unseeen})\\) are obtained. To comply with this CNMccontrol-oriented Cluster-based Network Modeling has 3 built-in methods. Namely, Random Forest (RF), AdaBoost, and Gaussian Process.\nFirst, RFRandom Forest is based on decision trees, but additionally deploys a technique called bootstrap aggregation or bagging. Bagging creates multiple sets from the original dataset, which are equivalent in size. However, some features are duplicated in the new datasets, whereas others are neglected entirely. This allows RFRandom Forest to approximate very complex functions and reduce the risk of overfitting, which is encountered commonly with regular decision trees. Moreover, it is such a powerful tool that, e.g., Kilian Weinberger, a well-known Professor for machine learning at Cornell University, considers RFRandom Forest in one of his lectures, to be one of the most powerful regression techniques that the state of the art has to offer. Furthermore, RFRandom Forest proved to be able to approximate the training data\nacceptable as shown in (Pierzyna 2021). However, as mentioned in subsection 4.0.1, it faced difficulties to approximate spike-like curves . Therefore, it was desired to test alternatives as well.\nThese two alternatives were chosen to be AdaBoost, and Gaussian Process. Both methods are well recognized and used in many machine learning applications. Thus, instead of motivating them and giving theoretical explanations, the reader is referred to (CAO et al. 2013), (Rasmussen 2004; Bishop 2006) for AdaBoost and Gaussian Process, respectively. As for the implementation, all 3 methods are invoked through Scikit-learn (Pedregosa et al. 2011). The weak learner for AdaBoost is Scikit-learn’s default decision tree regressor. The kernel utilized for the Gaussian Process is the Radial Basis Function (RBF). A comparison of these 3 methods in terms of prediction capabilities is provided in section 14.0.2.\nSince the predicted \\(\\boldsymbol{\\tilde{Q}}(\\vec{\\beta}_{unseeen}) ,\\, \\boldsymbol{\\tilde{T}}(\\vec{\\beta}_{unseeen})\\) are based on regression techniques, their output will have some deviation to the original \\(\\boldsymbol{Q}(\\vec{\\beta}_{unseeen}) ,\\, \\boldsymbol{T}(\\vec{\\beta}_{unseeen})\\). Due to that, the physical requirements given in equations 10.8 may be violated. \n\\[\n\\begin{equation}\n    \\begin{aligned}\n        0 \\leq  \\,  \\boldsymbol Q \\leq 1\\\\\n        \\boldsymbol T \\geq 0 \\\\\n        \\boldsymbol Q \\,(\\boldsymbol T &gt; 0) &gt; 0 \\\\\n        \\boldsymbol T(\\boldsymbol Q = 0) = 0\n    \\end{aligned}\n    \\label{eq_31_Q_T_prediction}\n\\end{equation}  \\tag{10.8}\\]\nTo manually enforce these physical constraints, the rules defined in equation 10.9 are applied. The smallest allowed probability is defined to be 0, thus negative probabilities are set to zero. The biggest probability is 1, hence, overshoot values are set to 1. Also, negative transition times would result in moving backward, therefore, they are set to zero. Furthermore, it is important to verify that a probability is zero if its corresponding transition time is less than or equals zero. In general, the deviation is in the order of \\(\\mathcal{O}(1 \\mathrm{e}{-2})\\), such that the modification following equation 10.9 can be considered reasonable. \n\\[\n\\begin{equation}\n    \\begin{aligned}\n        & \\boldsymbol Q &lt; 0 := 0 \\\\\n        & \\boldsymbol Q &gt; 1 := 1 \\\\\n        & \\boldsymbol T &lt; 0 := 0\\\\\n        & \\boldsymbol Q \\, (\\boldsymbol T \\leq 0) := 0\n    \\end{aligned}\n    \\label{eq_32_Rule}\n\\end{equation} \\tag{10.9}\\]\nIn conclusion, it can be said that modeling \\(\\boldsymbol Q / \\boldsymbol T\\) CNMccontrol-oriented Cluster-based Network Modeling is equipped with two different modal decomposition methods, SVDSingular Value Decomposition and NMF. To choose between them one attribute in settings.py needs to be modified. The application of NMFNon-negative Matrix Factorization is automated with the integrated parameter study. For the mode surrogate models, 3 different regression methods are available. Selecting between them is kept convenient, i.e. by editing one property in settings.py.\n\n\n\n\nBishop, Christopher. 2006. Pattern Recognition and Machine Learning. Springer. https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/.\n\n\nBrunton, Steven L, Joshua L Proctor, and J Nathan Kutz. 2016. “Sparse Identification of Nonlinear Dynamics with Control (SINDYc).” IFAC-PapersOnLine 49 (18): 710–15.\n\n\nBrunton, Steven, and J Kutz. 2019. “Data-Driven Science and Engineering.” Cambridge University Press. https://doi.org/10.1017/9781108380690.\n\n\nCAO, Ying, Qi-Guang MIAO, Jia-Chen LIU, and Lin GAO. 2013. “Advance and Prospects of AdaBoost Algorithm.” Acta Automatica Sinica 39 (6): 745–58. https://doi.org/https://doi.org/10.1016/S1874-1029(13)60052-X.\n\n\nHarris, Charles R., K. Jarrod Millman, Stéfan J. van der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020. “Array Programming with NumPy.” Nature 585 (7825): 357–62. https://doi.org/10.1038/s41586-020-2649-2.\n\n\nKaptanoglu, Alan, Brian De Silva, Urban Fasel, Kadierdan Kaheman, Andy Goldschmidt, Jared Callaham, Charles Delahunt, et al. 2022. “PySINDy: A Comprehensive Python Package for Robust Sparse System Identification.” Journal of Open Source Software 7 (69): 3994. https://doi.org/10.21105/joss.03994.\n\n\nLee, Daniel D, and H Sebastian Seung. 1999. “Learning the Parts of Objects by Non-Negative Matrix Factorization.” Nature 401 (6755): 788–91.\n\n\nPedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.” Journal of Machine Learning Research 12: 2825–30.\n\n\nPierzyna, Maximilian. 2021. “Control-Oriented Cluster-Basednetwork Modeling.” Research report, TU Braunschweig.\n\n\nRasmussen, Carl Edward. 2004. “Gaussian Processes in Machine Learning.” In Advanced Lectures on Machine Learning, 63–71. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-28650-9_4.\n\n\nSilva, Brian de, Kathleen Champion, Markus Quade, Jean-Christophe Loiseau, J. Kutz, and Steven Brunton. 2020. “PySINDy: A Python Package for the Sparse Identification of Nonlinear Dynamical Systems from Data.” Journal of Open Source Software 5 (49): 2104. https://doi.org/10.21105/joss.02104.\n\n\nTibshirani, Robert. 1996. “Regression Shrinkage and Selection via the Lasso.” Journal of the Royal Statistical Society: Series B (Methodological) 58 (1): 267–88.\n\n\nZheng, Peng, Travis Askham, Steven L Brunton, J Nathan Kutz, and Aleksandr Y Aravkin. 2018. “A Unified Framework for Sparse Relaxed Regularized Regression: SR3.” IEEE Access 7: 1404–23."
  },
  {
    "objectID": "Data/1_Writing/3_Task/0_Results.html",
    "href": "Data/1_Writing/3_Task/0_Results.html",
    "title": "11  Results",
    "section": "",
    "text": "In this chapter, the results achieved with CNMccontrol-oriented Cluster-based Network Modeling shall be presented and assessed. First, in section 12, the tracking algorithm is evaluated by showing the outcome for 3 different dynamical model configurations . Second, in section 13, statements about the performance of modeling the Centroid Position Evolution (CPE) are made . They are supported with some representative outputs. Third, in section 14 the two decomposition methods are compared in terms of computational time and prediction quality in subsection 14.0.1 and 14.0.2, respectively . Fourth, it has been mentioned that 3 different regressors for representing the \\(\\boldsymbol Q / \\boldsymbol T\\) tensor are available. Their rating is given in section 15. Finally, the CNMccontrol-oriented Cluster-based Network Modeling predicted trajectories for different models shall be displayed and evaluated in section 16.\nFor assessing the performance of CNMccontrol-oriented Cluster-based Network Modeling some dynamical model with a specific configuration will be used many times. In order not to repeat them too often, they will be defined in the following.\nModel configurations\n\nThe first model configuration is denoted as SLS, which stands for mall Lorenz ystem . It is the Lorenz system described with the sets of equations 7.1 and the number of centroids is \\(K=10\\). Furthermore, the model was trained with \\(\\vec{\\beta }_{tr} = [\\beta_0 = 28 ; \\, \\beta_{end} = 33], \\, n_{\\beta, tr} = 7\\), where the training model parameter values \\(\\vec{\\beta}_{tr}\\) are chosen to start from \\(\\beta_0 = 28\\) and end at \\(\\beta_{end} = 33\\), where the total number of linearly distributed model parameter values is \\(n_{\\beta, tr} = 7\\).\nThe second model is referred to as LS20. It is also a Lorenz system 7.1, but with a higher number of centroids \\(K=20\\) and the following model configuration: \\(\\vec{\\beta }_{tr} = [\\, \\beta_0 = 24.75 ; \\, \\beta_{end} = 53.75 \\,], \\, n_{\\beta, tr} = 60\\).\nThe third model is designated as FW15. It is based on the Four Wing set of equations 7.4 and an illustrative trajectory is given in figure 11.1 . The number of centroids is \\(K=15\\) and it is constructed with the following configuration \\(\\vec{\\beta }_{tr} = [\\, \\beta_0 = 8 ; \\, \\beta_{end} = 11 \\,], \\, n_{\\beta, tr} = 13\\).\n\n\n\nFigure 11.1— FW15 7.4 trajectory for \\(\\beta = 8\\)"
  },
  {
    "objectID": "Data/1_Writing/3_Task/1_Track_Results.html",
    "href": "Data/1_Writing/3_Task/1_Track_Results.html",
    "title": "12  Tracking results",
    "section": "",
    "text": "In this section, some outputs of tracking data and workflow, described in subsection 9.0.1, shall be presented . After that, in short, the current CNMccontrol-oriented Cluster-based Network Modeling shall be compared to first CNMc \nFirst, two illustrative solutions for the assignment problem from the final path, as explained in subsection 9.0.1, are provided in figures 12.1 (c) and 12.2 (c) . The axes are denoted as \\(c_k\\) and \\(c_p\\) and represent the labels of the \\(\\beta_j\\) and \\(\\beta_i\\) centroids, respectively. The color bar on the right side informs about the euclidean distance, which is equivalent to the cost. Above the solution of the assignment problem in figures 12.1 (c) and 12.2 (c), the corresponding \\(\\beta_i\\) and \\(\\beta_j\\) centroid labels are given in the respective two figures, i.e., 12.1 (a), 12.1 (b) and 12.2 (a), 12.2 (b) .\n\n\n\n\n\n\n(a) Ordered state, \\(\\beta_i =32.167\\)\n\n\n\n\n\n(b) Ordered state, \\(\\beta_j = 33\\)\n\n\n\n\n\n\n\n(c) Solution to the assignment problem\n\n\n\nFigure 12.1— Illustrative solution for the assignment problem, \\(\\beta_i =32.167,\\, \\beta_j = 33 ,\\, K =10\\)\n\n\n\n\nThe centroid \\(c_{k=1} (\\beta_j = 33)\\) has its lowest cost to \\(c_{p=3} (\\beta_i = 32.167)\\). In this case, this is also the solution for the assignment problem, outlined by the blue cross. However, the solution to the linear sum assignment problem is not always to choose the minimal cost for one inter \\(\\beta\\) match. It could be that one centroid in \\(\\beta_i\\) is to found the closest centroid to multiple centroids in \\(\\beta_j\\). Matching only based on the minimal distance does not include the restriction that exactly one centroid from \\(\\beta_i\\) must be matched with exactly one centroid from \\(\\beta_j\\). The latter demand is incorporated in the solution of the linear sum assignment problem. \n\n\n\n\n\n\n(a) Ordered state, \\(\\beta_i =31.333\\)\n\n\n\n\n\n(b) Ordered state, \\(\\beta_j = 32.167\\)\n\n\n\n\n\n\n\n(c) Solution to the assignment problem\n\n\n\nFigure 12.2— Illustrative solution for the assignment problem, \\(\\beta_i =31.333,\\, \\beta_j = 32.167, \\,K =10\\)\n\n\nComparing figure 12.1 (c) with the second example in figure 12.2 (c), it can be observed that the chosen inter \\(\\beta\\) centroid matches can have very different shapes. This can be seen by looking at the blue crosses. Furthermore, paying attention to the remaining possible inter \\(\\beta\\) centroid matches, it can be stated that there is a clear trend, i.e., the next best inter \\(\\beta\\) centroid match has a very high increase in its cost. For example, considering the following inter \\(\\beta\\) match. With \\(c_{k=1} (\\beta_j = 32.167)\\) and \\(c_{p=1} (\\beta_i = 31.333)\\), the minimal cost is around \\(cost_{min} \\approx 0.84\\). The next best option jumps to \\(cost_{second} = 13.823\\). These jumps can be seen for each inter \\(\\beta\\) match in figure in both depicted figures 12.1 (c) and 12.2 (c) . The key essence behind this finding is that for the chosen number of centroids \\(K\\) of this dynamical model (Lorenz system 7.1), no ambiguous regions, as explained at the beginning of this chapter, occur.\nNext, the tracking result of 3 different systems shall be viewed. The tracked state for SLS is depicted in figures 12.3 . In each of the figures, one centroid is colored blue that denotes the first centroid in the sequence of the underlying trajectory. Within the depicted range \\(\\vec{\\beta}\\), it can be observed, that each label across the \\(\\vec{\\beta}\\) is labeled as expected. No single ambiguity or mislabeling can be seen. In other words, it highlights the high performance of the tracking algorithm.\n\n\n\n\n\n\n\n\n\n\n\n\\(\\beta =28\\)\n\n\n\n\n\n\\(\\beta = 28.833\\)\n\n\n\n\n\n\n\n\\(\\beta = 31.333\\)\n\n\n\n\n\n\\(\\beta = 33\\)\n\n\n\nFigure 12.3— Tracked states for SLS, \\(K = 10,\\, \\vec{\\beta} = [\\, 28, \\, 28.333, \\, 31.333, \\, 31.14, \\, 33 \\, ]\\)\n\n\n\n\n\n\nThe second model is the LS20, i.e, \\(K= 20,\\, \\vec{\\beta }_{tr} = [\\, \\beta_0 = 24.75 ; \\, \\beta_{end} = 53.75 \\,], \\, n_{\\beta,tr} = 60\\). The outcome is depicted in figures 12.4 . It can be noted that \\(\\beta = 24.75\\) and \\(\\beta = 30.648\\) exhibit very similar results to the SLS model. The same is true for intermediate \\(\\beta\\) values, i.e., \\(24.75 \\leq \\beta \\lessapprox 30.648\\). However, with \\(\\beta \\gtrapprox 30.64\\) as depicted for \\(\\beta = 31.14\\), one centroid, i.e. the centroid with the label \\(20\\) in the right ear appears unexpectedly. With this, a drastic change to the centroid placing network is imposed. Looking at the upcoming \\(\\beta\\) these erratic changes are found again.\n\n\n\n\n\n\n\n\n\n\\(\\beta =24.75\\)\n\n\n\n\n\n\\(\\beta = 28.682\\)\n\n\n\n\n\n\n\n\\(\\beta = 30.648\\)\n\n\n\n\n\n\\(\\beta = 31.140\\)\n\n\n\n\n\n\n\n\\(\\beta = 42.936\\)\n\n\n\n\n\n\\(\\beta = 53.750\\)\n\n\n\nFigure 12.4— Tracked states for LS20, \\(K = 20,\\, \\vec{\\beta} = [\\, 24.75, \\, 28.682, \\, 30.648, \\, 31.14, \\, 31.14,\\) \\(42.936, \\, 53.75 \\, ]\\)\n\n\n\n\n\nGenerating a tracked state with these discontinuous cluster network deformations even manually can be considered hard to impossible because tracking demands some kind of similarity. If two cluster networks differ too much from each other, then necessarily at least tracked label is going to be unsatisfying. Hence, it would be wrong to conclude that the tracking algorithm is not performing well, but rather the clustering algorithm itself or the range of \\(\\vec{\\beta}\\) must be adapted. If the range of \\(\\vec{\\beta}\\) is shortened, multiple models can be trained and tracked.\nThe third model is referred to as FW15. Figures in 12.5 show the tracked state for 4 different \\(\\beta\\) values. It can be observed that for \\(\\beta = 11\\) the centroid placing has changed notably to the other \\(\\beta\\) values, thus tracking the centroids in the center for \\(\\beta = 11\\) becomes unfavorable. Overall, however, the tracked state results advocate the performance of the tracking algorithm.\n\n\n\n\n\n\n\n\n\n\\(\\beta =8\\)\n\n\n\n\n\n\\(\\beta = 8.25\\)\n\n\n\n\n\n\n\n\\(\\beta = 10\\)\n\n\n\n\n\n\\(\\beta = 11\\)\n\n\n\nFigure 12.5— Tracked states for FW15, \\(K = 15,\\, \\vec{\\beta} = [\\, 8, \\, 8.25, \\, 10, \\, 11 \\, ]\\)\n\n\n\n\n\nIt can be concluded that the tracking algorithm performs remarkably well. However, when the cluster placing network is abruptly changed from one \\(\\beta\\) to the other \\(\\beta\\), the tracking outcome gets worse and generates sudden cluster network deformation. As a possible solution, splitting up the \\(\\vec{\\beta}_{tr}\\) range into smaller \\(\\vec{\\beta}_{tr,i}\\) ranges, can be named. This is not only seen for the LS20, but also for other dynamical systems as illustratively shown with the center area of the FW15 system for \\(\\beta= 11\\)."
  },
  {
    "objectID": "Data/1_Writing/3_Task/2_Mod_CPE.html",
    "href": "Data/1_Writing/3_Task/2_Mod_CPE.html",
    "title": "13  CPE modeling results",
    "section": "",
    "text": "In this section, results to the CPECentroid Position Evolution modeling explained in subsection 10.0.1, shall be presented and assessed . First, a selection of equations, which defines the CPECentroid Position Evolution are given for one model configuration. Next, representative plots of the CPECentroid Position Evolution for different models are analyzed. Finally, the predicted centroid position is compared with the actual clustered centroid position.\nModeling the CPE returns, among other results, analytical equations. These equations describe the behavior of the centroid positions across the range \\(\\vec{\\beta}\\) and can also be used for making predictions for \\(\\vec{\\beta}_{unseen}\\). The model configuration for which they are be presented is SLS, i.e. Lorenz system 7.1, \\(K= 10,\\, \\vec{\\beta }_{tr} = [\\, \\beta_0 = 28 ; \\, \\beta_{end} =33 \\,], \\, n_{\\beta, tr} = 7\\). The analytical CPECentroid Position Evolution expressions are listed in 13.1 to 13.3 for the centroids \\([\\,1,\\, 2,\\,7\\,]\\), respectively. Recalling that the behavior across the 3 different axes (x, y, z) can vary greatly, each axis has its own regression model \\((\\tilde x,\\, \\tilde y,\\, \\tilde z)\\). Thus, for each label, 3 different analytical expressions are provided. \n\n\n\n\n\\[\n\\begin{equation}\n    \\begin{aligned}\n        \\tilde x &= -0.1661 \\, cos(3  \\, \\beta) \\\\\n        \\tilde y &=  -0.1375 \\, cos(3 \\,  \\beta) \\\\\n        \\tilde z &=  0.8326 \\, \\beta\n    \\end{aligned}\n\\end{equation} \\tag{13.1}\\]\n\n\n\n\n\n\nFigure 13.1— SLS, CPE model for centroid: 1\n\n\n\n\n\n\n\n\\[\n\\begin{equation}\n    \\begin{aligned}\n    \\tilde x &= 0.1543 \\, sin(3 \\, \\beta) + 0.2446 \\, cos(3 \\, \\beta) \\\\\n    \\tilde y &= 0.2638 \\, sin(3 \\, \\beta) + 0.4225 \\, cos(3 \\, \\beta) \\\\\n    \\tilde z &= 0.4877 \\, \\beta\n\\end{aligned}\n\\label{eq_28}\n\\end{equation} \\tag{13.2}\\]\n\n\n\n\n\n\nFigure 13.2— SLS, CPE model for centroid: 2\n\n\n\n\n\n\n\n\\[\n      \\begin{equation}\n        \\begin{aligned}\n            \\tilde x &= -0.1866 \\, \\beta + 0.133 \\, sin(3 \\, \\beta) \\\\\n            & \\quad + 0.1411 \\, cos(3 \\, \\beta) \\\\\n            \\tilde y &= -0.3 \\, \\beta \\\\\n            \\tilde z &= -1.0483+ 0.6358 \\,\\beta\n        \\end{aligned}\n        \\label{eq_29}\n      \\end{equation}  \\tag{13.3}\\]\n\n\n\n\n\n\nFigure 13.3— SLS, CPE model for centroid: 7\n\n\n\n\nRight to the equations the corresponding plots are depicted in figures 13.1 to 13.3 . Here, the blue and green curves indicate true and modeled CPE, respectively. Each of the figures supports the choice of allowing each axis to be modeled separately. The z-axis appears to undergo less alteration or to be more linear than the x- and y-axis. If a model is supposed to be valid for all 3 axes, a more complex model, i.e., a higher of terms, is required. Although more flexible models fit training data increasingly better, they tend to overfit. In other words, complex models capture the trained data well but could exhibit oscillations for \\(\\vec{\\beta}_{unseen}\\). The latter is even more severe when the model is employed for extrapolation. The difference between interpolation and extrapolation is that for extrapolation the prediction is made with \\(\\beta_{unseen}\\) which are not in the range of the trained \\(\\vec{\\beta}_{tr}\\). Therefore, less complexity is preferred.\nNext, the performance of predicting the centroid for \\(\\vec{\\beta}_{unseen}\\) is elaborated. For this purpose, figures 13.4 to 13.7 shall be examined. All figures depict the original centroid positions, which are obtained through the clustering step in green and the predicted centroid positions in blue. On closer inspection, orange lines connecting the true and predicted centroid positions can be identified. Note, that they will only be visible if the deviation between the true and predicted state is high enough. Figures 13.4 (a) an 13.4 (b) show the outcome for SLS with \\(\\beta_{unseen} = 28.5\\) and \\(\\beta_{unseen} = 32.5\\), respectively. Visually, both predictions are very close to the true centroid positions. Because of this high performance in showed in figures 13.5 (a) and 13.5 (b) two examples for extrapolation are given for \\(\\beta_{unseen} = 26.5\\) and \\(\\beta_{unseen} = 37\\), respectively. For the first one, the outcome is very applicable. In contrast, \\(\\beta_{unseen} = 37\\) returns some deviations which are notably high. \n\n\n\n\n\n\n\n(a) \\(\\beta_{unseen} = 28.5\\)\n\n\n\n\n\n(b) \\(\\beta_{unseen} = 32.5\\)\n\n\n\nFigure 13.4— SLS, original vs. modeled centroid position, \\(\\beta_{unseen} = 28.5\\) and \\(\\beta_{unseen} = 32.5\\)\n\n\n\n\n\n\n\n\n\n(a) \\(\\beta_{unseen} = 26.5\\)\n\n\n\n\n\n(b) \\(\\beta_{unseen} = 37\\)\n\n\n\nFigure 13.5— SLS, original vs. modeled centroid position, extrapolated \\(\\beta_{unseen} = 26.5\\) and \\(\\beta_{unseen} = 37\\)\n\n\n\n\n\n\n\n\n\n\\(\\beta_{unseen} = 31.75\\)\n\n\n\n\n\n\\(\\beta_{unseen} = 51.75\\)\n\n\n\nFigure 13.6— LS20, original vs. modeled centroid position, \\(\\beta_{unseen} = 31.75\\) and \\(\\beta_{unseen} = 51.75\\)\n\n\n\n\n\n\n\n\n\n\\(\\beta_{unseen} = 8.7\\)\n\n\n\n\n\n\\(\\beta_{unseen} = 10.1\\)\n\n\n\nFigure 13.7— FW15, original vs. modeled centroid position, \\(\\beta_{unseen} = 8.7\\) and \\(\\beta_{unseen} = 10.1\\)\n\n\nQuantitative measurements are performed by applying the Mean Square Error (MSE) following equation 13.4 . The variables are denoted as the number of samples \\(n\\), which in this case is equal to the number of centroids \\(n = K\\), the known \\(f(x_k)\\) and the predicted \\(y_k\\) centroid position. \\[\n\\begin{equation}\n        MSE = \\frac{1}{n} \\, \\sum_{i=1}^n \\left(f(x_k) - y_k\\right)^2\n        \\label{eq_30_MSE}\n\\end{equation}\n\\tag{13.4}\\]\nThe measured MSE errors for all displayed results are summarized in table 13.1 . The MSE for results of \\(\\beta_{unseen} = 28.5\\) and \\(\\beta_{unseen} = 32.5\\) in figures 13.4 is \\(0.622\\) and \\(0.677\\), respectively. Consequently, the performance of CNMccontrol-oriented Cluster-based Network Modeling is also confirmed quantitatively. Figures in 13.6 illustrate the outcome for LS20 for \\(\\beta_{unseen} = 31.75\\) and \\(\\beta_{unseen} = 51.75\\). In section 12 it is explained that for LS20 cluster network deformations appear . Nevertheless, the outcome visually and quantitatively endorses the CPE modeling capabilities. Figures in 13.7 depict the outcome for FW15 for \\(\\beta_{unseen} = 8.7\\) and \\(\\beta_{unseen} = 10.1\\). A few orange lines are visible, however overall the outcome is very satisfactory.\n\n\nTable 13.1— MSE for different Model configurations and \\(\\vec{\\beta}_{unseen}\\)\n\n\nFigure\nModel\n\\(\\boldsymbol{\\beta_{unseen}}\\)\nMSE\n\n\n\n\n13.4\nSLS\n\\(28.5\\)\n\\(0.622\\)\n\n\n13.4\nSLS\n\\(32.5\\)\n\\(0.677\\)\n\n\n13.5\nSLS\n\\(26.5\\)\n\\(1.193\\)\n\n\n13.5\nSLS\n\\(37\\)\n\\(5.452\\)\n\n\n13.6\nLS20\n\\(31.75\\)\n\\(1.857\\)\n\n\n13.6\nLS20\n\\(51.75\\)\n\\(2.536\\)\n\n\n13.7\nFW15\n\\(8.7\\)\n\\(1.617\\)\n\n\n13.7\nFW15\n\\(10.1\\)\n\\(1.5\\)\n\n\n\n\nIt can be concluded that the CPE modeling performance is satisfying. In the case of a few cluster network deformations, CNMccontrol-oriented Cluster-based Network Modeling is capable of providing acceptable results. However, as shown with SLS, if the model’s training range \\(\\vec{\\beta}_{tr}\\) and the number of \\(K\\) was selected appropriately, the MSE can be minimized."
  },
  {
    "objectID": "Data/1_Writing/3_Task/3_SVD_NMF.html",
    "href": "Data/1_Writing/3_Task/3_SVD_NMF.html",
    "title": "14  Transition properties modeling",
    "section": "",
    "text": "In the subsection 10.0.2, it has been explained that CNMccontrol-oriented Cluster-based Network Modeling has two built-in modal decomposition methods for the \\(\\boldsymbol Q / \\boldsymbol T\\) tensors, i .e., SVDSingular Value Decomposition and NMF. There are two main concerns for which performance measurements are needed. First, in subsection 14.0.1, the computational costs of both methods are examined . Then in subsection 14.0.2, the SVDSingular Value Decomposition and NMFNon-negative Matrix Factorization prediction quality will be presented and assessed .\n\n14.0.1 Computational cost\nIn this subsection, the goal is to evaluate the computational cost of the two decomposition methods implemented in CNMccontrol-oriented Cluster-based Network Modeling. NMFNon-negative Matrix Factorization was already used in first CNMc and it was found to be one of the most computational expensive tasks. With an increasing model order \\(L\\) it became the most computational task by far, which is acknowledged by (Pierzyna 2021). The run time was one of the main reasons why SVDSingular Value Decomposition should be implemented in CNMccontrol-oriented Cluster-based Network Modeling. To see if SVDSingular Value Decomposition can reduce run time, both methods shall be compared.\nFirst, it is important to mention that NMFNon-negative Matrix Factorization is executed for one single predefined mode number \\(r\\). It is possible that a selected \\(r\\) is not optimal, since \\(r\\) is a parameter that depends not only on the chosen dynamical system but also on other parameters, e.g., the number of centroids \\(K\\) and training model parameter values \\(n_{\\beta, tr}\\), as well as NMFNon-negative Matrix Factorization specific attributes. These are the maximal number of iterations in which the optimizer can converge and tolerance convergence. However, to find an appropriate \\(r\\), NMFNon-negative Matrix Factorization can be executed multiple times with different values for \\(r\\). Comparing the execution time of NMFNon-negative Matrix Factorization with multiple invocations against SVDSingular Value Decomposition can be regarded as an unbalanced comparison. Even though for a new dynamical system and its configuration the optimal \\(r_{opt}\\) for NMFNon-negative Matrix Factorization is most likely to be found over a parameter study, for the upcoming comparison, the run time of one single NMFNon-negative Matrix Factorization solution is measured.\nThe model for this purpose is SLS. Since SLS is trained with the output of 7 pairwise different model parameter values \\(n_{\\beta,tr} = 7\\), the maximal rank in SVDSingular Value Decomposition is limited to 7. Nevertheless, allowing NMFNon-negative Matrix Factorization to find a solution \\(r\\) was defined as \\(r=9\\), the maximal number of iterations in which the optimizer can converge is 10 million and the convergence tolerance is \\(1\\mathrm{e}{-6}\\). Both methods can work with sparse matrices. However, the SVDSingular Value Decomposition solver is specifically designed to solve sparse matrices. The measured times for decomposing the \\(\\boldsymbol Q / \\boldsymbol T\\) tensors for 7 different \\(L\\) are listed in table 14.1 . It can be observed that for SVDSingular Value Decomposition up to \\(L=6\\), the computational time for both \\(\\boldsymbol Q / \\boldsymbol T\\) tensors is less than 1 second. Such an outcome is efficient for science and industry applications. With \\(L=7\\) a big jump in time for both \\(\\boldsymbol Q / \\boldsymbol T\\) is found. However, even after this increase, the decomposition took around 5 seconds, which still is acceptable.\n\n\nTable 14.1— Execution time for SLS of and for different \\(L\\)\n\n\n\n\n\n\n\n\n\n\\(L\\)\nSVD \\(\\boldsymbol Q\\)\nNMF \\(\\boldsymbol Q\\)\nSVD \\(\\boldsymbol T\\)\nNMF \\(\\boldsymbol T\\)\n\n\n\n\n\\(1\\)\n\\(2 \\,\\mathrm{e}{-4}\\) s\n\\(64\\) s\n\\(8 \\, \\mathrm{e}{-05}\\) s\n\\(3 \\, \\mathrm{e}{-2}\\) s\n\n\n\\(2\\)\n\\(1 \\, \\mathrm{e}{-4}\\) s\n\\(8 \\, \\mathrm{e}{-2}\\) s\n\\(1 \\, \\mathrm{e}{-4}\\) s\n\\(1\\) h\n\n\n\\(3\\)\n\\(2 \\, \\mathrm{e}{-4}\\) s\n\\(10\\) s\n\\(2 \\, \\mathrm{e}{-4}\\) s\n\\(0.1\\) s\n\n\n\\(4\\)\n\\(4 \\, \\mathrm{e}{-3}\\) s\n\\(20\\) s\n\\(7 \\, \\mathrm{e}{-3}\\) s\n\\(1.5\\) h\n\n\n\\(5\\)\n\\(6 \\, \\mathrm{e}{-2}\\) s\n\\(&gt; 3\\) h\n\\(3 \\, \\mathrm{e}{-2}\\) s\n-\n\n\n\\(6\\)\n\\(0.4\\) s\n-\n\\(0.4\\) s\n-\n\n\n\\(7\\)\n\\(5.17\\) s\n-\n\\(4.52\\) s\n-\n\n\n\n\nCalculating \\(\\boldsymbol Q\\) with NMFNon-negative Matrix Factorization for \\(L=1\\) already takes 64 seconds. This is more than SVDSingular Value Decomposition demanded for \\(L=7\\). The \\(\\boldsymbol T\\) tensor on the other is much faster and is below a second. However, as soon as \\(L=2\\) is selected, \\(\\boldsymbol T\\) takes 1 full hour, \\(L=4\\) more than 1 hour. The table for NMFNon-negative Matrix Factorization is not filled, since running \\(\\boldsymbol Q\\) for \\(L=5\\) was taking more than 3 hours, but still did not finish. Therefore, the time measurement was aborted. This behavior was expected since it was already mentioned in (Pierzyna 2021). Overall, the execution time for NMFNon-negative Matrix Factorization is not following a trend, e.g., computing \\(\\boldsymbol T\\) for \\(L=3\\) is faster than for \\(L=2\\) and \\(\\boldsymbol Q\\) for \\(L=4\\) is faster than for \\(L=1\\). In other words, there is no obvious rule, on whether even a small \\(L\\) could lead to hours of run time.\nIt can be concluded that SVDSingular Value Decomposition is much faster than NMFNon-negative Matrix Factorization and it also shows a clear trend, i.e. the computation time is expected to increase with \\(L\\). NMFNon-negative Matrix Factorization on the other hand first requires an appropriate mode number \\(r\\), which most likely demands a parameter study. However, even for a single NMFNon-negative Matrix Factorization solution, it can take hours. With increasing \\(L\\) the amount of run time is generally expected to increase, even though no clear rule can be defined. Furthermore, it needs to be highlighted that NMFNon-negative Matrix Factorization was tested on a small model, where \\(n_{\\beta,tr} = 7\\). The author of this thesis experienced an additional increase in run time when \\(n_{\\beta,tr}\\) is selected higher. Also, executing NMFNon-negative Matrix Factorization on multiple dynamical systems or model configurations might become infeasible in terms of time. Finally, with the implementation of SVDSingular Value Decomposition, the bottleneck in modeling \\(\\boldsymbol Q / \\boldsymbol T\\) could be eliminated.\n\n\n14.0.2 Prediction quality\nIn this subsection, the quality of the SVDSingular Value Decomposition and NMFNon-negative Matrix Factorization \\(\\boldsymbol Q / \\boldsymbol T\\) predictions are evaluated. The used model configuration for this aim is SLS. First, only the \\(\\boldsymbol Q\\) output with SVDSingular Value Decomposition followed by NMFNon-negative Matrix Factorization shall be analyzed and compared. Then, the same is done for the \\(\\boldsymbol T\\) output.\nIn order to see how many modes \\(r\\) were chosen for SVDSingular Value Decomposition the two figures 14.1 and 14.2 are shown. It can be derived that with \\(r = 4\\), \\(99 \\%\\) of the information content could be captured. The presented results are obtained for \\(\\boldsymbol Q\\) and \\(L =1\\).\n\n\n\n\n\nFigure 14.1— SLS, , cumulative energy of \\(\\boldsymbol Q\\) for \\(L=1\\)\n\n\n\n\n\nFigure 14.2— SLS, , singular values of \\(\\boldsymbol Q\\) for \\(L=1\\)\n\n\n\n\nFigures 14.3 (a) to 14.3 (c) depict the original \\(\\boldsymbol{Q}(\\beta_{unseen} = 28.5)\\), which is generated with CNM, the CNMccontrol-oriented Cluster-based Network Modeling predicted \\(\\boldsymbol{\\tilde{Q}}(\\beta_{unseen} = 28.5)\\) and their deviation \\(| \\boldsymbol{Q}(\\beta_{unseen} = 28.5) - \\boldsymbol{\\tilde{Q}}(\\beta_{unseen} = 28.5) |\\), respectively. In the graphs, the probabilities to move from centroid \\(c_p\\) to \\(c_j\\) are indicated. Contrasting figure 14.3 (a) and 14.3 (b) exhibits barely noticeable differences. For highlighting present deviations, the direct comparison between the CNMCluster-based Network Modeling and CNMccontrol-oriented Cluster-based Network Modeling predicted \\(\\boldsymbol Q\\) tensors is given in figure 14.3 (c) . It can be observed that the highest value is \\(max( \\boldsymbol{Q}(\\beta_{unseen} = 28.5) - \\boldsymbol{\\tilde{Q}}(\\beta_{unseen} = 28.5) |) \\approx 0.0697 \\approx 0.07\\). Note that all predicted \\(\\boldsymbol Q\\) and \\(\\boldsymbol T\\) tensors are obtained with RFRandom Forest as the regression model. \n\n\n\n\n\n\n(a) Original \\(\\boldsymbol{Q}(\\beta_{unseen} = 28.5)\\)\n\n\n\n\n\n(b) predicted \\(\\boldsymbol{\\tilde{Q}}(\\beta_{unseen} = 28.5)\\)\n\n\n\n\n\n\n\n(c) Deviation \\(| \\boldsymbol{Q}(\\beta_{unseen}) - \\boldsymbol{\\tilde{Q}}(\\beta_{unseen}) |\\)\n\n\n\nFigure 14.3— SLS, SVDSingular Value Decomposition, original \\(\\boldsymbol{Q}(\\beta_{unseen} = 28.5)\\) , CNMccontrol-oriented Cluster-based Network Modeling predicted \\(\\boldsymbol{\\tilde{Q}}(\\beta_{unseen} = 28.5)\\) and deviation \\(| \\boldsymbol{Q}(\\beta_{unseen} = 28.5) - \\boldsymbol{\\tilde{Q}}(\\beta_{unseen} = 28.5) |\\) for \\(L=1\\)\n\n\nThe same procedure shall now be performed with NMF. The results are depicted in figures 14.4 and 14.5 . Note that the original CNMCluster-based Network Modeling \\(\\boldsymbol{Q}(\\beta_{unseen} = 28.5)\\) does not change, thus figure 14.3 (a) can be reused. By exploiting figure 14.6, it can be observed that the highest deviation for the NMFNon-negative Matrix Factorization version is \\(max( \\boldsymbol{Q}(\\beta_{unseen} = 28.5) - \\boldsymbol{\\tilde{Q}}(\\beta_{unseen} = 28.5) |) \\approx 0.0699 \\approx 0.07\\). The maximal error of NMFNon-negative Matrix Factorization \\((\\approx 0.0699)\\) is slightly higher than that of SVDSingular Value Decomposition \\((\\approx 0.0697)\\). Nevertheless, both methods have a very similar maximal error and seeing visually other significant differences is hard. \n\n\n\n\n\nFigure 14.4— predicted \\(\\boldsymbol{\\tilde{Q}}(\\beta_{unseen} = 28.5)\\)\n\n\n\n\n\nFigure 14.5— Deviation \\(| \\boldsymbol{Q}(\\beta_{unseen} ) - \\boldsymbol{\\tilde{Q}}(\\beta_{unseen} ) |\\)\n\n\n\n\n\nSLS, NMFNon-negative Matrix Factorization, CNMccontrol-oriented Cluster-based Network Modeling predicted \\(\\boldsymbol{\\tilde{Q}}(\\beta_{unseen} = 28.5)\\) and deviation \\(| \\boldsymbol{Q}(\\beta_{unseen} = 28.5) - \\boldsymbol{\\tilde{Q}}(\\beta_{unseen} = 28.5) |\\) for \\(L=1\\)\n\n\n\nIn order to have a quantifiable error value, the Mean absolute error (MAE) following equation 10.4 is leveraged. The MAE errors for SVDSingular Value Decomposition and NMFNon-negative Matrix Factorization are \\(MAE_{SVD} = 0.002 580 628\\) and \\(MAE_{NMF} = 0.002 490 048\\), respectively. NMFNon-negative Matrix Factorization is slightly better than SVDSingular Value Decomposition with \\(MAE_{SVD} - MAE_{NMF} \\approx 1 \\mathrm{e}{-4}\\), which can be considered to be negligibly small. Furthermore, it must be stated that SVDSingular Value Decomposition was only allowed to use \\(r_{SVD} = 4\\) modes, due to the \\(99 \\%\\) energy demand, whereas NMFNon-negative Matrix Factorization used \\(r_{NMF} = 9\\) modes. Given that SVDSingular Value Decomposition is stable in computational time, i.e., it is not assumed that for low \\(L\\), the computational cost scales up to hours, SVDSingular Value Decomposition is the clear winner for this single comparison. \nFor the sake of completeness, the procedure shall be conducted once as well for the \\(\\boldsymbol T\\) tensor. For this purpose figures 14.6 to 14.10 shall be considered. It can be inspected that the maximal errors for SVDSingular Value Decomposition and NMFNon-negative Matrix Factorization are \\(max( \\boldsymbol{T}(\\beta_{unseen} = 28.5) - \\boldsymbol{\\tilde{T}}(\\beta_{unseen} = 28.5) |) \\approx 0.126\\) and \\(max( \\boldsymbol{T}(\\beta_{unseen} = 28.5) - \\boldsymbol{\\tilde{T}}(\\beta_{unseen} = 28.5) | ) \\approx 0.115\\), respectively. The MAE errors are, \\(MAE_{SVD} = 0.002 275 379\\) and \\(MAE_{NMF} = 0.001 635 510\\). NMFNon-negative Matrix Factorization is again slightly better than SVDSingular Value Decomposition with \\(MAE_{SVD} - MAE_{NMF} \\approx 6 \\mathrm{e}{-4}\\), which is a deviation of \\(\\approx 0.06 \\%\\) and might also be considered as negligibly small. \n\n\n\n\n\n\nFigure 14.6— Original \\(\\boldsymbol{T}(\\beta_{unseen} = 28.5)\\)\n\n\n\n\n\nFigure 14.7— predicted \\(\\boldsymbol{\\tilde{T}}(\\beta_{unseen} = 28.5)\\)\n\n\n\n\n\n\n\nFigure 14.8— Deviation \\(| \\boldsymbol{T}(\\beta_{unseen}) - \\boldsymbol{\\tilde{T}}(\\beta_{unseen}) |\\)\n\n\n\n\n\nSLS, SVDSingular Value Decomposition, original \\(\\boldsymbol{T}(\\beta_{unseen} = 28.5)\\), predicted \\(\\boldsymbol{\\tilde{T}}(\\beta_{unseen} = 28.5)\\) and deviation \\(| \\boldsymbol{T}(\\beta_{unseen} = 28.5) - \\boldsymbol{\\tilde{T}}(\\beta_{unseen} = 28.5) |\\) for \\(L=1\\)\n\n\n\n\n\n\n\n\n\nFigure 14.9— predicted \\(\\boldsymbol{\\tilde{T}}(\\beta_{unseen} = 28.5)\\)\n\n\n\n\n\nFigure 14.10— Deviation \\(| \\boldsymbol{T}(\\beta_{unseen}) - \\boldsymbol{\\tilde{T}}(\\beta_{unseen}) |\\)\n\n\n\n\n\nSLS, NMFNon-negative Matrix Factorization, CNMccontrol-oriented Cluster-based Network Modeling predicted \\(\\boldsymbol{\\tilde{T}}(\\beta_{unseen} = 28.5)\\) and deviation \\(| \\boldsymbol{T}(\\beta_{unseen} = 28.5) - \\boldsymbol{\\tilde{T}}(\\beta_{unseen} = 28.5) |\\) for \\(L=1\\)\n\n\n\nAdditional MAE errors for different \\(L\\) and \\(\\beta_{unseen}= 28.5,\\, \\beta_{unseen}= 32.5\\) are collected in table 14.2 . First, it can be outlined that regardless of the chosen method, SVDSingular Value Decomposition or NMFNon-negative Matrix Factorization, all encountered MAE errors are very small. Consequently, it can be recorded that CNMccontrol-oriented Cluster-based Network Modeling convinces with an overall well approximation of the \\(\\boldsymbol Q / \\boldsymbol T\\) tensors. Second, comparing SVDSingular Value Decomposition and NMFNon-negative Matrix Factorization through their respective MAE errors, it can be inspected that the deviation of both is mostly in the order of \\(\\mathcal{O} \\approx 1 \\mathrm{e}{-2}\\). It is a difference in \\(\\approx 0.1 \\%\\) and can again be considered to be insignificantly small.\nDespite this, NMFNon-negative Matrix Factorization required the additional change given in equation 14.1, which did not apply to SVDSingular Value Decomposition. The transition time entries at the indexes where the probability is positive should be positive as well. Yet, this is not always the case when NMFNon-negative Matrix Factorization is executed. To correct that, these probability entries are manually set to zero. This rule was also actively applied to the results presented above. Still, the outcome is very satisfactory, because the modeling errors are found to be small. \n\n\nTable 14.2— SLS, Mean absolute error for different \\(L\\) and two \\(\\beta_{unseen}\\)\n\n\n\n\n\n\n\n\n\n\n\\(L\\)\n\\(\\beta_{unseen}\\)\n\\(\\boldsymbol{MAE}_{SVD, \\boldsymbol Q}\\)\n\\(\\boldsymbol{MAE}_{NMF, \\boldsymbol Q}\\)\n\\(\\boldsymbol{MAE}_{SVD, \\boldsymbol T}\\)\n\\(\\boldsymbol{MAE}_{NMF, \\boldsymbol T}\\)\n\n\n\n\n\\(1\\)\n\\(28.5\\)\n\\(0.002580628\\)\n\\(0.002490048\\)\n\\(0.002275379\\)\n\\(0.001635510\\)\n\n\n\\(1\\)\n\\(32.5\\)\n\\(0.003544923\\)\n\\(0.003650155\\)\n\\(0.011152145\\)\n\\(0.010690052\\)\n\n\n\\(2\\)\n\\(28.5\\)\n\\(0.001823848\\)\n\\(0.001776276\\)\n\\(0.000409955\\)\n\\(0.000371242\\)\n\n\n\\(2\\)\n\\(32.5\\)\n\\(0.006381635\\)\n\\(0.006053059\\)\n\\(0.002417142\\)\n\\(0.002368680\\)\n\n\n\\(3\\)\n\\(28.5\\)\n\\(0.000369228\\)\n\\(0.000356817\\)\n\\(0.000067680\\)\n\\(0.000062964\\)\n\n\n\\(3\\)\n\\(32.5\\)\n\\(0.001462458\\)\n\\(0.001432738\\)\n\\(0.000346298\\)\n\\(0.000343520\\)\n\n\n\\(4\\)\n\\(28.5\\)\n\\(0.000055002\\)\n\\(0.000052682\\)\n\\(0.000009420\\)\n\\(0.000008790\\)\n\n\n\\(4\\)\n\\(32.5\\)\n\\(0.000215147\\)\n\\(0.000212329\\)\n\\(0.000044509\\)\n\\(0.000044225\\)\n\n\n\n\n\\[\n\\begin{equation}\n    \\begin{aligned}\n        TGZ := \\boldsymbol T ( \\boldsymbol Q  &gt; 0) \\leq 0 \\\\\n        \\boldsymbol Q ( TGZ) := 0\n    \\end{aligned}\n    \\label{eq_33}\n\\end{equation}\n\\tag{14.1}\\]\nIn summary, both methods NMFNon-negative Matrix Factorization and SVDSingular Value Decomposition provide a good approximation of the \\(\\boldsymbol Q / \\boldsymbol T\\) tensors. The deviation between the prediction quality of both is negligibly small. However, since SVDSingular Value Decomposition is much faster than NMFNon-negative Matrix Factorization and does not require an additional parameter study, the recommended decomposition method is SVDSingular Value Decomposition. Furthermore, it shall be highlighted that SVDSingular Value Decomposition used only \\(r = 4\\) modes for the \\(\\boldsymbol Q\\) case, whereas for NMFNon-negative Matrix Factorization \\(r=9\\) were used. Finally, as a side remark, all the displayed figures and the MAE errors are generated and calculated with CNMCluster-based Network Modeling’s default implemented methods. \n\n\n\n\nPierzyna, Maximilian. 2021. “Control-Oriented Cluster-Basednetwork Modeling.” Research report, TU Braunschweig."
  },
  {
    "objectID": "Data/1_Writing/3_Task/4_SVD_Regression.html",
    "href": "Data/1_Writing/3_Task/4_SVD_Regression.html",
    "title": "15  Transition property regression models",
    "section": "",
    "text": "In this section, the results of the 3 different regression methods, Random Forest (RF), AdaBoost and Gaussian Process (GP) are compared. All the 3 regressors are implemented in CNMccontrol-oriented Cluster-based Network Modeling and can be selected via settings.py. The utilized model configuration is SLS and the decomposition method is SVDSingular Value Decomposition.\nFirst, it shall be noted that CNMccontrol-oriented Cluster-based Network Modeling also offers the possibility to apply pySindy. However, pySindy has struggled to represent the training data in the first place, thus it cannot be employed for predicting \\(\\beta_{unseen}\\). The latter does not mean that pySindy is not applicable for the construction of a surrogate model for the decomposed \\(\\boldsymbol Q / \\boldsymbol T\\) modes, but rather that the selected candidate library was not powerful enough. Nevertheless, only results for the 3 initially mentioned regressors will be discussed.\nIn figures 15.1 to 15.6 the true (dashed) and the approximation (solid) of the first 4 \\(\\boldsymbol Q / \\boldsymbol T\\) modes are shown for the methods RF, AdaBoost and GP, respectively. To begin with, it can be noted that the mode behavior over different model parameter values \\(mod(\\beta)\\) is discontinuous, i.e., it exhibits spikes or sudden changes. In figures 15.1 and 15.2 it can be observed that RFRandom Forest reflects the actual behavior of \\(mod(\\beta)\\) quite well. However, it encounters difficulties in capturing some spikes. AdaBoost on the other hand proves in figures 15.3 and 15.4 to represent the spikes better. Overall, AdaBoost outperforms RFRandom Forest in mirroring training data. \n\n\n\n\n\nFigure 15.1— \\(\\boldsymbol Q\\)\n\n\n\n\n\nFigure 15.2— \\(\\boldsymbol T\\)\n\n\n\n\n\nSLS, SVDSingular Value Decomposition, \\(\\boldsymbol Q / \\boldsymbol T\\) modes approximation with RFRandom Forest for \\(L=1\\)\n\n\n\n\n\n\n\n\nFigure 15.3— \\(\\boldsymbol Q\\)\n\n\n\n\n\nFigure 15.4— \\(\\boldsymbol T\\)\n\n\n\n\n\nSLS, SVDSingular Value Decomposition, \\(\\boldsymbol Q / \\boldsymbol T\\) mode approximation with AdaBoost for \\(L=1\\)\n\n\n\n\n\n\n\n\nFigure 15.5— \\(\\boldsymbol Q\\)\n\n\n\n\n\nFigure 15.6— \\(\\boldsymbol T\\)\n\n\n\n\n\nSLS, SVDSingular Value Decomposition, \\(\\boldsymbol Q / \\boldsymbol T\\) mode approximation with GP for \\(L=1\\)\n\n\n\nGaussian Process (GP) is a very powerful method for regression. Often this is also true when reproducing \\(mod(\\beta)\\). However, there are cases where the performance is insufficient, as shown in figures 15.5 and 15.6 . Applying GP results in absolutely incorrect predicted tensors \\(\\boldsymbol{\\tilde{Q}}(\\beta_{unseen}),\\, \\boldsymbol{\\tilde{T}}(\\beta_{unseen})\\), where too many tensors entries are wrongly forced to zero. Therefore, \\(\\boldsymbol{\\tilde{Q}}(\\beta_{unseen}),\\, \\boldsymbol{\\tilde{T}}(\\beta_{unseen})\\) will eventually lead to an unacceptably high deviation from the original trajectory. Consequently, the GP regression is not applicable for the decomposed \\(\\boldsymbol Q / \\boldsymbol T\\) modes without further modification.\nThe two remaining regressors are Random Forest (RF) and AdaBoost. Although AdaBoost is better at capturing the true modal behavior \\(mod(\\beta)\\), there is no guarantee that it will always be equally better at predicting the modal behavior for unseen model parameter values \\(mod(\\beta_{unseen})\\). In table 15.1 the MAE errors for different \\(L\\) and \\(\\beta_{unseen} = [\\, 28 .5,\\, 32.5\\,]\\) are provided. Since the table exhibits much information, the results can also be read qualitatively through the graphs 15.7 and 15.8 for \\(\\beta_{unseen} = 28.5\\) and \\(\\beta_{unseen} = 32.5\\), respectively. For the visual inspection, it is important to observe the order of the vertical axis scaling. It can be noted that the MAE errors themselves and the deviation between the RFRandom Forest and AdaBoost MAE errors are very low. Thus, it can be stated that RFRandom Forest as well ad AdaBoost are both well-suited regressors.\n\n\nTable 15.1— SLS, Mean absolute error for comparing and AdaBoost different \\(L\\) and two \\(\\beta_{unseen}\\)\n\n\n\n\n\n\n\n\n\n\n\\(L\\)\n\\(\\beta_{unseen}\\)\n\\(\\boldsymbol{MAE}_{RF, \\boldsymbol Q}\\)\n\\(\\boldsymbol{MAE}_{AdaBoost, \\boldsymbol Q}\\)\n\\(\\boldsymbol{MAE}_{RF, \\boldsymbol T}\\)\n\\(\\boldsymbol{MAE}_{AdaBoost, \\boldsymbol T}\\)\n\n\n\n\n\\(1\\)\n\\(28.5\\)\n\\(0.002580628\\)\n\\(0.002351781\\)\n\\(0.002275379\\)\n\\(0.002814208\\)\n\n\n\\(1\\)\n\\(32.5\\)\n\\(0.003544923\\)\n\\(0.004133114\\)\n\\(0.011152145\\)\n\\(0.013054876\\)\n\n\n\\(2\\)\n\\(28.5\\)\n\\(0.001823848\\)\n\\(0.001871858\\)\n\\(0.000409955\\)\n\\(0.000503748\\)\n\n\n\\(2\\)\n\\(32.5\\)\n\\(0.006381635\\)\n\\(0.007952153\\)\n\\(0.002417142\\)\n\\(0.002660403\\)\n\n\n\\(3\\)\n\\(28.5\\)\n\\(0.000369228\\)\n\\(0.000386292\\)\n\\(0.000067680\\)\n\\(0.000082808\\)\n\n\n\\(3\\)\n\\(32.5\\)\n\\(0.001462458\\)\n\\(0.001613434\\)\n\\(0.000346298\\)\n\\(0.000360097\\)\n\n\n\\(4\\)\n\\(28.5\\)\n\\(0.000055002\\)\n\\(0.000059688\\)\n\\(0.000009420\\)\n\\(0.000011500\\)\n\n\n\\(4\\)\n\\(32.5\\)\n\\(0.000215147\\)\n\\(0.000230404\\)\n\\(0.000044509\\)\n\\(0.000046467\\)\n\n\n\\(5\\)\n\\(28.5\\)\n\\(0.000007276\\)\n\\(0.000007712\\)\n\\(0.000001312\\)\n\\(0.000001600\\)\n\n\n\\(5\\)\n\\(32.5\\)\n\\(0.000028663\\)\n\\(0.000030371\\)\n\\(0.000005306\\)\n\\(0.000005623\\)\n\n\n\\(6\\)\n\\(28.5\\)\n\\(0.000000993\\)\n\\(0.000052682\\)\n\\(0.000000171\\)\n\\(0.000000206\\)\n\n\n\\(6\\)\n\\(32.5\\)\n\\(0.000003513\\)\n\\(0.000003740\\)\n\\(0.000000629\\)\n\\(0.000000668\\)\n\n\n\\(7\\)\n\\(28.5\\)\n\\(0.000000136\\)\n\\(0.000000149\\)\n\\(0.000000023\\)\n\\(0.000000031\\)\n\n\n\\(7\\)\n\\(32.5\\)\n\\(0.000000422\\)\n\\(0.000000454\\)\n\\(0.000000078\\)\n\\(0.000000082\\)\n\n\n\n\n\n\n\n\n\n\n(a) \\(\\boldsymbol Q\\)\n\n\n\n\n\n(b) \\(\\boldsymbol T\\)\n\n\n\nFigure 15.7— SLS, Mean absolute error for comparing RFRandom Forest and AdaBoost different \\(L\\) and \\(\\beta_{unseen} = 28.5\\)\n\n\n\n\n\n\n\n\n(a) \\(\\boldsymbol Q\\)\n\n\n\n\n\n(b) \\(\\boldsymbol T\\)\n\n\n\nFigure 15.8— SLS, Mean absolute error for comparing RFRandom Forest and AdaBoost different \\(L\\) and \\(\\beta_{unseen} = 32.5\\)\n\n\nIn summary, the following can be said, RFRandom Forest and AdaBoost are both performing well in regression. Furthermore, no clear winner between the two regressors can be detected. The third option GP is dismissed as it sometimes has unacceptably low regression performance. Finally, there is the possibility to use pySindy, however, for that, an appropriate candidate library must be defined."
  },
  {
    "objectID": "Data/1_Writing/3_Task/5_Pred.html",
    "href": "Data/1_Writing/3_Task/5_Pred.html",
    "title": "16  CNMc predictions",
    "section": "",
    "text": "In this section, some representative outputs for the CNMccontrol-oriented Cluster-based Network Modeling predicted trajectories shall be discussed. For that, first, the quality measurement abilities implemented in CNMccontrol-oriented Cluster-based Network Modeling are elaborated. Next, the model SLS is analyzed and explained in detail in the subsection 16.0.1. Finally, the outcome for other models shall be presented briefly in subsection 16.0.2.\nThere are several methods implemented in CNMccontrol-oriented Cluster-based Network Modeling to assess the quality of the predicted trajectories. The first one is the autocorrelation, which will be calculated for all \\(\\vec{\\beta}_{unseen}\\) and all provided \\(\\vec{L}\\), for the true, CNMCluster-based Network Modeling and CNMccontrol-oriented Cluster-based Network Modeling predicted trajectories. As usual, the output is plotted and saved as HTML files for a feature-rich visual inspection. For qualitative assessment, the MAE errors are calculated for all \\(\\vec{\\beta}_{unseen}\\) and \\(\\vec{L}\\) for two sets. The first set consists of the MAE errors between the true and the CNMCluster-based Network Modeling predicted trajectories. The second set contains the MAE errors between the true and the CNMccontrol-oriented Cluster-based Network Modeling predicted trajectories. Both sets are plotted as MAE errors over \\(L\\) and stored as HTML files. Furthermore, the one \\(L\\) value which exhibits the least MAE error is printed in the terminal and can be found in the log file as well. \nThe second technique is the CPDCluster Probability Distribution, which will also be computed for all the 3 trajectories, i.e., true, CNMCluster-based Network Modeling and CNMccontrol-oriented Cluster-based Network Modeling predicted trajectories. The CPDCluster Probability Distribution depicts the probability of being at one centroid \\(c_i\\). For each \\(\\vec{\\beta}_{unseen}\\) and all \\(L\\) the CPDCluster Probability Distribution is plotted and saved. The third method displays all the 3 trajectories in the state space. Moreover, the trajectories are plotted as 2-dimensional graphs, i.e., each axis as a subplot over the time \\(t\\). The final method calculates the MAE errors of the \\(\\boldsymbol Q / \\boldsymbol T\\) tensors for all \\(L\\).\nThe reason why more than one quality measurement method is integrated into CNMccontrol-oriented Cluster-based Network Modeling is that CNMccontrol-oriented Cluster-based Network Modeling should be able to be applied to, among other dynamical systems, chaotic systems. The motion of the Lorenz system 7.1 is not as complex as of the, e.g., the Four Wing 7.4 . Nevertheless, the Lorenz system already contains quasi-random elements, i.e., the switching from one ear to the other cannot be captured exactly with a surrogate mode. However, the characteristic of the Lorenz system and other chaotic dynamical systems as well can be replicated. In order to prove the latter, more than one method to measure the prediction quality is required.\n\n16.0.1 Assessment of SLS\nIn this subsection, the prediction capability for the SLS will be analyzed in detail. All the presented output is generated with SVDSingular Value Decomposition as the decomposition method and RFRandom Forest as the \\(\\boldsymbol Q / \\boldsymbol T\\) regressor.\nThe final objective of CNMccontrol-oriented Cluster-based Network Modeling is to capture the characteristics of the original trajectory. However, it is important to outline that CNMccontrol-oriented Cluster-based Network Modeling is trained with the CNMCluster-based Network Modeling predicted trajectories. Thus, the outcome of CNMccontrol-oriented Cluster-based Network Modeling highly depends on the ability of CNMCluster-based Network Modeling to represent the original data. Consequently, CNMccontrol-oriented Cluster-based Network Modeling can only be as effective as CNMCluster-based Network Modeling is in the first place, with the approximation of the true data. Figures 16.1 and 16.2 show the true, CNMCluster-based Network Modeling and CNMccontrol-oriented Cluster-based Network Modeling predicted trajectories and a focused view on the CNMCluster-based Network Modeling and CNMccontrol-oriented Cluster-based Network Modeling trajectories, respectively. The output was generated for \\(\\beta_{unseen} = 28.5\\) and \\(L =1\\). First, it can be observed that CNMCluster-based Network Modeling is not able to capture the full radius of the Lorenz attractor. This is caused by the low chosen number of centroids \\(K=10\\). Furthermore, as mentioned at the beginning of this chapter, the goal is not to replicate the true data one-to-one, but rather to catch the significant behavior of any dynamic system. With the low number of centroids \\(K\\), CNMCluster-based Network Modeling extracts the characteristics of the Lorenz system well. Second, the other aim for CNMccontrol-oriented Cluster-based Network Modeling is to match the CNMCluster-based Network Modeling data as closely as possible. Both figures 16.1 and 16.2 prove that CNMccontrol-oriented Cluster-based Network Modeling has fulfilled its task very well. \n\n\n\n\n\nFigure 16.1— True, and predicted trajectories\n\n\n\n\n\nFigure 16.2— and predicted trajectories\n\n\n\n\n\nSLS, \\(\\beta_{unseen}=28.5,\\, L=1\\), true, CNMCluster-based Network Modeling and CNMccontrol-oriented Cluster-based Network Modeling predicted trajectories\n\n\n\nA close-up of the movement of the different axes is shown in the picture 16.3 . Here, as well, the same can be observed as described above. Namely, the predicted CNMccontrol-oriented Cluster-based Network Modeling trajectory is not a one-to-one reproduction of the original trajectory. However, the characteristics, i.e., the magnitude of the motion in all 3 directions (x, y, z) and the shape of the oscillations, are very similar to the original trajectory. Note that even though the true and predicted trajectories are utilized to assess, whether the characteristical behavior could be extracted, a single evaluation based on the trajectories is not sufficient and often not advised or even possible. In complex systems, trajectories can change rapidly while dynamical features persist (Fernex, Semaan, and Noack 2021). In CNMccontrol-oriented Cluster-based Network Modeling the predicted trajectories are obtained through the CNMCluster-based Network Modeling propagation, which itself is based on a probabilistic model, i.e. the \\(\\boldsymbol Q\\) tensor. Thus, matching full trajectories becomes even more unrealistic. The latter two statements highlight yet again that more than one method of measuring quality is needed. To further support the generated outcome the autocorrelation and CPDCluster Probability Distribution in figure 16.4 and 16.5, respectively, shall be considered. It can be inspected that the CNMCluster-based Network Modeling and CNMccontrol-oriented Cluster-based Network Modeling autocorrelations are matching the true autocorrelation in the shape favorably well. Nonetheless, the degree of reflecting the magnitude fully decreases quite fast. Considering the CPDCluster Probability Distribution, it can be recorded that the true CPDCluster Probability Distribution could overall be reproduced satisfactorily.\n\n\n\nFigure 16.3— SLS, \\(\\beta_{unseen}=28.5, \\, L=1\\), true, and predicted trajectories as 2d graphs\n\n\n\n\n\n\n\nFigure 16.4— autocorrelation\n\n\n\n\n\nFigure 16.5— \n\n\n\n\n\nSLS, \\(\\beta_{unseen}= 28.5, \\, L =1\\), autocorrelation and CPDCluster Probability Distribution for true, CNMCluster-based Network Modeling and CNMccontrol-oriented Cluster-based Network Modeling predicted trajectories\n\n\n\nTo illustrate the influence of \\(L\\), figure 16.6 shall be viewed. It depicts the MAE error for the true and CNMccontrol-oriented Cluster-based Network Modeling predicted trajectories for \\(\\beta_{unseen}= [\\, 28.5,\\, 32.5 \\, ]\\) with \\(L\\) up to 7. It can be observed that the choice of \\(L\\) has an impact on the prediction quality measured by autocorrelation. For \\(\\beta_{unseen}=28.5\\) and \\(\\beta_{unseen}=32.5\\), the optimal \\(L\\) values are \\(L = 2\\) and \\(L = 7\\), respectively. To emphasize it even more that with the choice of \\(L\\) the prediction quality can be regulated, figure 16.7 shall be considered. It displays the 3 autocorrelations for \\(L = 7\\). Matching the shape of the true autocorrelation was already established with \\(L =1\\) as shown in figure 16.4 . In addition to that, \\(L=7\\) improves by matching the true magnitude. Finally, it shall be mentioned that similar results have been accomplished with other \\(K\\) tested values, where the highest value was \\(K =50\\).\n\n\n\n\n\nFigure 16.6— SLS, MAE error for true and predicted autocorrelations for \\(\\beta_{unseen}= [\\, 28.5,\\) \\(32.5 \\, ]\\) and different values of \\(L\\)\n\n\n\n\n\nFigure 16.7— SLS, \\(\\beta_{unseen}=32.5, \\, L=7\\), and predicted autocorrelation\n\n\n\n\n\n\n16.0.2 Results of further dynamical systems\nIn this subsection, the prediction results for other models will be displayed. The chosen dynamical systems with their configurations are the following. \nAll the presented outputs were generated with SVDSingular Value Decomposition as the decomposition method and RFRandom Forest as the \\(\\boldsymbol Q / \\boldsymbol T\\) regressor. Furthermore, the B-spline interpolation in the propagation step of CNMCluster-based Network Modeling was replaced with linear interpolation. The B-spline interpolation was originally utilized for smoothing the motion between two centroids. However, it was discovered for a high number of \\(K\\), the B-spline interpolation is not able to reproduce the motion between two centroids accurately, but rather would impose unacceptable high deviations or oscillations into the predictions. This finding is also mentioned in (Pierzyna 2021) and addressed as one of first CNMc’s limitations.\nTwo illustrative examples of the unacceptable high deviations caused by the B-spline interpolation are given in figures 16.8 and 16.9 . The results are obtained for LS20 for \\(\\beta = 31.75\\) and \\(\\beta = 51.75\\) with \\(L=3\\). In figures 16.8 (a) and 16.8 (b) it can be inspected that the B-spline interpolation has a highly undesired impact on the predicted trajectories. In Contrast to that, in figures, 16.8 (c) and 16.8 (d), where linear interpolation is utilized, no outliers are added to the predictions. The impact of the embedded outliers, caused by the B-spline interpolation, on the autocorrelation is depicted in figures 16.9 (a) and 16.9 (b) . The order of the deviation between the true and the CNMccontrol-oriented Cluster-based Network Modeling predicted autocorrelation can be grasped by inspecting the vertical axis scale. Comparing it with the linear interpolated autocorrelations, shown in figures 16.9 (c) and 16.9 (d), it can be recorded that the deviation between the true and predicted autocorrelations is significantly lower than in the B-spline interpolation case. \nNevertheless, it is important to highlight that the B-spline interpolation is only a tool for smoothing the motion between two centroids. The quality of the modeled \\(\\boldsymbol Q / \\boldsymbol T\\) cannot be assessed directly by comparing the trajectories and the autocorrelations. To stress that the CPDCluster Probability Distribution in figure 16.10 and 16.11 shall be considered. It can be observed that CPDCluster Probability Distribution does not represent the findings of the autocorrelations, i.e., the true and predicted behavior agree acceptably overall. This is because the type of interpolation has no influence on the modeling of the probability tensor \\(\\boldsymbol Q\\). Thus, the outcome with the B-spline interpolation should not be regarded as an instrument that enables making assumptions about the entire prediction quality of CNMccontrol-oriented Cluster-based Network Modeling. The presented points underline again the fact that more than one method should be considered to evaluate the prediction quality of CNMccontrol-oriented Cluster-based Network Modeling. \n\n\n\n\n\n\n(a) Trajectories, B-spline, \\(\\beta_{unseen} = 31.75\\)\n\n\n\n\n\n(b) Trajectories, B-spline, \\(\\beta_{unseen} = 51.75\\)\n\n\n\n\n\n\n\n(c) Trajectories, linear, \\(\\beta_{unseen} = 31.75\\)\n\n\n\n\n\n(d) Trajectories, linear, \\(\\beta_{unseen} = 51.75\\)\n\n\n\nFigure 16.8— Illustrative undesired oscillations cased by the B-spline interpolation and its impact on the predicted trajectory contrasted with linear interpolation, LS20, \\(\\beta = 31.75\\) and \\(\\beta =51.75\\), \\(L=3\\)\n\n\n\n\n\n\n\n\n\n(a) Autocorrelations, B-spline, \\(\\beta = 31.75\\)\n\n\n\n\n\n(b) Autocorrelations, B-spline, \\(\\beta_{unseen} = 51.75\\)\n\n\n\n\n\n\n\n(c) Autocorrelations, linear, \\(\\beta = 31.75\\)\n\n\n\n\n\n(d) Autocorrelations, linear, \\(\\beta_{unseen} = 51.75\\)\n\n\n\nFigure 16.9— Illustrative undesired oscillations cased by the B-spline interpolation and its impact on the predicted autocorrelations contrasted with linear interpolation, LS20, \\(\\beta = 31.75\\) and \\(\\beta =51.75\\), \\(L=3\\)\n\n\n\n\n\n\n\n\nFigure 16.10— , \\(\\beta = 31.75\\)\n\n\n\n\n\nFigure 16.11— , \\(\\beta_{unseen} = 51.75\\)\n\n\n\n\n\nIllustrative the B-spline interpolation and its impact on the CPDsCluster Probability Distributions, LS20, \\(\\beta = 31.75\\) and \\(\\beta =51.75\\), \\(L=3\\)\n\n\n\nThe results generated with the above mentioned linear interpolation for FW50, Rössler15 and TS15 are depicted in figures 16.12 to 16.14, respectively. Each of them consists of an illustrative trajectory, 3D and 2D trajectories, the autocorrelations, the CPDCluster Probability Distribution and the MAE error between the true and CNMccontrol-oriented Cluster-based Network Modeling predicted trajectories for a range of \\(\\vec{L}\\) and some \\(\\vec{\\beta}_{unseen}\\). The illustrative trajectory includes arrows, which provide additional information. First, the direction of the motion, then the size of the arrows represents the velocity of the system. Furthermore, the change in the size of the arrows is equivalent to a change in the velocity, i.e., the acceleration. Systems like the TS15 exhibit a fast change in the size of the arrows, i.e., the acceleration is nonlinear. The more complex the behavior of the acceleration is, the more complex the overall system becomes. The latter statement serves to emphasize that CNMccontrol-oriented Cluster-based Network Modeling can be applied not only to rather simple systems such as the Lorenz attractor (Lorenz 1963), but also to more complex systems such as the FW50 and TS15.\nAll in all, the provided results for the 3 systems are very similar to those already explained in the previous subsection 16.0.1. Thus, the results presented are for demonstration purposes and will not be discussed further. However, the 3 systems also have been calculated with different values for \\(K\\). For FW50, the range of \\(\\vec{K}= [\\, 15, \\, 30, \\, 50 \\, ]\\) was explored with the finding that the influence of \\(K\\) remained quite small. For Rössler15 and TS15, the ranges were chosen as \\(\\vec{K}= [\\, 15, \\, 30, \\, 100\\,]\\) and \\(\\vec{K}= [\\, 15, \\, 75 \\,]\\), respectively. The influence of \\(K\\) was found to be insignificant also for the latter two systems.   \n\n\n\n\n\n\nIllustrative trajectory \\(\\beta = 9\\)\n\n\n\n\n\nTrajectories, \\(\\beta_{unseen} = 8.1\\)\n\n\n\n\n\n\n\n2D-trajectories, \\(\\beta_{unseen} = 8.1\\)\n\n\n\n\n\nAutocorrelations, \\(\\beta_{unseen} = 8.1\\)\n\n\n\n\n\n\n\n, \\(\\beta_{unseen} = 8.1\\)\n\n\n\n\n\nAutocorrelations \\(MAE(L,\\, \\beta_{unseen})\\)\n\n\n\nFigure 16.12— Results for FW50, \\(\\beta_{unseen} = 8.1, \\, L= 2\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllustrative trajectory \\(\\beta = 7.5\\)\n\n\n\n\n\nTrajectories, \\(\\beta_{unseen} = 9.6\\)\n\n\n\n\n\n\n\n2D-trajectories, \\(\\beta_{unseen} = 9.6\\)\n\n\n\n\n\nAutocorrelations, \\(\\beta_{unseen} = 9.6\\)\n\n\n\n\n\n\n\n, \\(\\beta_{unseen} = 9.6\\)\n\n\n\n\n\nAutocorrelations \\(MAE(L,\\, \\beta_{unseen})\\)\n\n\n\nFigure 16.13— Results for Rössler15, \\(\\beta_{unseen} = 9.6,\\, L =1\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllustrative trajectory \\(\\beta = 11\\)\n\n\n\n\n\nTrajectories, \\(\\beta_{unseen} = 5.1\\)\n\n\n\n\n\n\n\n2D-trajectories, \\(\\beta_{unseen} = 5.1\\)\n\n\n\n\n\nAutocorrelations, \\(\\beta_{unseen} = 5.1\\)\n\n\n\n\n\n\n\n, \\(\\beta_{unseen} = 5.1\\)\n\n\n\n\n\nAutocorrelations \\(MAE(L,\\, \\beta_{unseen})\\)\n\n\n\nFigure 16.14— Results for TS15, \\(\\beta_{unseen} = 5.1,\\, L =2\\)\n\n\n\n\n\n\n\n\n\nFernex, Daniel, Richard Semaan, and Bernd Noack. 2021. “Generalized Cluster-Based Network Model for an Actuated Turbulent Boundary Layer.” In AIAA Scitech 2021 Forum. American Institute of Aeronautics; Astronautics. https://doi.org/10.2514/6.2021-1333.\n\n\nLorenz, Edward N. 1963. “Deterministic Nonperiodic Flow.” Journal of Atmospheric Sciences 20 (2): 130–41.\n\n\nPierzyna, Maximilian. 2021. “Control-Oriented Cluster-Basednetwork Modeling.” Research report, TU Braunschweig."
  },
  {
    "objectID": "Data/1_Writing/4_Task/1_Concl.html",
    "href": "Data/1_Writing/4_Task/1_Concl.html",
    "title": "17  Conclusion and outlook",
    "section": "",
    "text": "A tool to capture and predict the behavior of nonlinear complex and chaotic dynamical systems within a range of some model parameter values \\(\\vec{\\beta}\\) is presented. The tool is called control-oriented Cluster-based Network Modeling (CNMc). It could be shown that CNMccontrol-oriented Cluster-based Network Modeling is able to capture and make predictions for the well-known Lorenz system (Lorenz 1963). With having removed one of the major limitations in the first attempt of CNMccontrol-oriented Cluster-based Network Modeling (Pierzyna 2021), the introduced version of CNMccontrol-oriented Cluster-based Network Modeling is not limited to any dimension anymore. Furthermore, the restriction of the dynamical system to exhibit a circular trajectory is removed. Since these two limitations could be removed, the presented CNMccontrol-oriented Cluster-based Network Modeling can be applied to any general dynamical system. To outline this fact, 10 different dynamical systems are implemented by default in CNMccontrol-oriented Cluster-based Network Modeling. Some of these dynamical systems were used to evaluate CNMccontrol-oriented Cluster-based Network Modeling performance. It could be observed that CNMccontrol-oriented Cluster-based Network Modeling is not only able to deal with the Lorenz system but also with more complicated systems. The objective is to represent the characteristic behavior of general dynamical systems that could be fulfilled on all tested systems.\nThe third limitation which could be removed is the unacceptably high computational time with Non-negative Matrix Factorization (NMF). It could be highlighted that Singular Value Decomposition (SVD) returns the decomposition within seconds, instead of hours, without adding any inaccuracies. Moreover, SVDSingular Value Decomposition does not require a parameter study. Executing NMFNon-negative Matrix Factorization once is already computational more expensive than SVDSingular Value Decomposition, but with a parameter study, NMFNon-negative Matrix Factorization becomes even more unsatisfactory in the application. By having removed these 3 major limitations, CNMccontrol-oriented Cluster-based Network Modeling can be applied to any dynamical system within a reasonable computational time on a regular laptop. Nevertheless, CNMccontrol-oriented Cluster-based Network Modeling contains algorithms, which highly benefit from computational power. Thus, faster outputs are achieved with clusters. Also, with having replaced the B-spline interpolation through linear interpolation, the predicted trajectories can be visually depicted appropriately without the Another important introduced advancement is that the B-spline interpolation was replaced by linear interpolation. This allows to avoid unreasonably high interpolation errors (oscillations) of the trajectory and enables an appropriate visualization. \nCNMccontrol-oriented Cluster-based Network Modeling Is written from scratch in a modular way such that implementing it into existing code, replacing employed algorithms with others is straightforward or used as a black-box function. All important parameters can be adjusted via one file (settings.py). Helpful post-processing features are part of CNMccontrol-oriented Cluster-based Network Modeling and can also be controlled with settings.py. Overall CNMccontrol-oriented Cluster-based Network Modeling includes a high number of features, e.g., a log file, storing results at desired steps, saving plots as HTML files which allow extracting further information about the outcome, the ability to execute multiple models consequentially, and activating and disabling each step of CNMccontrol-oriented Cluster-based Network Modeling. All displayed outputs in this thesis were generated with CNMccontrol-oriented Cluster-based Network Modeling. Finally, one limitation which remains shall be mentioned. The used SVDSingular Value Decomposition code receives sparse matrices, however, it returns a dense matrix. The consequence is that with high model orders \\(L\\), quickly multiple hundreds of gigabytes of RAM are required. The maximal \\(L\\) which could be achieved on the laptop of the author, which has 16 GB RAM, is \\(L=7\\).\nAs an outlook, a new SVDSingular Value Decomposition algorithm should be searched for or written from scratch. The demand for the new SVDSingular Value Decomposition solver is that it must receive sparse matrices and also returns the solution in form of sparse matrices. With that \\(L\\) could be increased, i.e., \\(L&gt;7\\). In this thesis, it could be shown that CNMccontrol-oriented Cluster-based Network Modeling can handle chaotic systems well. Thus, the next step could be, replacing the current data generation step, where differential equations are solved, with actual CFDComputational Fluid Dynamics data as input. Hence, the objective would be to apply CNMccontrol-oriented Cluster-based Network Modeling to real CFDComputational Fluid Dynamics data to predict flow fields.\n\n\n\n\nLorenz, Edward N. 1963. “Deterministic Nonperiodic Flow.” Journal of Atmospheric Sciences 20 (2): 130–41.\n\n\nPierzyna, Maximilian. 2021. “Control-Oriented Cluster-Basednetwork Modeling.” Research report, TU Braunschweig."
  },
  {
    "objectID": "Data/1_Writing/4_Task/2_Zusammen_Deutsch.html",
    "href": "Data/1_Writing/4_Task/2_Zusammen_Deutsch.html",
    "title": "18  Zusammenfassung auf Deutsch",
    "section": "",
    "text": "Die Arbeit wurde an der Technischen Universität Braunschweig geschrieben. Da diese Arbeit auf eine Fremdsprache geschrieben wurde, soll der Anforderung der TU-Braunschweig, dass eine Zusammenfassung auf Deutsch, welche etwa 1 DIN A4-Seite beträgt, nachgekommen werden. Zunächst wird kurz die Motivation dieser Master-Arbeit erklärt. Im Anschluss sollen die Ergebnisse im Kurzen erörtert werden.\nIn dieser Master-Arbeit war es Ziel, eine bereits bestehende Methode, das sog. control-oriented Cluster-based Network Modeling (CNMc), zu verbessern. Die Vorversion ist in (Pierzyna 2021) beschrieben. Hier konnte gezeigt werden, dass CNMccontrol-oriented Cluster-based Network Modeling für das Lorenz System, (Lorenz 1963) vielversprechende Approximationen zulässt. Das Lorenz System ist recht bekannt unter den chaotischen Systemen. Ein chaotisches System ist ein dynamisches System, was selbst durch Differenzialgleichungen beschrieben wird. Sinn von CNMccontrol-oriented Cluster-based Network Modeling ist daher, das Approximieren bzw. Vorhersagen von Trajektorien (zeitliche Lösung der Differenzialgleichung) von dynamischen Systemen. CNMccontrol-oriented Cluster-based Network Modeling wurde innerhalb der ersten Version speziell für das Lorenz System entwickelt, sodass es nicht für allgemeingültige dynamische System verwendet werden konnte. Die Limitierungen verlangten unter anderem, dass die Trajektorie kreisförmig seien müsse. Zudem, musste ein 3-dimensionales Problem vorliegen. Weiters kam hinzu, dass ein wichtiger Schritt in dem CNMccontrol-oriented Cluster-based Network Modeling Arbeitsablauf (Moden-Findung) mehrere Stunden in Anspruch nahm und somit die Anwendung von CNMccontrol-oriented Cluster-based Network Modeling unattraktiver machte. Aufgrund dessen, dass es Schwierigkeiten beim Ausführen der ersten CNMccontrol-oriented Cluster-based Network Modeling-Version gab, wurde CNMccontrol-oriented Cluster-based Network Modeling von neu programmiert.\nZunächst wurde der Code nun in der Form geschrieben, dass der Nutzer nach Belieben neue dynamische Systeme einfach hinzufügen kann. Standardmäßig kommt CNMccontrol-oriented Cluster-based Network Modeling bereits mit 10 verschiedenen dynamischen Systemen. Danach wurden zwei wichtige Limitierungen entfernt. Die Erste, CNMccontrol-oriented Cluster-based Network Modeling kann inzwischen mit jedem Verhalten der Trajektorie umgehen. In anderen Worten, die Trajektorie des dynamischen Systems muss nicht kreisförmig sein. Zweitens ist CNMccontrol-oriented Cluster-based Network Modeling nicht mehr durch die Anzahl der Dimension restriktiert. Vereinfacht ausgedrückt, ob CNMccontrol-oriented Cluster-based Network Modeling auf eine 3d oder eine andere beliege dimensionale Differenzialgleichung angewendet werden soll, spielt keine Rolle mehr. Für den Schritt, in welchem die Moden einer Daten-Matrix gefunden werden, stehen aktuell zwei verschiedene Möglichkeiten zu Verfügung, Non-negative Matrix Factorization (NMF) und Singular Value Decomposition (SVD). NMFNon-negative Matrix Factorization wurde bereits in der ersten Version von CNMccontrol-oriented Cluster-based Network Modeling verwendet. Doch wurde es dahingehend weiter verbessert, dass jetzt das Finden des wichtigen Parameters, der Anzahl der verwendeten Moden, automatisiert durchgeführt wird. Somit kann NMFNon-negative Matrix Factorization automatisiert auf unterschiedliche dynamische System angewendet werden. SVDSingular Value Decomposition ist die zweite Methode und wurde implementiert, um die hohe Rechenzeit des NMFNon-negative Matrix Factorization zu verhindern. Es konnte gezeigt werden, dass SVDSingular Value Decomposition tatsächlich, um ein vielfaches schneller als NMFNon-negative Matrix Factorization ist. Die Rechenzeit von SVDSingular Value Decomposition bewegt sich im Bereich von Sekunden, wohingegen NMFNon-negative Matrix Factorization mehrere Stunden in Anspruch nehmen kann. Auch wurde auch gezeigt, dass beide Methoden qualitativ gleichwertige Ergebnisse liefern.\nEine weitere wichtige Änderung, welche in der aktuellen CNMccontrol-oriented Cluster-based Network Modeling Version implementiert ist die, dass eine sog. B-Spline Interpolation durch eine lineare Interpolation ersetzt wurde. Als Folge können unangebracht hohe Interpolationsfehler (Oszillationen) der Trajektorie umgangen werden. Durch letztere Änderung können die Ergebnisse nun auch Graph dargestellt werden, ohne dass durch die B-Spline Interpolation eingebrachte Ausreißer eine visuelle Auswertung unmöglich machen.\nMit dieser Arbeit konnte gezeigt werden, dass CNMccontrol-oriented Cluster-based Network Modeling nicht nur für das Lorenz System, sondern für allgemeingültige dynamische Systeme verwendet werden kann. Hierfür wurden beispielsweise die Ergebnisse für drei andere dynamische Systeme gezeigt. Die aktuelle CNMccontrol-oriented Cluster-based Network Modeling Version wurde in einer modularen Art geschrieben, welche es erlaubt, einzelne Algorithmen leicht durch andere zu ersetzen. Jeder einzelne Haupt-Schritt in CNMccontrol-oriented Cluster-based Network Modeling kann aktiviert oder deaktiviert werden. Dadurch können bereits vorhanden Ergebnisse eingeladen werden, anstatt diese jedes Mal neu zu berechnen. Das Resultat ist eine hohe Ersparnis an Rechenzeit. CNMccontrol-oriented Cluster-based Network Modeling kommt mit vielen Features, über eine einzige Datei lässt sich der gesamte Ablauf von CNMccontrol-oriented Cluster-based Network Modeling steuern. Wodurch bestimmt werden kann, welche Parameter in den einzelnen Schritten verwendet werden, wo Ergebnisse abgespeichert und geladen werden sollen, sowie auch wo und ob die Ergebnisse visuell abgespeichert werden sollen. Die Resultate werden für die visuelle Inspektion als HTML-Dateien zur Verfügung gestellt. Damit ist es möglich weitere Informationen zu erhalten, wie beispielsweise, das Ablesen von Werten an bestimmten Stellen und anderen nützlichen Funktionen, wie etwa das Rotieren, Zoomen und Ausblenden einzelner Graphen. Das Ziel war es, dem Nutzer einen Post-Processor mitzugeben, sodass er auch ohne weitere kostenpflichtige Software visuelle Auswertungen vornehmen kann. Doch CNMccontrol-oriented Cluster-based Network Modeling hat auch eine log-Datei integriert, in welcher alle Ausgaben, wie unter anderem Ergebnisse einzelner Qualitätsmesstechniken (Metriken bzw. Normen) nachgelesen werden können.\nZusammenfassend lässt sich sagen, mit dieser Master-Thesis befindet sich CNMccontrol-oriented Cluster-based Network Modeling in einem Zustand, in welchem es für allgemeingültige dynamische Systeme angewendet werden kann. Das Implementieren von weiteren Systemen wurde vereinfacht und wichtige Limitierungen, wie Anzahl der Dimensional und unzulässig hohe Rechenzeit konnten beseitigt werden. Zudem ist das Tool gut dokumentiert, und bietet diverse Features an, worunter beispielsweise die Post-Processing Möglichkeiten inbegriffen sind.\n\n\n\n\nLorenz, Edward N. 1963. “Deterministic Nonperiodic Flow.” Journal of Atmospheric Sciences 20 (2): 130–41.\n\n\nPierzyna, Maximilian. 2021. “Control-Oriented Cluster-Basednetwork Modeling.” Research report, TU Braunschweig."
  },
  {
    "objectID": "Data/1_Writing/5_Additional/10_References.html",
    "href": "Data/1_Writing/5_Additional/10_References.html",
    "title": "19  References",
    "section": "",
    "text": "Argyris, John, Gunter Faust, Maria Haase, and Rudolf Friedrich. 2017.\nDie Erforschung Des Chaos. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-54546-1.\n\n\nArthur, David, and Sergei Vassilvitskii. 2006. “K-Means++: The\nAdvantages of Careful Seeding.” Stanford.\n\n\nBishop, Christopher. 2006. Pattern Recognition and Machine\nLearning. Springer. https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/.\n\n\nBoeing, Geoff. 2016. “Visual Analysis of Nonlinear Dynamical\nSystems: Chaos, Fractals, Self-Similarity and the Limits of\nPrediction.” Systems 4 (4): 37. https://doi.org/10.3390/systems4040037.\n\n\nBrunton, Steven L, Joshua L Proctor, and J Nathan Kutz. 2016.\n“Sparse Identification of Nonlinear Dynamics with Control\n(SINDYc).” IFAC-PapersOnLine 49 (18): 710–15.\n\n\nBrunton, Steven, and J Kutz. 2019. “Data-Driven Science and\nEngineering.” Cambridge University Press. https://doi.org/10.1017/9781108380690.\n\n\nButt, Javed. 2021. “Development of a Module for Mission Analysis\nfor a Gradient-Based Aerodynamic Shape Optimization Process.” TU\nBraunschweig. https://elib.dlr.de/144285/.\n\n\nCAO, Ying, Qi-Guang MIAO, Jia-Chen LIU, and Lin GAO. 2013.\n“Advance and Prospects of AdaBoost Algorithm.” Acta\nAutomatica Sinica 39 (6): 745–58. https://doi.org/https://doi.org/10.1016/S1874-1029(13)60052-X.\n\n\nChen, Guanrong, and Tetsushi Ueta. 1999. “Yet Another Chaotic\nAttractor.” International Journal of Bifurcation and\nChaos 9 (07): 1465–66.\n\n\nDevia Narvaez, Diana, German Velez, and Diego Devia Narvaez. 2018.\n“Bifurcation Analysis of the van Der Pol Oscillator.”\nContemporary Engineering Sciences 11 (85): 4245–52. https://doi.org/10.12988/ces.2018.88389.\n\n\nFernex, Daniel, Bernd R. Noack, and Richard Semaan. 2021.\n“Cluster-Based Network Modelingfrom Snapshots to\nComplex Dynamical Systems.” Science Advances 7 (25). https://doi.org/10.1126/sciadv.abf5006.\n\n\nFernex, Daniel, Richard Semaan, and Bernd Noack. 2021.\n“Generalized Cluster-Based Network Model for an Actuated Turbulent\nBoundary Layer.” In AIAA Scitech 2021 Forum. American\nInstitute of Aeronautics; Astronautics. https://doi.org/10.2514/6.2021-1333.\n\n\nFrochte, Jörg. 2020. Maschinelles Lernen. Carl Hanser Verlag\nGmbH & Co. KG. https://doi.org/10.3139/9783446463554.\n\n\nGerbrands, Jan J. 1981. “On the Relationships Between SVD, KLT and\nPCA.” Pattern Recognition 14 (1-6): 375–81.\n\n\nGrebogi, Celso, Edward Ott, Steven Pelikan, and James A. Yorke. 1984.\n“Strange Attractors That Are Not Chaotic.” Physica D:\nNonlinear Phenomena 13 (1): 261–68. https://doi.org/https://doi.org/10.1016/0167-2789(84)90282-3.\n\n\nHarris, Charles R., K. Jarrod Millman, Stéfan J. van der Walt, Ralf\nGommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020.\n“Array Programming with NumPy.”\nNature 585 (7825): 357–62. https://doi.org/10.1038/s41586-020-2649-2.\n\n\nHunter, J. D. 2007. “Matplotlib: A 2D Graphics\nEnvironment.” Computing in Science & Engineering 9\n(3): 90–95. https://doi.org/10.1109/MCSE.2007.55.\n\n\nInc., Plotly Technologies. 2015. “Collaborative Data\nScience.” Montreal, QC: Plotly Technologies Inc. 2015. https://plot.ly.\n\n\nKaiser, Eurika, Bernd R Noack, Laurent Cordier, Andreas Spohn, Marc\nSegond, Markus Abel, Guillaume Daviller, Jan Östh, Siniša Krajnović, and\nRobert K Niven. 2014. “Cluster-Based Reduced-Order Modelling of a\nMixing Layer.” Journal of Fluid Mechanics 754: 365–414.\n\n\nKaptanoglu, Alan, Brian De Silva, Urban Fasel, Kadierdan Kaheman, Andy\nGoldschmidt, Jared Callaham, Charles Delahunt, et al. 2022.\n“PySINDy: A Comprehensive Python Package for Robust Sparse System\nIdentification.” Journal of Open Source Software 7 (69):\n3994. https://doi.org/10.21105/joss.03994.\n\n\n“K-Means Finding Set of Initial Points.” n.d. https://theory.stanford.edu/~sergei/slides/BATS-Means.pdf.\n\n\n“K-Means++ Visual Explanation.” n.d. https://theory.stanford.edu/~sergei/slides/BATS-Means.pdf.\n\n\nKutz, Prof. J. Nathan. 2022. “AMATH 568Advanced Differential\nEquations: Asymptotics & Perturbations.”\n\n\nLambe, Andrew B., and Joaquim R. R. A. Martins. 2012. “Extensions\nto the Design Structure Matrix for the Description of Multidisciplinary\nDesign, Analysis, and Optimization Processes.” Structural and\nMultidisciplinary Optimization 46: 273–84. https://doi.org/10.1007/s00158-012-0763-y.\n\n\nLanger, Stefan, Axel Schwöppe, and Norbert Kroll. 2014. “The DLR\nFlow Solver TAU - Status and Recent Algorithmic Developments.” In\n52nd Aerospace Sciences Meeting. https://elib.dlr.de/90979/.\n\n\nLee, Daniel D, and H Sebastian Seung. 1999. “Learning the Parts of\nObjects by Non-Negative Matrix Factorization.” Nature\n401 (6755): 788–91.\n\n\nLi, Chunbiao, Ihsan Pehlivan, Julien Clinton Sprott, and Akif Akgul.\n2015. “A Novel Four-Wing Strange Attractor Born in\nBistablity.” IEICE Electronics Express 12 (February). https://doi.org/10.1587/elex.12.20141116.\n\n\nLi, Hao, Daniel Fernex, Richard Semaan, Jianguo Tan, Marek Morzyński,\nand Bernd R Noack. 2021. “Cluster-Based Network Model.”\nJournal of Fluid Mechanics 906.\n\n\nLloyd, Stuart. 1982. “Least Squares Quantization in PCM.”\nIEEE Transactions on Information Theory 28 (2): 129–37.\n\n\nLorenz, Edward N. 1963. “Deterministic Nonperiodic Flow.”\nJournal of Atmospheric Sciences 20 (2): 130–41.\n\n\nLu, Jinhu, and Guanrong Chen. 2002. “A New Chaotic Attractor\nCoined.” I. J. Bifurcation and Chaos 12 (March): 659–61.\nhttps://doi.org/10.1142/S0218127402004620.\n\n\nPedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O.\nGrisel, M. Blondel, et al. 2011. “Scikit-Learn: Machine Learning\nin Python.” Journal of Machine Learning\nResearch 12: 2825–30.\n\n\nPierzyna, Maximilian. 2021. “Control-Oriented Cluster-Basednetwork\nModeling.” Research report, TU Braunschweig.\n\n\nProtas, Bartosz, Bernd R Noack, and Jan Östh. 2015. “Optimal\nNonlinear Eddy Viscosity in Galerkin Models of Turbulent Flows.”\nJournal of Fluid Mechanics 766: 337–67.\n\n\n“pySindy’s Remark on RK45 Vs. LSODA.” 2022. https://pysindy.readthedocs.io/en/latest/examples/1_feature_overview.html.\n\n\nRasmussen, Carl Edward. 2004. “Gaussian Processes in Machine\nLearning.” In Advanced Lectures on Machine Learning,\n63–71. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-28650-9_4.\n\n\nRickles, D., P. Hawe, and A. Shiell. 2007. “A Simple Guide to\nChaos and Complexity.” Journal of Epidemiology\n& Community Health 61 (11): 933–37. https://doi.org/10.1136/jech.2006.054254.\n\n\nRössler, O. E. 1976. “An Equation for Continuous Chaos.”\nPhysics Letters A 57 (5): 397–98. https://doi.org/https://doi.org/10.1016/0375-9601(76)90101-8.\n\n\nSilva, Brian de, Kathleen Champion, Markus Quade, Jean-Christophe\nLoiseau, J. Kutz, and Steven Brunton. 2020. “PySINDy:\nA Python Package for the Sparse Identification of Nonlinear Dynamical\nSystems from Data.” Journal of Open Source Software 5\n(49): 2104. https://doi.org/10.21105/joss.02104.\n\n\nSPROTT, Julien. 2020. “Do We Need More Chaos Examples?”\nChaos Theory and Applications 2 (2): 49–51.\n\n\nStrogatz, Steven. 2019. Nonlinear Dynamics and Chaos : With\nApplications to Physics, Biology, Chemistry, and Engineering. Boca\nRaton: CRC Press.\n\n\nTaylor, Robert LV. 2010. “Attractors: Nonstrange to\nChaotic.” Society for Industrial and Applied Mathematics,\nUndergraduate Research Online, 72–80.\n\n\nTibshirani, Robert. 1996. “Regression Shrinkage and Selection via\nthe Lasso.” Journal of the Royal Statistical Society: Series\nB (Methodological) 58 (1): 267–88.\n\n\nVaidyanathan, Sundarapandian, Aceng Sambas, Sen Zhang, Yicheng Zeng,\nMohamad Afendee Mohamed, and Mustafa Mamat. 2019. “A New\nTwo-Scroll Chaotic System with Two Nonlinearities: Dynamical Analysis\nand Circuit Simulation.” Telkomnika 17 (5): 2465–74.\n\n\nVan Rossum, Guido, and Fred L. Drake. 2009. Python 3 Reference\nManual. Scotts Valley, CA: CreateSpace.\n\n\nVirtanen, Pauli, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler\nReddy, David Cournapeau, Evgeni Burovski, et al. 2020. “SciPy 1.0: Fundamental Algorithms for\nScientific Computing in Python.” Nature Methods\n17: 261–72. https://doi.org/10.1038/s41592-019-0686-2.\n\n\n“Wikipedia Entry on Chaos Theory.” 2021. https://en.wikipedia.org/wiki/Chaos_theory.\n\n\nZheng, Peng, Travis Askham, Steven L Brunton, J Nathan Kutz, and\nAleksandr Y Aravkin. 2018. “A Unified Framework for Sparse Relaxed\nRegularized Regression: SR3.” IEEE Access 7: 1404–23."
  },
  {
    "objectID": "Data/8_Add_2_Master/0_Add_2_Mast.html#modifications-that-have-been-made-to-the-original-master-thesis",
    "href": "Data/8_Add_2_Master/0_Add_2_Mast.html#modifications-that-have-been-made-to-the-original-master-thesis",
    "title": "20  Modification to the original thesis and source code",
    "section": "20.1 Modifications that have been made to the original master thesis",
    "text": "20.1 Modifications that have been made to the original master thesis\nInitially, the author wanted to give a detailed listing of the changes which were made for the website. It is believed to be not necessary, however, the following list could be obtained until the change of mind:\n\nThe images for the PDF were embedded as PDF files. For this web view, the images were all converted from PDF to SVG using Inkscape. Note that at the beginning of writing the master thesis all figures were generated as .svg, PNGs and PDFs via an automated process. However, too many images were stored, thus only SVGs and PNGs were kept at some point. The conversion from PDF to SVG might include quality loss. Instead of the conversion, it would be possible to generate all the images directly as SVG again. Considering the high number of used figures, the conversion from PDF to SVG is much faster. For the latter, all the differential equations must have been solved again. So in a nutshell, SVGs are used instead of PDFs, though a conversation process, which might involve some quality losses.\nthe order of references and appendix\nthe two appendices in the web view have their own separate pages\nThe first 3 set of equations and figures in section 13 are displayed in full width instead of theequations and corresponding figures being next to each other in a two column representation\nthe original master thesis PDF was written in Latex (see chapter 21)\nThe section you are reading right now, is not found in the PDF file, due to obvious reasons"
  },
  {
    "objectID": "Data/8_Add_2_Master/0_Add_2_Mast.html#source-code",
    "href": "Data/8_Add_2_Master/0_Add_2_Mast.html#source-code",
    "title": "20  Modification to the original thesis and source code",
    "section": "20.2 Source code",
    "text": "20.2 Source code\nFor this section, the author of this work would like to switch from the passive voice used in scientific writing to the active voice used for an engaging and friendly tone. I initially intended to release the entire code on GitHub, so that everyone could play with it. This was also one of the reasons why I invested in code readability during coding. However, the code is not my property, as it was written for the TU Braunschweig. Dr. Richard Semaan advised me to wait with publishing the source code until he and his team have made more progress towards a publication. My experience with Dr. Semaan is that he’s a nice guy, and he usually replies within half an hour. So maybe he would be willing to share the source code with people who ask him for it. You can contact him through the contact information provided at the TU Braunschweig website.\nIt might be well-known that some people and universities tend to say that the written thesis is what counts. Since I have another opinion on that, I would like to apologize - I totally understand that such a thesis is much more valuable and enjoyable with the source code. In fact, I would argue that the code is the most important part of my thesis."
  },
  {
    "objectID": "Data/8_Add_2_Master/2_About_Author.html#sec-subsec_Additional",
    "href": "Data/8_Add_2_Master/2_About_Author.html#sec-subsec_Additional",
    "title": "22  About the author",
    "section": "22.1 Contact",
    "text": "22.1 Contact\nYou can contact me through some channels:\n\n LinkedIn\n\n\n Twitter @JavArButt \n\n Facebook\n\n Discord"
  },
  {
    "objectID": "Data/8_Add_2_Master/3_CV.html#cv-in-english",
    "href": "Data/8_Add_2_Master/3_CV.html#cv-in-english",
    "title": "23  CV/Resume",
    "section": "23.1 CV in English",
    "text": "23.1 CV in English"
  },
  {
    "objectID": "Data/8_Add_2_Master/3_CV.html#lebenslauf-auf-detusch",
    "href": "Data/8_Add_2_Master/3_CV.html#lebenslauf-auf-detusch",
    "title": "23  CV/Resume",
    "section": "23.2 Lebenslauf auf Detusch",
    "text": "23.2 Lebenslauf auf Detusch"
  },
  {
    "objectID": "Data/10_Law/0_Mentioning.html",
    "href": "Data/10_Law/0_Mentioning.html",
    "title": "24  Mentioning",
    "section": "",
    "text": "I would like to start by expressing my gratitude to the developer and investor of quarto. It was the main tool that was used to create this webpage of my master thesis. As you can see, it looks quite fancy, offers some nice features, e.g., the interactive 3D plot of tornado. Next, during the creation of the master thesis, some tools were used extensively. Without those, the research conducted through this master thesis, would have not been possible. Among these are, the programming language Python, the libraries NumPy, scikit-learn, SciPy, plotly, my code editor vscode, the free online translator DeepL and many more. Python is great because of its remarkable amount of open-source libraries. You probably do not calculate any vector or matrix operation without NumPy. The documentation, the ease of switching between machine learning algorithms and the vast amount of implemented algorithms is more than impressive: scikit-learn. Doing some computational science, SciPy is a fantastic friend and also the documentation has improved a lot. Usually people use Matplotlib which is understandable, it is a very powerful library. However, the looks and the interactivity that plotly offers is incredible. Regarding my code editor vscode, what can I say, I use it for Python, Julia, Java, C++, HTML, CSS, JavaScript, Json, XML, Latex, Markdown, git ….. Having user defined short-keys for nearly everything, writing own add-ons or just downloading all kinds of add-ons from the extension market is undeniably efficient.\nMany thanks to professor Steve Brunton and Nathan Kutz for their amazing free online lectures and their data driven book. Special thanks to the creator of these beautiful animations, which are used on this website and will be linked to later.\nSince I used a lot of free software, I believe it is proper etiquette to mention and acknowledge them. One important aspect of open source software is the license. Often it demands that if the source code was modified, a copy of the original license is made available and or a link to the original license is provided. No modification of the source code happened within this master thesis, neither in the HTML nor in the PDF version. Listing the tools with their license shall show my gratitude and appreciation for their work. The latter can be found in the following table. It shall provide the name of the tool/library/program and its corresponding license. The visitor can click on the first link to be directed to the license distributor’s site. The second option, if available, is to click on the second link, which shows the general copies of the licenses within this website.\n\nLicenses of used open source tools\n\n\nTool\nLicense\n\n\n\n\nPython\nPython license\n\n\nNumPy\nBSD 3-Clause (general copy in 25)\n\n\nscikit-learn\nBSD 3-Clause (general copy in 25)\n\n\nSciPy\nBSD 3-Clause (general copy in 25\n\n\nplotly\nMIT (general copy in 25)\n\n\nvscode\nMIT (general copy in 25)\n\n\nDeepL\nDeepL free\n\n\nMatplotlib\nMatplotlib license\n\n\nPandoc\nGNU GPL v2 (general copy in 25)\n\n\nBootstrap 5.1\nMIT (general copy in 25)\n\n\nBootswatch 5.1\nMIT (general copy in 25)\n\n\nDeno\nMIT (general copy in 25)\n\n\nesbuild\nMIT (general copy in 25)\n\n\nDart Sass\nMIT (general copy in 25)\n\n\nQuarto\nGNU GPL v2 (general copy in 25)\n\n\nLanguageTool\nLanguageTool free\n\n\nGrammarly\nGrammarly free\n\n\nInkscape\nGNU GPL v2 (general copy in 25)\n\n\nLottiFiles\nLottie Simple License (general copy in 25)\n\n\ndotLottie\nMIT (general copy in 25)\n\n\nFloating UI\nMIT (general copy in 25)\n\n\nTippy.js\nMIT (general copy in 25)\n\n\nLatex\nLatex license\n\n\nIonicons\nMIT (general copy in 25)\n\n\nmanypixels\nLicense\n\n\ngiscus\nMIT (general copy in 25)\n\n\nhypothesis\nBSD 2-Clause\n\n\nFeather\nMIT (general copy in 25)\n\n\nRembg\nMIT (general copy in 25)\n\n\n\n\n24.0.1 Animations and images\nThank to some special people who uploaded their beautiful work on LottiFiles. \n\n\nThe Pakistani Rikschah can be found at Pak Rik and my thanks goes to. Note, this file was modified a bit. I am a muslim and I am not sure, if I am allowed to have drawings of cartoons included. It might be that the Almighty asks me, on the day of resurrection, whether I can bring life into these drawings. Obviously, I cannot give live, thus, to be on the safe side, I removed the driver in the original animation. \nThe Bismillah animation and my thanks goes to \nThe mosque animiation, thank you \nThe paper and pen animation, thank you \nThe aircraft animation, thank you \nThe rocket animation, thank you. The rocket animation was modfied by me. \n\n\nThere is a black board that appears, when hovering over abbreviations. This blackboard was generated using two different icon providers and some modifications: board, star and moon.\n\n\n24.0.2 Quarto tools\n\ncollapse-callout, MIT, (general copy in 25)\nLightbox, MIT, (general copy in 25)"
  },
  {
    "objectID": "Data/10_Law/1_Copy_Licenses.html",
    "href": "Data/10_Law/1_Copy_Licenses.html",
    "title": "25  Copy of licenses",
    "section": "",
    "text": "MIT\n\n\n\n\n\nsee online\nThe MIT License (MIT)\nCopyright © 2023 \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n\n\n\n\nBSD 3-Clause “New” or “Revised” License\n\n\n\n\n\nsee online example NumPy license\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above\n   copyright notice, this list of conditions and the following\n   disclaimer in the documentation and/or other materials provided\n   with the distribution.\n\n* Neither the name of the NumPy Developers nor the names of any\n   contributors may be used to endorse or promote products derived\n   from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n\n\n\n\n\n\n\nGNU GPL v2\n\n\n\n\n\nsee online at GNU GPL v2\n\nGNU GENERAL PUBLIC LICENSE\nVersion 2, June 1991\nCopyright (C) 1989, 1991 Free Software Foundation, Inc.  \n51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA\n\nEveryone is permitted to copy and distribute verbatim copies\nof this license document, but changing it is not allowed.\n\n\nPreamble\nThe licenses for most software are designed to take away your freedom to share and change it. By contrast, the GNU General Public License is intended to guarantee your freedom to share and change free software–to make sure the software is free for all its users. This General Public License applies to most of the Free Software Foundation’s software and to any other program whose authors commit to using it. (Some other Free Software Foundation software is covered by the GNU Lesser General Public License instead.) You can apply it to your programs, too.\nWhen we speak of free software, we are referring to freedom, not price. Our General Public Licenses are designed to make sure that you have the freedom to distribute copies of free software (and charge for this service if you wish), that you receive source code or can get it if you want it, that you can change the software or use pieces of it in new free programs; and that you know you can do these things.\nTo protect your rights, we need to make restrictions that forbid anyone to deny you these rights or to ask you to surrender the rights. These restrictions translate to certain responsibilities for you if you distribute copies of the software, or if you modify it.\nFor example, if you distribute copies of such a program, whether gratis or for a fee, you must give the recipients all the rights that you have. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights.\nWe protect your rights with two steps: (1) copyright the software, and (2) offer you this license which gives you legal permission to copy, distribute and/or modify the software.\nAlso, for each author’s protection and ours, we want to make certain that everyone understands that there is no warranty for this free software. If the software is modified by someone else and passed on, we want its recipients to know that what they have is not the original, so that any problems introduced by others will not reflect on the original authors’ reputations.\nFinally, any free program is threatened constantly by software patents. We wish to avoid the danger that redistributors of a free program will individually obtain patent licenses, in effect making the program proprietary. To prevent this, we have made it clear that any patent must be licensed for everyone’s free use or not licensed at all.\nThe precise terms and conditions for copying, distribution and modification follow.\n\n\nTERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n0. This License applies to any program or other work which contains a notice placed by the copyright holder saying it may be distributed under the terms of this General Public License. The “Program”, below, refers to any such program or work, and a “work based on the Program” means either the Program or any derivative work under copyright law: that is to say, a work containing the Program or a portion of it, either verbatim or with modifications and/or translated into another language. (Hereinafter, translation is included without limitation in the term “modification”.) Each licensee is addressed as “you”.\nActivities other than copying, distribution and modification are not covered by this License; they are outside its scope. The act of running the Program is not restricted, and the output from the Program is covered only if its contents constitute a work based on the Program (independent of having been made by running the Program). Whether that is true depends on what the Program does.\n1. You may copy and distribute verbatim copies of the Program’s source code as you receive it, in any medium, provided that you conspicuously and appropriately publish on each copy an appropriate copyright notice and disclaimer of warranty; keep intact all the notices that refer to this License and to the absence of any warranty; and give any other recipients of the Program a copy of this License along with the Program.\nYou may charge a fee for the physical act of transferring a copy, and you may at your option offer warranty protection in exchange for a fee.\n2. You may modify your copy or copies of the Program or any portion of it, thus forming a work based on the Program, and copy and distribute such modifications or work under the terms of Section 1 above, provided that you also meet all of these conditions:\na) You must cause the modified files to carry prominent notices stating that you changed the files and the date of any change.\nb) You must cause any work that you distribute or publish, that in whole or in part contains or is derived from the Program or any part thereof, to be licensed as a whole at no charge to all third parties under the terms of this License.\nc) If the modified program normally reads commands interactively when run, you must cause it, when started running for such interactive use in the most ordinary way, to print or display an announcement including an appropriate copyright notice and a notice that there is no warranty (or else, saying that you provide a warranty) and that users may redistribute the program under these conditions, and telling the user how to view a copy of this License. (Exception: if the Program itself is interactive but does not normally print such an announcement, your work based on the Program is not required to print an announcement.)\nThese requirements apply to the modified work as a whole. If identifiable sections of that work are not derived from the Program, and can be reasonably considered independent and separate works in themselves, then this License, and its terms, do not apply to those sections when you distribute them as separate works. But when you distribute the same sections as part of a whole which is a work based on the Program, the distribution of the whole must be on the terms of this License, whose permissions for other licensees extend to the entire whole, and thus to each and every part regardless of who wrote it.\nThus, it is not the intent of this section to claim rights or contest your rights to work written entirely by you; rather, the intent is to exercise the right to control the distribution of derivative or collective works based on the Program.\nIn addition, mere aggregation of another work not based on the Program with the Program (or with a work based on the Program) on a volume of a storage or distribution medium does not bring the other work under the scope of this License.\n3. You may copy and distribute the Program (or a work based on it, under Section 2) in object code or executable form under the terms of Sections 1 and 2 above provided that you also do one of the following:\na) Accompany it with the complete corresponding machine-readable source code, which must be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange; or,\nb) Accompany it with a written offer, valid for at least three years, to give any third party, for a charge no more than your cost of physically performing source distribution, a complete machine-readable copy of the corresponding source code, to be distributed under the terms of Sections 1 and 2 above on a medium customarily used for software interchange; or,\nc) Accompany it with the information you received as to the offer to distribute corresponding source code. (This alternative is allowed only for noncommercial distribution and only if you received the program in object code or executable form with such an offer, in accord with Subsection b above.)\nThe source code for a work means the preferred form of the work for making modifications to it. For an executable work, complete source code means all the source code for all modules it contains, plus any associated interface definition files, plus the scripts used to control compilation and installation of the executable. However, as a special exception, the source code distributed need not include anything that is normally distributed (in either source or binary form) with the major components (compiler, kernel, and so on) of the operating system on which the executable runs, unless that component itself accompanies the executable.\nIf distribution of executable or object code is made by offering access to copy from a designated place, then offering equivalent access to copy the source code from the same place counts as distribution of the source code, even though third parties are not compelled to copy the source along with the object code.\n4. You may not copy, modify, sublicense, or distribute the Program except as expressly provided under this License. Any attempt otherwise to copy, modify, sublicense or distribute the Program is void, and will automatically terminate your rights under this License. However, parties who have received copies, or rights, from you under this License will not have their licenses terminated so long as such parties remain in full compliance.\n5. You are not required to accept this License, since you have not signed it. However, nothing else grants you permission to modify or distribute the Program or its derivative works. These actions are prohibited by law if you do not accept this License. Therefore, by modifying or distributing the Program (or any work based on the Program), you indicate your acceptance of this License to do so, and all its terms and conditions for copying, distributing or modifying the Program or works based on it.\n6. Each time you redistribute the Program (or any work based on the Program), the recipient automatically receives a license from the original licensor to copy, distribute or modify the Program subject to these terms and conditions. You may not impose any further restrictions on the recipients’ exercise of the rights granted herein. You are not responsible for enforcing compliance by third parties to this License.\n7. If, as a consequence of a court judgment or allegation of patent infringement or for any other reason (not limited to patent issues), conditions are imposed on you (whether by court order, agreement or otherwise) that contradict the conditions of this License, they do not excuse you from the conditions of this License. If you cannot distribute so as to satisfy simultaneously your obligations under this License and any other pertinent obligations, then as a consequence you may not distribute the Program at all. For example, if a patent license would not permit royalty-free redistribution of the Program by all those who receive copies directly or indirectly through you, then the only way you could satisfy both it and this License would be to refrain entirely from distribution of the Program.\nIf any portion of this section is held invalid or unenforceable under any particular circumstance, the balance of the section is intended to apply and the section as a whole is intended to apply in other circumstances.\nIt is not the purpose of this section to induce you to infringe any patents or other property right claims or to contest validity of any such claims; this section has the sole purpose of protecting the integrity of the free software distribution system, which is implemented by public license practices. Many people have made generous contributions to the wide range of software distributed through that system in reliance on consistent application of that system; it is up to the author/donor to decide if he or she is willing to distribute software through any other system and a licensee cannot impose that choice.\nThis section is intended to make thoroughly clear what is believed to be a consequence of the rest of this License.\n8. If the distribution and/or use of the Program is restricted in certain countries either by patents or by copyrighted interfaces, the original copyright holder who places the Program under this License may add an explicit geographical distribution limitation excluding those countries, so that distribution is permitted only in or among countries not thus excluded. In such case, this License incorporates the limitation as if written in the body of this License.\n9. The Free Software Foundation may publish revised and/or new versions of the General Public License from time to time. Such new versions will be similar in spirit to the present version, but may differ in detail to address new problems or concerns.\nEach version is given a distinguishing version number. If the Program specifies a version number of this License which applies to it and “any later version”, you have the option of following the terms and conditions either of that version or of any later version published by the Free Software Foundation. If the Program does not specify a version number of this License, you may choose any version ever published by the Free Software Foundation.\n10. If you wish to incorporate parts of the Program into other free programs whose distribution conditions are different, write to the author to ask for permission. For software which is copyrighted by the Free Software Foundation, write to the Free Software Foundation; we sometimes make exceptions for this. Our decision will be guided by the two goals of preserving the free status of all derivatives of our free software and of promoting the sharing and reuse of software generally.\nNO WARRANTY\n11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM “AS IS” WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\n\nEND OF TERMS AND CONDITIONS\n\n\nHow to Apply These Terms to Your New Programs\nIf you develop a new program, and you want it to be of the greatest possible use to the public, the best way to achieve this is to make it free software which everyone can redistribute and change under these terms.\nTo do so, attach the following notices to the program. It is safest to attach them to the start of each source file to most effectively convey the exclusion of warranty; and each file should have at least the “copyright” line and a pointer to where the full notice is found.\none line to give the program's name and an idea of what it does.\nCopyright (C) yyyy  name of author\n\nThis program is free software; you can redistribute it and/or\nmodify it under the terms of the GNU General Public License\nas published by the Free Software Foundation; either version 2\nof the License, or (at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program; if not, write to the Free Software\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\nAlso add information on how to contact you by electronic and paper mail.\nIf the program is interactive, make it output a short notice like this when it starts in an interactive mode:\nGnomovision version 69, Copyright (C) year name of author\nGnomovision comes with ABSOLUTELY NO WARRANTY; for details\ntype `show w'.  This is free software, and you are welcome\nto redistribute it under certain conditions; type `show c' \nfor details.\nThe hypothetical commands `show w’ and `show c’ should show the appropriate parts of the General Public License. Of course, the commands you use may be called something other than `show w’ and `show c’; they could even be mouse-clicks or menu items–whatever suits your program.\nYou should also get your employer (if you work as a programmer) or your school, if any, to sign a “copyright disclaimer” for the program, if necessary. Here is a sample; alter the names:\nYoyodyne, Inc., hereby disclaims all copyright\ninterest in the program `Gnomovision'\n(which makes passes at compilers) written \nby James Hacker.\n\nsignature of Ty Coon, 1 April 1989\nTy Coon, President of Vice\nThis General Public License does not permit incorporating your program into proprietary programs. If your program is a subroutine library, you may consider it more useful to permit linking proprietary applications with the library. If this is what you want to do, use the GNU Lesser General Public License instead of this License.\n\n\n\n\n\n\n\n\n\n\nLottie Simple License\n\n\n\n\n\nsee online at Lottie Simple License\nCopyright © 2021 Design Barn Inc.\nPermission is hereby granted, free of charge, to any person obtaining a copy of the public animation files available for download at the LottieFiles site (“Files”) to download, reproduce, modify, publish, distribute, publicly display, and publicly digitally perform such Files, including for commercial purposes, provided that any display, publication, performance, or distribution of Files must contain (and be subject to) the same terms and conditions of this license. Modifications to Files are deemed derivative works and must also be expressly distributed under the same terms and conditions of this license. You may not purport to impose any additional or different terms or conditions on, or apply any technical measures that restrict exercise of, the rights granted under this license. This license does not include the right to collect or compile Files from LottieFiles to replicate or develop a similar or competing service.\nUse of Files without attributing the creator(s) of the Files is permitted under this license, though attribution is strongly encouraged. If attributions are included, such attributions should be visible to the end user.\nFILES ARE PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. EXCEPT TO THE EXTENT REQUIRED BY APPLICABLE LAW, IN NO EVENT WILL THE CREATOR(S) OF FILES OR DESIGN BARN, INC. BE LIABLE ON ANY LEGAL THEORY FOR ANY SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE, OR EXEMPLARY DAMAGES ARISING OUT OF THIS LICENSE OR THE USE OF SUCH FILES."
  },
  {
    "objectID": "Data/10_Law/2_Used_Hippocratic.html",
    "href": "Data/10_Law/2_Used_Hippocratic.html",
    "title": "26  Released under license",
    "section": "",
    "text": "Hippocratic License HL3-BDS-CL-ECO-EXTR-MEDIA-MIL-SV-XUAR\n\n\n\n\n\n\n\nExpand Hippocratic license\n\n\n\n\n\nHIPPOCRATIC LICENSE\nVersion 3.0, October 2021\nhttps://firstdonoharm.dev/version/3/0/bds-cl-eco-extr-media-mil-sv-xuar.md\nTERMS AND CONDITIONS\nTERMS AND CONDITIONS FOR USE, COPY, MODIFICATION, PREPARATION OF DERIVATIVE WORK, REPRODUCTION, AND DISTRIBUTION:\n1. DEFINITIONS:\nThis section defines certain terms used throughout this license agreement.\n1.1. “License” means the terms and conditions, as stated herein, for use, copy, modification, preparation of derivative work, reproduction, and distribution of Software (as defined below).\n1.2. “Licensor” means the copyright and/or patent owner or entity authorized by the copyright and/or patent owner that is granting the License.\n1.3. “Licensee” means the individual or entity exercising permissions granted by this License, including the use, copy, modification, preparation of derivative work, reproduction, and distribution of Software (as defined below).\n1.4. “Software” means any copyrighted work, including but not limited to software code, authored by Licensor and made available under this License.\n1.5. “Supply Chain” means the sequence of processes involved in the production and/or distribution of a commodity, good, or service offered by the Licensee.\n1.6. “Supply Chain Impacted Party” or “Supply Chain Impacted Parties” means any person(s) directly impacted by any of Licensee’s Supply Chain, including the practices of all persons or entities within the Supply Chain prior to a good or service reaching the Licensee.\n1.7. “Duty of Care” is defined by its use in tort law, delict law, and/or similar bodies of law closely related to tort and/or delict law, including without limitation, a requirement to act with the watchfulness, attention, caution, and prudence that a reasonable person in the same or similar circumstances would use towards any Supply Chain Impacted Party.\n1.8. “Worker” is defined to include any and all permanent, temporary, and agency workers, as well as piece-rate, salaried, hourly paid, legal young (minors), part-time, night, and migrant workers.\n2. INTELLECTUAL PROPERTY GRANTS:\nThis section identifies intellectual property rights granted to a Licensee.\n2.1. Grant of Copyright License: Subject to the terms and conditions of this License, Licensor hereby grants to Licensee a worldwide, non-exclusive, no-charge, royalty-free copyright license to use, copy, modify, prepare derivative work, reproduce, or distribute the Software, Licensor authored modified software, or other work derived from the Software.\n2.2. Grant of Patent License: Subject to the terms and conditions of this License, Licensor hereby grants Licensee a worldwide, non-exclusive, no-charge, royalty-free patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer Software.\n3. ETHICAL STANDARDS:\nThis section lists conditions the Licensee must comply with in order to have rights under this License.\nThe rights granted to the Licensee by this License are expressly made subject to the Licensee’s ongoing compliance with the following conditions:\n\n3.1. The Licensee SHALL NOT, whether directly or indirectly, through agents or assigns:\n\n3.1.1. Infringe upon any person’s right to life or security of person, engage in extrajudicial killings, or commit murder, without lawful cause (See Article 3, United Nations Universal Declaration of Human Rights; Article 6, International Covenant on Civil and Political Rights)\n\n3.1.2. Hold any person in slavery, servitude, or forced labor (See Article 4, United Nations Universal Declaration of Human Rights; Article 8, International Covenant on Civil and Political Rights);\n\n3.1.3. Contribute to the institution of slavery, slave trading, forced labor, or unlawful child labor (See Article 4, United Nations Universal Declaration of Human Rights; Article 8, International Covenant on Civil and Political Rights);\n\n3.1.4. Torture or subject any person to cruel, inhumane, or degrading treatment or punishment (See Article 5, United Nations Universal Declaration of Human Rights; Article 7, International Covenant on Civil and Political Rights);\n\n3.1.5. Discriminate on the basis of sex, gender, sexual orientation, race, ethnicity, nationality, religion, caste, age, medical disability or impairment, and/or any other like circumstances (See Article 7, United Nations Universal Declaration of Human Rights; Article 2, International Covenant on Economic, Social and Cultural Rights; Article 26, International Covenant on Civil and Political Rights);\n\n3.1.6. Prevent any person from exercising his/her/their right to seek an effective remedy by a competent court or national tribunal (including domestic judicial systems, international courts, arbitration bodies, and other adjudicating bodies) for actions violating the fundamental rights granted to him/her/them by applicable constitutions, applicable laws, or by this License (See Article 8, United Nations Universal Declaration of Human Rights; Articles 9 and 14, International Covenant on Civil and Political Rights);\n\n3.1.7. Subject any person to arbitrary arrest, detention, or exile (See Article 9, United Nations Universal Declaration of Human Rights; Article 9, International Covenant on Civil and Political Rights);\n\n3.1.8. Subject any person to arbitrary interference with a person’s privacy, family, home, or correspondence without the express written consent of the person (See Article 12, United Nations Universal Declaration of Human Rights; Article 17, International Covenant on Civil and Political Rights);\n\n3.1.9. Arbitrarily deprive any person of his/her/their property (See Article 17, United Nations Universal Declaration of Human Rights);\n\n3.1.10. Forcibly remove indigenous peoples from their lands or territories or take any action with the aim or effect of dispossessing indigenous peoples from their lands, territories, or resources, including without limitation the intellectual property or traditional knowledge of indigenous peoples, without the free, prior, and informed consent of indigenous peoples concerned (See Articles 8 and 10, United Nations Declaration on the Rights of Indigenous Peoples);\n\n3.1.11. Ecocide: Commit ecocide:\n* 3.1.11.1. For the purpose of this section, “ecocide” means unlawful or wanton acts committed with knowledge that there is a substantial likelihood of severe and either widespread or long-term damage to the environment being caused by those acts;\n* 3.1.11.2. For the purpose of further defining ecocide and the terms contained in the previous paragraph:\n* 3.1.11.2.1. “Wanton” means with reckless disregard for damage which would be clearly excessive in relation to the social and economic benefits anticipated;\n* 3.1.11.2.2. “Severe” means damage which involves very serious adverse changes, disruption, or harm to any element of the environment, including grave impacts on human life or natural, cultural, or economic resources;\n* 3.1.11.2.3. “Widespread” means damage which extends beyond a limited geographic area, crosses state boundaries, or is suffered by an entire ecosystem or species or a large number of human beings;\n* 3.1.11.2.4. “Long-term” means damage which is irreversible or which cannot be redressed through natural recovery within a reasonable period of time; and\n* 3.1.11.2.5. “Environment” means the earth, its biosphere, cryosphere, lithosphere, hydrosphere, and atmosphere, as well as outer space\n(See Section II, Independent Expert Panel for the Legal Definition of Ecocide, Stop Ecocide Foundation and the Promise Institute for Human Rights at UCLA School of Law, June 2021);\n\n3.1.12. Extractive Industries: Be an individual or entity, or a representative, agent, affiliate, successor, attorney, or assign of an individual or entity, that engages in fossil fuel or mineral exploration, extraction, development, or sale;\n\n3.1.13. Boycott / Divestment / Sanctions: Be an individual or entity, or a representative, agent, affiliate, successor, attorney, or assign of an individual or entity, identified by the Boycott, Divestment, Sanctions (“BDS”) movement on its website (https://bdsmovement.net/ and https://bdsmovement.net/get-involved/what-to-boycott) as a target for boycott;\n\n3.1.14. Xinjiang Uygur Autonomous Region: Be an individual or entity, or a representative, agent, affiliate, successor, attorney, or assign of any individual or entity, that does business in, purchases goods from, or otherwise benefits from goods produced in the Xinjiang Uygur Autonomous Region of China;\n\n3.1.15. Mass Surveillance: Be a government agency or multinational corporation, or a representative, agent, affiliate, successor, attorney, or assign of a government or multinational corporation, which participates in mass surveillance programs;\n\n3.1.16. Military Activities: Be an entity or a representative, agent, affiliate, successor, attorney, or assign of an entity which conducts military activities;\n\n3.1.17. Media: Be an individual or entity, or a or a representative, agent, affiliate, successor, attorney, or assign of an individual or entity, that broadcasts messages promoting killing, torture, or other forms of extreme violence;\n\n3.1.18. Interfere with Workers’ free exercise of the right to organize and associate (See Article 20, United Nations Universal Declaration of Human Rights; C087 - Freedom of Association and Protection of the Right to Organise Convention, 1948 (No. 87), International Labour Organization; Article 8, International Covenant on Economic, Social and Cultural Rights); and\n\n3.1.19. Harm the environment in a manner inconsistent with local, state, national, or international law.\n\n3.2. The Licensee SHALL:\n\n3.2.1. Provide equal pay for equal work where the performance of such work requires equal skill, effort, and responsibility, and which are performed under similar working conditions, except where such payment is made pursuant to:\n* 3.2.1.1. A seniority system;\n* 3.2.1.2. A merit system;\n* 3.2.1.3. A system which measures earnings by quantity or quality of production; or\n* 3.2.1.4. A differential based on any other factor other than sex, gender, sexual orientation, race, ethnicity, nationality, religion, caste, age, medical disability or impairment, and/or any other like circumstances (See 29 U.S.C.A. § 206(d)(1); Article 23, United Nations Universal Declaration of Human Rights; Article 7, International Covenant on Economic, Social and Cultural Rights; Article 26, International Covenant on Civil and Political Rights); and\n\n3.2.2. Allow for reasonable limitation of working hours and periodic holidays with pay (See Article 24, United Nations Universal Declaration of Human Rights; Article 7, International Covenant on Economic, Social and Cultural Rights).\n\n\n4. SUPPLY CHAIN IMPACTED PARTIES:\nThis section identifies additional individuals or entities that a Licensee could harm as a result of violating the Ethical Standards section, the condition that the Licensee must voluntarily accept a Duty of Care for those individuals or entities, and the right to a private right of action that those individuals or entities possess as a result of violations of the Ethical Standards section.\n4.1. In addition to the above Ethical Standards, Licensee voluntarily accepts a Duty of Care for Supply Chain Impacted Parties of this License, including individuals and communities impacted by violations of the Ethical Standards. The Duty of Care is breached when a provision within the Ethical Standards section is violated by a Licensee, one of its successors or assigns, or by an individual or entity that exists within the Supply Chain prior to a good or service reaching the Licensee.\n4.2. Breaches of the Duty of Care, as stated within this section, shall create a private right of action, allowing any Supply Chain Impacted Party harmed by the Licensee to take legal action against the Licensee in accordance with applicable negligence laws, whether they be in tort law, delict law, and/or similar bodies of law closely related to tort and/or delict law, regardless if Licensee is directly responsible for the harms suffered by a Supply Chain Impacted Party. Nothing in this section shall be interpreted to include acts committed by individuals outside of the scope of his/her/their employment.\n5. NOTICE: This section explains when a Licensee must notify others of the License.\n5.1. Distribution of Notice: Licensee must ensure that everyone who receives a copy of or uses any part of Software from Licensee, with or without changes, also receives the License and the copyright notice included with Software (and if included by the Licensor, patent, trademark, and attribution notice). Licensee must ensure that License is prominently displayed so that any individual or entity seeking to download, copy, use, or otherwise receive any part of Software from Licensee is notified of this License and its terms and conditions. Licensee must cause any modified versions of the Software to carry prominent notices stating that Licensee changed the Software.\n5.2. Modified Software: Licensee is free to create modifications of the Software and distribute only the modified portion created by Licensee, however, any derivative work stemming from the Software or its code must be distributed pursuant to this License, including this Notice provision.\n5.3. Recipients as Licensees: Any individual or entity that uses, copies, modifies, reproduces, distributes, or prepares derivative work based upon the Software, all or part of the Software’s code, or a derivative work developed by using the Software, including a portion of its code, is a Licensee as defined above and is subject to the terms and conditions of this License.\n6. REPRESENTATIONS AND WARRANTIES:\n6.1. Disclaimer of Warranty: TO THE FULL EXTENT ALLOWED BY LAW, THIS SOFTWARE COMES “AS IS,” WITHOUT ANY WARRANTY, EXPRESS OR IMPLIED, AND LICENSOR SHALL NOT BE LIABLE TO ANY PERSON OR ENTITY FOR ANY DAMAGES OR OTHER LIABILITY ARISING FROM, OUT OF, OR IN CONNECTION WITH THE SOFTWARE OR THIS LICENSE, UNDER ANY LEGAL CLAIM.\n6.2. Limitation of Liability: LICENSEE SHALL HOLD LICENSOR HARMLESS AGAINST ANY AND ALL CLAIMS, DEBTS, DUES, LIABILITIES, LIENS, CAUSES OF ACTION, DEMANDS, OBLIGATIONS, DISPUTES, DAMAGES, LOSSES, EXPENSES, ATTORNEYS’ FEES, COSTS, LIABILITIES, AND ALL OTHER CLAIMS OF EVERY KIND AND NATURE WHATSOEVER, WHETHER KNOWN OR UNKNOWN, ANTICIPATED OR UNANTICIPATED, FORESEEN OR UNFORESEEN, ACCRUED OR UNACCRUED, DISCLOSED OR UNDISCLOSED, ARISING OUT OF OR RELATING TO LICENSEE’S USE OF THE SOFTWARE. NOTHING IN THIS SECTION SHOULD BE INTERPRETED TO REQUIRE LICENSEE TO INDEMNIFY LICENSOR, NOR REQUIRE LICENSOR TO INDEMNIFY LICENSEE.\n7. TERMINATION\n7.1. Violations of Ethical Standards or Breaching Duty of Care: If Licensee violates the Ethical Standards section or Licensee, or any other person or entity within the Supply Chain prior to a good or service reaching the Licensee, breaches its Duty of Care to Supply Chain Impacted Parties, Licensee must remedy the violation or harm caused by Licensee within 30 days of being notified of the violation or harm. If Licensee fails to remedy the violation or harm within 30 days, all rights in the Software granted to Licensee by License will be null and void as between Licensor and Licensee.\n7.2. Failure of Notice: If any person or entity notifies Licensee in writing that Licensee has not complied with the Notice section of this License, Licensee can keep this License by taking all practical steps to comply within 30 days after the notice of noncompliance. If Licensee does not do so, Licensee’s License (and all rights licensed hereunder) will end immediately.\n7.3. Judicial Findings: In the event Licensee is found by a civil, criminal, administrative, or other court of competent jurisdiction, or some other adjudicating body with legal authority, to have committed actions which are in violation of the Ethical Standards or Supply Chain Impacted Party sections of this License, all rights granted to Licensee by this License will terminate immediately.\n7.4. Patent Litigation: If Licensee institutes patent litigation against any entity (including a cross-claim or counterclaim in a suit) alleging that the Software, all or part of the Software’s code, or a derivative work developed using the Software, including a portion of its code, constitutes direct or contributory patent infringement, then any patent license, along with all other rights, granted to Licensee under this License will terminate as of the date such litigation is filed.\n7.5. Additional Remedies: Termination of the License by failing to remedy harms in no way prevents Licensor or Supply Chain Impacted Party from seeking appropriate remedies at law or in equity.\n8. MISCELLANEOUS:\n8.1. Conditions: Sections 3, 4.1, 5.1, 5.2, 7.1, 7.2, 7.3, and 7.4 are conditions of the rights granted to Licensee in the License.\n8.2. Equitable Relief: Licensor and any Supply Chain Impacted Party shall be entitled to equitable relief, including injunctive relief or specific performance of the terms hereof, in addition to any other remedy to which they are entitled at law or in equity.\n8.3. Copyleft: Modified software, source code, or other derivative work must be licensed, in its entirety, under the exact same conditions as this License.\n8.4. Severability: If any term or provision of this License is determined to be invalid, illegal, or unenforceable by a court of competent jurisdiction, any such determination of invalidity, illegality, or unenforceability shall not affect any other term or provision of this License or invalidate or render unenforceable such term or provision in any other jurisdiction. If the determination of invalidity, illegality, or unenforceability by a court of competent jurisdiction pertains to the terms or provisions contained in the Ethical Standards section of this License, all rights in the Software granted to Licensee shall be deemed null and void as between Licensor and Licensee.\n8.5. Section Titles: Section titles are solely written for organizational purposes and should not be used to interpret the language within each section.\n8.6. Citations: Citations are solely written to provide context for the source of the provisions in the Ethical Standards.\n8.7. Section Summaries: Some sections have a brief italicized description which is provided for the sole purpose of briefly describing the section and should not be used to interpret the terms of the License.\n8.8. Entire License: This is the entire License between the Licensor and Licensee with respect to the claims released herein and that the consideration stated herein is the only consideration or compensation to be paid or exchanged between them for this License. This License cannot be modified or amended except in a writing signed by Licensor and Licensee.\n8.9. Successors and Assigns: This License shall be binding upon and inure to the benefit of the Licensor’s and Licensee’s respective heirs, successors, and assigns.\n\n\n\n\n\n\n\n\n\nSome background\n\n\n\n\n\nThis project initially intended to use the library animate.css. However, it turned out that there was no need for it in this web thesis, so it is not used. Nevertheless, after reading their license on Github, I found the content very compelling.\nThus, I want to thank animate.css. Through their project, I came to know about the very appealing Hippocratic License. Let me give you some examples of why this license agreement is awesome: theBDS movement works to raise awareness of and combat the oppression conducted by Israel’s government. They aim to stop international support for Israel’s mistreatment of Palestinians and pressure Israel to comply with international law. Up until that point, I didn’t know that one could incorporate such beautiful justice into a license agreement, and I was pleasantly surprised to discover that there has already been significant work done in this area.\nAdditionally, I found great joy in reading some of the articles of the Universal Declaration of Human Rights. I am deeply grateful to have read such familiar articles and witnessed efforts to spread justice across the globe. When I say familiar articles, I mean, they have reminded me of my Quran.\n\n\n\n\n\n\n\n\n\nLicense in short\n\n\n\n\n\nYou are free to use the content of this webpage for whatever you like, including modification, sale, distribution, and more. However, please note that there are some important restrictions: You can do whatever you like with this content as long as it is halal or morally supportable. If you are unsure about a topic, please consult the license agreement.\nFirst, you are not allowed to insult, target minorities or religious groups, support Israel’s government, assist India in its oppression in Kashmir, assist the Chinese government’s oppression against Uighurs, and so on. Second, there is a copyleft - it basically means, your work is mandated to have the same license, i.e., you as well want to make sure that your work cannot be misused."
  },
  {
    "objectID": "Data/1_Writing/5_Additional/0_Appendix.html",
    "href": "Data/1_Writing/5_Additional/0_Appendix.html",
    "title": "Appendix A — Further implemented dynamical systems",
    "section": "",
    "text": "Chen (Chen and Ueta 1999): \\[     \n    \\begin{equation}\n        \\label{eq_8_Chen}\n        \\begin{aligned}\n            \\dot x &= a\\, (y - x) \\\\\n            \\dot y &= x \\,(\\beta - a) - xz + \\beta y \\\\\n            \\dot z &= x y -b z\n        \\end{aligned}\n    \\end{equation} \\tag{A.1}\\]\n\nLu (Lu and Chen 2002): \\[\n    \\begin{equation}\n        \\label{eq_9_Lu}\n        \\begin{aligned}\n            \\dot x &= a \\, (y -x) \\\\\n            \\dot y &= \\beta y -x z  \\\\\n            \\dot z &= x y - b z\n        \\end{aligned}\n    \\end{equation} \\tag{A.2}\\]\n\nVan der Pol (Devia Narvaez, Velez, and Devia Narvaez 2018): \\[\n    \\begin{equation}\n        \\label{eq_14_VDP}\n        \\begin{aligned}\n            \\dot x &= y \\\\\n            \\dot y &= y \\beta\\,(1-x^2) -x\n        \\end{aligned}\n    \\end{equation} \\tag{A.3}\\]\n\n\n\n\n\nChen, Guanrong, and Tetsushi Ueta. 1999. “Yet Another Chaotic Attractor.” International Journal of Bifurcation and Chaos 9 (07): 1465–66.\n\n\nDevia Narvaez, Diana, German Velez, and Diego Devia Narvaez. 2018. “Bifurcation Analysis of the van Der Pol Oscillator.” Contemporary Engineering Sciences 11 (85): 4245–52. https://doi.org/10.12988/ces.2018.88389.\n\n\nLu, Jinhu, and Guanrong Chen. 2002. “A New Chaotic Attractor Coined.” I. J. Bifurcation and Chaos 12 (March): 659–61. https://doi.org/10.1142/S0218127402004620."
  },
  {
    "objectID": "Data/1_Writing/5_Additional/1_Appendix.html",
    "href": "Data/1_Writing/5_Additional/1_Appendix.html",
    "title": "Appendix B — Some basics about chaotic systems",
    "section": "",
    "text": "Since Chaotic systems are the height of intricacy when considering dynamical systems. The reason why the term intricacy was chosen instead of complexity is that chaotic systems can be, but are not necessarily complex. For the relation between complex and chaotic the reader is referred to (Rickles, Hawe, and Shiell 2007). The mentioned intricacy of chaotic systems shall be explained by reviewing two reasons. First, chaotic systems are sensitive to their initial conditions. To understand this, imagine we want to solve an ODEOrdinary Differential Equation. In order to solve any differential equation, the initial condition or starting state must be known. Meaning, that the solution to the ODEOrdinary Differential Equation at the very first initial step, from where the remaining interval is solved, must be identified beforehand. One might believe, a starting point, which is not guessed unreasonably off, should suffice to infer the system’s future dynamics.\nThis is an educated attempt, however, it is not true for systems that exhibit sensitivity to initial conditions. These systems amplify any perturbation or deviation exponentially as time increases. From this it can be concluded that even in case the initial value would be accurate to, e.g., 10 decimal places, still after some time, the outcome can not be trusted anymore. Visually this can be comprehended by thinking of initial conditions as locations in space. Let us picture two points with two initial conditions that are selected to be next to each other. Only by zooming in multiple times, a small spatial deviation should be perceivable. As the time changes, the points will leave the location defined through the initial condition. \nWith chaotic systems in mind, both initially neighboring points will diverge exponentially fast from each other. As a consequence of the initial condition not being known with infinite precision, the initial microscopic errors become macroscopic with increasing time. Microscopic mistakes might be considered to be imperceptible and thus have no impact on the outcome, which would be worth to be mentioned. Macroscopic mistakes on the other hand are visible. Depending on accuracy demands solutions might be or might not be accepted. However, as time continues further, the results eventually will become completely unusable and diverge from the actual output on a macroscopic scale.\nThe second reason, why chaotic systems are very difficult to cope with, is the lack of a clear definition. It can be argued that even visually, it is not always possible to unambiguously identify a chaotic system. The idea is that at some time step, a chaotic system appears to be evolving randomly over time. The question then arises, how is someone supposed to distinguish between something which is indeed evolving randomly and something which only appears to be random. The follow-up question most likely is going to be, what is the difference between chaos and randomness, or even if there is a difference. \nMaybe randomness itself is only a lack of knowledge, e.g., the movement of gas particles can be considered to be chaotic or random. If the velocity and spatial position of each molecule are trackable, the concept of temperature is made redundant. Gibbs only invented the concept of temperature in order to be able to make some qualitative statements about a system (Argyris et al. 2017). A system that can not be described microscopically. Here the question arises if the movement of the molecules would be random, how is it possible that every time some amount of heat is introduced into a system, the temperature changes in one direction. If a random microscale system always tends to go in one direction within a macroscale view,\na clear definition of randomness is required. \nLaplace once said if the initial condition (space and velocity) of each atom would be known,\nthe entire future could be calculated. In other words, if a system is build on equations, which is a deterministic way to describe an event, the outcome should just depend on the values of the variables. Thus, the future, for as long as it is desired could be predicted or computed exactly. To briefly summarize this conversion, Albert Einstein once remarked that God would not play dice. Nils Bohr replied that it would be presumptuous of us human beings to prescribe to the Almighty how he is to take his decisions. A more in-depth introduction to this subject is provided by (Argyris et al. 2017). Nevertheless, by doing literature research, one way to visually distinguish between randomness and chaos was found (Boeing 2016). Yet, in (Boeing 2016) the method was only deployed on a logistic map. Hence, further research is required here. \nAs explained, a clear definition of chaos does not exist. However, some parts of definitions do occur regularly, e.g., the already mentioned Sensitive  Dependence on Initial Conditions (SDIC). Other definition parts are the following: Chaotic motion is and based on a system. An aperiodic system is not repeating any previous and a deterministic system is described by governing equations. A trajectory is the evolution of a dynamical system over time. For instance, a dynamical system consisting of 3 variables is denoted as a 3-dimensional dynamical system. Each of the variables has its own representation axis. Assuming these 3 variables capture space, motion in the x-,y- and z-direction is possible. For each point in a defined time range, there is one set of x, y and z values, which fully describes the output of the dynamical system or the position at a chosen time point. Simply put, the trajectory is the movement or change of the variables of the differential equation over time. Usually, the trajectory is displayed in the phase space, i.e., the axis represents the state or values of the variables of a dynamical system. An example can be observed in section 4.0.1. \nOne misconception which is often believed (Taylor 2010) and found, e.g., in Wikipedia (“Wikipedia Entry on Chaos Theory” 2021) is that strange attractors would only appear as a consequence of chaos. Yet, Grebogi et al. (Grebogi et al. 1984) proved otherwise. According to strange attractors exhibit self-similarity. This can be understood visually by imaging any shape of a trajectory. Now by zooming in or out, the exact same shape is found again. The amount of zooming in or out and consequently changing the view scale, will not change the perceived shape of the trajectory. Self-similarity happens to be one of the fundamental properties of a geometry in order to be called a fractal (Taylor 2010). In case one believes, strange attractors would always be chaotic and knows that by definition strange attractors phase space is self-similar, then something further misleading is concluded. Namely, if a geometry is turned out not only to be self-similar but also to be a fractal, this would demand interpreting every fractal to be chaotic. \nTo refute this, consider the Gophy attractor (Grebogi et al. 1984). It exhibits the described self-similarity,\nmoreover, it is a fractal, and it is also a strange attractor. However, the Gophy attractor is not chaotic. The reason is found, when calculating the Lyapunov exponent, which is negative (Taylor 2010). Latter tells us that two neighboring trajectories are not separating exponentially fast from each other. Thus, it does not obey the sensitive dependence of initial conditions requirement and is regarded to be non-chaotic. The key messages are that a chaotic attractor surely is a strange attractor and a strange attractor is not necessarily chaotic. A strange attractor refers to a fractal geometry in which chaotic behavior may or may not exist (Taylor 2010). Having acquired the knowledge that strange attractors can occur in chaotic systems and form a fractal, one might infer another question. If a chaotic strange attractor always generates a geometry, which stays constant when scaled, can chaos be regarded to be random?\nThis question will not be discussed in detail here, but for the sake of completeness, the 3 known types of nonstrange attractors shall be mentioned. These are the fixed point attractor, the limit cycle attractor, and the torus attractor (Taylor 2010). A fixed point attractor is one point in the phase space, which attracts or pulls nearby trajectories to itself. Inside the fix-point attractor, there is no motion, meaning the derivative of the differential equation is zero. In simpler words, once the trajectory runs into a fix-point, the trajectory ends there. This is because no change over time can be found here. A limit cycle can be expressed as an endlessly repeating loop, e.g. in the shape of a circle. The trajectory can start at any given initial condition, still, it can go through a place in the phase space, from where the trajectory is continued as an infinitely repeating loop. For a visualization of the latter and the tours, as well more detail the reader is referred to (Argyris et al. 2017; Kutz 2022; Strogatz 2019; Taylor 2010).\n\n\n\n\nArgyris, John, Gunter Faust, Maria Haase, and Rudolf Friedrich. 2017. Die Erforschung Des Chaos. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-54546-1.\n\n\nBoeing, Geoff. 2016. “Visual Analysis of Nonlinear Dynamical Systems: Chaos, Fractals, Self-Similarity and the Limits of Prediction.” Systems 4 (4): 37. https://doi.org/10.3390/systems4040037.\n\n\nGrebogi, Celso, Edward Ott, Steven Pelikan, and James A. Yorke. 1984. “Strange Attractors That Are Not Chaotic.” Physica D: Nonlinear Phenomena 13 (1): 261–68. https://doi.org/https://doi.org/10.1016/0167-2789(84)90282-3.\n\n\nKutz, Prof. J. Nathan. 2022. “AMATH 568Advanced Differential Equations: Asymptotics & Perturbations.”\n\n\nRickles, D., P. Hawe, and A. Shiell. 2007. “A Simple Guide to Chaos and Complexity.” Journal of Epidemiology & Community Health 61 (11): 933–37. https://doi.org/10.1136/jech.2006.054254.\n\n\nStrogatz, Steven. 2019. Nonlinear Dynamics and Chaos : With Applications to Physics, Biology, Chemistry, and Engineering. Boca Raton: CRC Press.\n\n\nTaylor, Robert LV. 2010. “Attractors: Nonstrange to Chaotic.” Society for Industrial and Applied Mathematics, Undergraduate Research Online, 72–80.\n\n\n“Wikipedia Entry on Chaos Theory.” 2021. https://en.wikipedia.org/wiki/Chaos_theory."
  }
]